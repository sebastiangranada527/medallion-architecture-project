{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ceb4872",
   "metadata": {},
   "source": [
    "# 1. Iniciar Spark y leer Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da8e650d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas en Bronze: 5500\n",
      "root\n",
      " |-- sale_date: date (nullable = true)\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- total: double (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n",
      "+----------+--------+------------------------------------+----------+--------+-------+-------+---------+\n",
      "|sale_date |store_id|customer_id                         |product   |quantity|price  |total  |status   |\n",
      "+----------+--------+------------------------------------+----------+--------+-------+-------+---------+\n",
      "|2025-07-27|NW-166  |8b1ff910-f298-4568-8f85-d7879a818f90|Smartphone|2       |1190.42|2380.84|Completed|\n",
      "|2025-01-15|NW017   |03afe752-6931-46bf-a7f2-f1d57ddba376|Headphones|1       |1026.98|1026.98|Completed|\n",
      "|2025-03-12|NW055   |7d3928fa-7308-4afb-9c1f-0759e812d758|Monitor   |1       |NULL   |575.75 |Returned |\n",
      "|2025-03-14|NW-142  |9670544b-48ea-4a5d-946b-1798f7d40349|Smartphone|5       |1084.0 |5420.0 |Completed|\n",
      "|2025-09-16|078-NW  |7a87eccb-7518-413b-934e-29ee2534a622|Laptop    |3       |647.28 |1941.84|Returned |\n",
      "+----------+--------+------------------------------------+----------+--------+-------+-------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, regexp_replace, when, to_date, sum as spark_sum, count, lit\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Medallion - Capas Silver y Gold\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Ruta a Bronze (de Etapa 2)\n",
    "bronze_path = \"../../etapa2-bronze/data/bronze/sales_raw.parquet\"\n",
    "df_bronze = spark.read.parquet(bronze_path)\n",
    "\n",
    "print(\"Filas en Bronze:\", df_bronze.count())\n",
    "df_bronze.printSchema()\n",
    "df_bronze.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a94ff9",
   "metadata": {},
   "source": [
    "# 2. Capa Silver – Limpieza y estandarización\n",
    "\n",
    "## Limpieza de datos\n",
    "\n",
    "1. Estandarizar store_id (eliminar prefijos/sufijos y normalizar)\n",
    "2. Manejar nulos en columnas clave\n",
    "3. Filtrar filas corruptas (ejemplo: total negativo o cantidad negativa)\n",
    "4. Convertir fechas a formato estándar\n",
    "5. Guardar Silver\n",
    "\n",
    "## Verificación\n",
    "\n",
    "1. Filas después de limpieza\n",
    "2. store_id únicos\n",
    "3. Ejemplos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "272e1634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa Silver guardada en: ../data/silver/sales_clean.parquet\n",
      "Filas después de limpieza: 5500\n",
      "+--------+\n",
      "|store_id|\n",
      "+--------+\n",
      "|07      |\n",
      "|125     |\n",
      "|124     |\n",
      "|51      |\n",
      "|030     |\n",
      "|169     |\n",
      "|088     |\n",
      "|15      |\n",
      "|54      |\n",
      "|155     |\n",
      "|154     |\n",
      "|132     |\n",
      "|009     |\n",
      "|101     |\n",
      "|11      |\n",
      "|138     |\n",
      "|032     |\n",
      "|065     |\n",
      "|073     |\n",
      "|29      |\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "+----------+--------+------------------------------------+----------+--------+-------+-------+---------+\n",
      "|sale_date |store_id|customer_id                         |product   |quantity|price  |total  |status   |\n",
      "+----------+--------+------------------------------------+----------+--------+-------+-------+---------+\n",
      "|2025-07-27|166     |8b1ff910-f298-4568-8f85-d7879a818f90|Smartphone|2       |1190.42|2380.84|Completed|\n",
      "|2025-01-15|017     |03afe752-6931-46bf-a7f2-f1d57ddba376|Headphones|1       |1026.98|1026.98|Completed|\n",
      "|2025-03-12|055     |7d3928fa-7308-4afb-9c1f-0759e812d758|Monitor   |1       |0.0    |575.75 |Returned |\n",
      "|2025-03-14|142     |9670544b-48ea-4a5d-946b-1798f7d40349|Smartphone|5       |1084.0 |5420.0 |Completed|\n",
      "|2025-09-16|078     |7a87eccb-7518-413b-934e-29ee2534a622|Laptop    |3       |647.28 |1941.84|Returned |\n",
      "+----------+--------+------------------------------------+----------+--------+-------+-------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# 1. Estandarizar store_id (eliminar prefijos/sufijos y normalizar)\n",
    "df_silver = df_bronze.withColumn(\n",
    "    \"store_id\",\n",
    "    regexp_replace(col(\"store_id\"), r\"[^0-9]\", \"\")  # Quita todo lo que no sea número\n",
    ").withColumn(\n",
    "    \"store_id\",\n",
    "    when(col(\"store_id\") != \"\", col(\"store_id\")).otherwise(\"UNKNOWN\")\n",
    ")\n",
    "\n",
    "# 2. Manejar nulos en columnas clave\n",
    "df_silver = df_silver.na.fill({\n",
    "    \"price\": 0.0,\n",
    "    \"total\": 0.0,\n",
    "    \"status\": \"Unknown\",\n",
    "    \"quantity\": 0\n",
    "})\n",
    "\n",
    "# 3. Filtrar filas corruptas (ejemplo: total negativo o cantidad negativa)\n",
    "df_silver = df_silver.filter(\n",
    "    (col(\"total\") >= 0) & (col(\"quantity\") >= 0)\n",
    ")\n",
    "\n",
    "# 4. Convertir fechas a formato estándar\n",
    "df_silver = df_silver.withColumn(\"sale_date\", to_date(col(\"sale_date\")))\n",
    "\n",
    "# 5. Guardar Silver\n",
    "silver_path = \"../data/silver/sales_clean.parquet\"\n",
    "df_silver.write.mode(\"overwrite\").parquet(silver_path)\n",
    "print(\"Capa Silver guardada en:\", silver_path)\n",
    "\n",
    "# Verificación\n",
    "print(\"Filas después de limpieza:\", df_silver.count())\n",
    "df_silver.select(\"store_id\").distinct().show(20, truncate=False)\n",
    "df_silver.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45be3bd",
   "metadata": {},
   "source": [
    "# 3. Capa Gold – Tablas curadas y métricas de negocio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6baf593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tablas Gold generadas:\n",
      "- Daily: ../data/gold/sales_fact_daily.parquet\n",
      "- Product-Store: ../data/gold/sales_fact_product_store.parquet\n"
     ]
    }
   ],
   "source": [
    "# 1. Tabla de hechos diaria: Revenue por día\n",
    "df_gold_daily = df_silver.groupBy(\"sale_date\") \\\n",
    "    .agg(\n",
    "        spark_sum(\"total\").alias(\"daily_revenue\"),\n",
    "        count(\"*\").alias(\"num_transactions\"),\n",
    "        spark_sum(\"quantity\").alias(\"total_quantity\")\n",
    "    ) \\\n",
    "    .orderBy(\"sale_date\")\n",
    "\n",
    "# 2. Tabla de hechos por producto y tienda (para análisis más granular)\n",
    "df_gold_product_store = df_silver.groupBy(\"sale_date\", \"product\", \"store_id\") \\\n",
    "    .agg(\n",
    "        spark_sum(\"total\").alias(\"revenue\"),\n",
    "        count(\"*\").alias(\"transactions\")\n",
    "    )\n",
    "\n",
    "# 3. Guardar en Gold\n",
    "gold_daily_path = \"../data/gold/sales_fact_daily.parquet\"\n",
    "gold_product_store_path = \"../data/gold/sales_fact_product_store.parquet\"\n",
    "\n",
    "df_gold_daily.write.mode(\"overwrite\").parquet(gold_daily_path)\n",
    "df_gold_product_store.write.mode(\"overwrite\").parquet(gold_product_store_path)\n",
    "\n",
    "print(\"Tablas Gold generadas:\")\n",
    "print(\"- Daily:\", gold_daily_path)\n",
    "print(\"- Product-Store:\", gold_product_store_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84907110",
   "metadata": {},
   "source": [
    "# 4. Validación y visualización rápida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a80f9575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+----------------+--------------+\n",
      "|sale_date |daily_revenue     |num_transactions|total_quantity|\n",
      "+----------+------------------+----------------+--------------+\n",
      "|2024-12-21|24151.810000000005|10              |31            |\n",
      "|2024-12-22|13844.140000000001|9               |24            |\n",
      "|2024-12-23|27729.260000000002|15              |47            |\n",
      "|2024-12-24|18798.09          |15              |37            |\n",
      "|2024-12-25|30142.49          |12              |48            |\n",
      "|2024-12-26|35226.26          |16              |53            |\n",
      "|2024-12-27|22571.26          |11              |31            |\n",
      "|2024-12-28|20570.24          |10              |30            |\n",
      "|2024-12-29|21889.72          |10              |27            |\n",
      "|2024-12-30|27064.719999999998|19              |54            |\n",
      "+----------+------------------+----------------+--------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAcAAAJICAYAAAAdGo3BAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOydB7wdVbX/1+039970TkmhJ5SE0HtvF7GhIoqiFJ8+eE/hPeHhX6kqDxUVnyiKoj55UhUVDb23kJAQSAiQEALpvd9+zz3/z9pn1syaPXvaOXP6+vIJ95Q5M3tm9uyy9lq/VZNOp9MgCIIgCIIgCIIgCELVUlvsAgiCIAiCIAiCIAiCUFzEOCAIgiAIgiAIgiAIVY4YBwRBEARBEARBEAShyhHjgCAIgiAIgiAIgiBUOWIcEARBEARBEARBEIQqR4wDgiAIgiAIgiAIglDliHFAEARBEARBEARBEKocMQ4IgiAIgiAIgiAIQpUjxgFBEARBEARBEARBqHLEOCAIgiAIQiROPPFE9S9JPvjgA6ipqYHf//73ie539uzZ0NjYCB9++GGi+61Enn32WXUP8G/cOrBo0SKor6+HhQsX5rmUgiAIQr4R44AgCIJQ1uCkEic29A8nKrvuuit86UtfglWrVhW7eCULXh9+3dra2mCPPfaAT33qU/DnP/8ZBgYGoJz5f//v/8H5558PEydO9Hz30EMPwVlnnQWjRo1SBoRddtkFPvOZz8DTTz8Npc769evhv/7rv+DAAw9U96y5uRn22msv+PKXvwwvvvhiwcszdepUOPvss+Haa68t+LEFQRCEZKlPeH+CIAiCUBRuvPFGmDx5MnR3d8OsWbOU0QAnS7iiiRMowUtTUxP85je/Ua+7urrUKvvDDz+sDAS4Ovy3v/0NhgwZYm//+OOPJ14GnLzjsRsaGhLb5/z58+HJJ5+El19+2fV5Op2Giy66SNWNgw8+GK688koYN24crFmzRhkMTjnlFHjppZfg6KOPhlIEvSFwIr5jxw747Gc/C1/96lfVPVy2bBn89a9/Vef13HPPwfHHH1/QcmE52tvbYenSpbDnnnsW9NiCIAhCcohxQBAEQagIcCX40EMPVa8vueQStSp8yy23wN///ne1Kix4QS+LCy64wPXZd7/7Xfjv//5vuOaaa+DSSy+F++67z/4OV9mTor+/X3kn4D6TNt787ne/gwkTJsCRRx7p+vzWW29VE+hvfOMb8OMf/1h5THBPgz/+8Y/qmpQiW7ZsgY9//OOqfGj82G+//Tz37d5774VBgwYVvGynnnoqDB8+HP7whz8oI50gCIJQnkhYgSAIglCRHHfcceovrmZy3nnnHbUyPmLECDUpRYMCGhCI1157TU0acaKj89hjj6nv/vGPf9ifYegCrkaPHTtWreLuv//+cNdddxljuu+//3743ve+B7vttps6Nq5Uv/fee65tJ02apFz+o8T79/T0wHXXXafcyvHYu+++O1x11VXq81xAt/XTTz8dHnjgAVi8eLFvGXp7e5U7+SGHHAJDhw6F1tZWdd2feeYZo67Aj370I/jpT3+qVpexvBiv7qc5gC7+uC/c57Bhw+BjH/sYvP3225HKj6voJ598smvyj94JN998s5pUYzn4d8QXvvAFOPzww9XrzZs3w3/+53/a7vvoQYEGqDfeeMN4b9GI8q1vfUt5ImCZP/rRj8KKFStc277wwgvw6U9/Whku6H5dccUVqmxh3HHHHcrDAa+fbhhAsAwYRnHYYYe5Pn/99ddVubH8eB5Y59CzJgq//vWv1b1CgwNeFyy/CfT6IE8TQRAEoXwpTfO4IAiCIOQITjoRXNEk3nrrLTjmmGOUJgFOgHEShxN2XJHFOPtPfOITyliAsff4+YUXXujaJ04AcX9nnHGGer9u3Tq1Oo0Ts8svvxxGjx4NjzzyCFx88cWwfft2tULNwRX52tpaNenctm0b/OAHP4DPf/7z8Oqrr8Y+P1x1xwkohk585StfgSlTpsCCBQvgJz/5iZrQ4wQ5F3CijGEETzzxBOyzzz7GbfAcMSwBJ6XoZYDu7r/97W/V9UEX+OnTp3tW9DHsA8uLk2M00Ji0DTAkACe0eB+uv/56NXn+n//5H3Xv5s2bpwwofqCxZvny5TBjxgzX53idcMKP96Suri70/N9//311DXEyj+EqeK9/9atfwQknnKCMGqhTwEGjD9aDq6++WukC4CQeV9RxlZ9W89HY0tnZCV/72tdg5MiR6hrhea1cuVJ9FwSGe+B+PvnJT0JUsL6jgQUNA2g0wkk8ngNO5DH84IgjjvD9Ld7Hf/mXf1EhFnjN8HpgfcN7hkYNHTQQoXEA6wQPRREEQRDKiLQgCIIglDG/+93v0tidPfnkk+kNGzakV6xYkX7wwQfTo0ePTjc1Nan3xCmnnJI+8MAD093d3fZnAwMD6aOPPjq99957259dc8016YaGhvTmzZvtz3p6etLDhg1LX3TRRfZnF198cXr8+PHpjRs3usr02c9+Nj106NB0Z2enev/MM8+oMk6ZMkXth7jtttvU5wsWLLA/mzhxYvrCCy/0nOcJJ5yg/hF//OMf07W1tekXXnjBtd0dd9yh9vnSSy8FXjc8Rmtrq+/3r7/+utrPFVdc4VuG/v5+1/kgW7ZsSY8dO9Z1nZYtW6b2NWTIkPT69etd29N3eB+J6dOnp8eMGZPetGmT/dkbb7yhzveLX/xi4HlhPcD9Pfzww67P6Vo/9NBD6ShgHUmlUp6yYp268cYb7c/o3u66667p7du325/ff//96nM8LkH1gXPzzTena2pq0h9++GFgeYYPH66uiw4eE+s9/du5c6f93cc//vF0Y2NjeunSpfZnq1evTg8ePDh9/PHHe84B/yK9vb3q+uPx+P399a9/rbbjdYD405/+pL579dVXA89DEARBKF0krEAQBEGoCHCVFlfucVUTwwbQKwDDBdCFH8FVY3RVR/0BXOHeuHGj+rdp0ya10r1kyRI7u8F5550HfX198Je//MXeP66ib926VX1H4nbobXDOOeeo17Q//If7Q88AXOXmoKI8j9un0AdclY0LrjSjtwC6mPNjozs9orv2xwVd0BG8Vn7gCjydD3oA4DVGLQH0vtDPHTn33HPVPQoCXedxtR1DK3CVmjjooIPgtNNOg5kzZwb+Hu+n7jGC4Io2MnjwYIgCejaglweSSqXUfvGa7LvvvsZz++IXv+jaN9bB8ePHu8rL9QA6OjrU/cKVeaw/6P4fBJaf7onu4YHXlP6h5wKVGessesWgBwaBZfrc5z6nPCnomuhgaA16P6DQIK+veE8wfMQEXW88J0EQBKE8EeOAIAiCUBHcfvvtygX+wQcfVMrpOEnBCR6Bsf04CfvOd77jmkzhP4zbR3BChEybNk1NurkYH75GkUOafG/YsEEZCzAuW98fGgH4/giMNTdNqFBsLi5ozEC3cf3YFAKgHzsuO3fujDSZRm0GnLijhgK6ymMZ/vnPfyrjiA6654eBGRMQnITroDEE7ytOrMPAe80hV/cgYwcHjR0YorH33nureoT3Hs/tzTffNJ4bbsfBEAPUgqDwFgTDHcjogRN93B+GKSCmfXLwPtA94aAAINZ7/MfB+okhDH7XEc9P10TQ74F+ThiWwA0Nputt0nIQBEEQygPRHBAEQRAqAhRMo2wFuFp67LHHqhXSd999V03EKLYd4/1JM0AHJ3MEeghgHDlORnFihl4IGFtPava0P1T717UJCJw0c/xi3flE1m9yhSvB/Pd4fBTLQ9V9E6a48DhgCkj9mujcfffdarKL1/ub3/wmjBkzRpURhf90IUikEEr6aKAwGVxIxA91GbC8YXz/+99XhiQUm7zpppvUhB49CTD+3qSTEAbeP/R8QO8KXN3H8qB3C3qr4DUM2yduj2KI6NHC0z7qdaxY0PVGI4ogCIJQnohxQBAEQag4aIJ60kknwc9//nMlPkgrnjixwhCEMNA4cMMNN6jQAcxEgC7YmFuewFVfNBrgpC/K/qKC3gTokWBazeWrtqgij5NFVJ/Px2otpvXD/eKE1g/00sAyYfgFLwN5YmTDxIkT1V806uhgpgmcfOKk2g8yAixbtsz1ORqL8Nrec889KqtAmCghnhvWHxTm4+C9MU2A0ZNDN/igtwpN3tEogUKR6GmBIQiEvuLvx0c+8hGVZeChhx6KlJoT62dLS4vvdURDh58Bie4BnhN5yiBomMDrip41Ovg57tNPvFIQBEEofSSsQBAEQahIUJEdvQlQNR4V8nFVGz9DtXaMa9dBN2zd9RpX5jGcAP9hrPbxxx9vf4+TS4yhR+MBrbIH7S8qOOnHSSCmCSQwdaLuAo4TRFx1vvPOOz37QHX/KK73fmBWBYxXRwOJ7lrOoQk293zAzAuvvPJK1sfG64xZDnASzY0keI2xTBgyEgRmosBJL8bNc3CijCv2mA4R/+phB+QJgRkE6Nz0bVDngXQpdP73f//XFbKAxgWsZ5h1gfaH8H3i69tuuw2igBkO0EiFqQ95ekm+Lw4eD9NRYgYBHtqAWRf+9Kc/KWOJX1YB9MBB4wKmT+T1ENNNmgxXyNy5c1UaTz9NAkEQBKH0Ec8BQRAEoWJBV3dMRYeTGhRXQ10CnBThpB9T7+GqN06WcDKL6eT0HPY4Ob722mtVPD2mJySBOj6JRuE/TAmH+5s6dapyG0fBOkzHh6/jcskll6iJ5ZlnnqkMAOiej5NWNBroQnSYbhHPC8uAaf7QiwFXhfHzxx57zA6z8APFA3HfCBpQ0DsBwycwrh5XzVFPIWw1G70GMAXk2WefrVaPcUKJ18EUHx+VH/7wh2pSfdRRR6nrTqkMceKJqQ3D+NjHPqZW2HHCzD0asD6gTsOtt96qrhmKBo4bNw7Wrl2r0haiYeDll1+2zw3j+VE/AkUDceX///7v/3xj7jHsAOsWbo91Co1SGJKB9YI8GvAeYlgLGhhwYo6Gpah6E7h/PCcUwMSVe/RiOeyww5QnDBqOKBUi17X47ne/qzwTsFz/+q//qkJi0DjW09Oj0mj6gfvE32IqQ/QcwOcA7y2mojSdP3oUYGpEPIYgCIJQxhQ7XYIgCIIgJJHKcM6cOZ7vMBXdnnvuqf5h2j0E07phOrxx48apdIWYgu4jH/mISn+os2TJErVv/Pfiiy8aj79u3br0ZZddlt59993V/nC/mDIR077pqeIeeOCB0DR+yK233qrKhWnzjjnmmPRrr73mSSNIKeduueWW9P7776+2xXR3hxxySPqGG25Ib9u2LTSVIZ0b/mtpaUlPmjQpfe6556proafxQ/QyYBrI73//+yr9Ih7/4IMPTv/jH/9Q+8bP9PP84Q9/6Nmn3zXAlIR47oMGDVIpEM8555z0okWL0lGYN2+e2qee5pHA8zv99NPTI0aMSNfX16t0lOedd1762WefdaUy/I//+A/1HZYBy/LKK694rgHd23vuuUelwMQUgLj92Wef7UlPiOU/9dRT021tbelRo0alL730UpWi0XT+fqxZsyb9zW9+Mz116lR1HLzue+yxh6rTzz//vPFanHHGGeqYeI9POumk9Msvv+zaRk9lSPziF79IT548WR3j0EMPVfs31cNHHnlE/R6fF0EQBKF8qcH/FdtAIQiCIAiCkCSoxbDLLrso7YR88uyzzyovC1y5R0+EagQFHtFDAz0bBEEQhPJFNAcEQRAEQag4MNsAakVQWj4hP6CGA2piYEYHQRAEobwRzQFBEARBECoO1IHgYnpCfkDhTtSuEARBEMof8RwQBEEQBEEQBEEQhCpHNAcEQRAEQRAEQRAEocoRzwFBEARBEARBEARBqHKKbhzAXL8XXHABjBw5EgYNGqRyT7/22mv29+jYgDmmx48fr74/9dRTYcmSJa59YB7pz3/+8ypn8LBhw1ROZD2/MuZsPu6441Su6t13392Y3xeVhjEPMW6D5Zg5c2Yez1wQBEEQBEEQBEEQSoOiChJu2bIFjjnmGJUC6JFHHoHRo0erif/w4cPtbXAS/7Of/Qz+8Ic/wOTJk+E73/kOnHHGGbBo0SI1iUfQMLBmzRp44oknoK+vD7785S/DV77yFfjTn/6kvt++fTucfvrpyrBwxx13wIIFC+Ciiy5ShgTcDnn55Zfh/PPPh5tvvhk+8pGPqN9iap558+bBAQccEHouAwMDsHr1ahg8eLBK5yMIgiAIgiAIgiAI+QQX03fs2KHS99bW5rj2ny4iV199dfrYY4/1/X5gYCA9bty49A9/+EP7s61bt6abmprS99xzj3q/aNEi1ExIz5kzx97mkUceSdfU1KRXrVql3v/iF79IDx8+PN3T0+M69r777mu//8xnPpM+++yzXcc/4ogj0v/yL/8S6VxWrFihyiH/5J/8k3/yT/7JP/kn/+Sf/JN/8k/+QQH/4Xw0V4rqOfD3v/9deQF8+tOfhueeew523XVX+Nd//Ve49NJL1ffLli2DtWvXqhV/YujQoSo90SuvvAKf/exn1V/0ADj00EPtbXB7tJq8+uqr8IlPfEJtc/zxx0NjY6O9DR73lltuUd4L6KmA21x55ZWu8uE2f/3rX41l7+npUf8I0nXEMqP3QLWDHhzPPPOM8gppaGgodnGEEkTqiBAXqTNCXKTOCLkg9UeIi9QZoRh1Br0G0MM+iTloUY0D77//Pvzyl79Uk/JvfetbMGfOHPj3f/93NYm/8MILlWEAGTt2rOt3+J6+w79jxoxxfV9fXw8jRoxwbYMXTN8HfYfGAfwbdBwdDD+44YYbPJ+jkaGlpSWLq1F54HVAA40g+CF1RIiL1BkhLlJnhFyQ+iPEReqMUOg609nZqf4mEdpeVOMAxunjiv/3v/999f7ggw+GhQsXKl0ANA6UMtdcc43L0wB1DVDoELUNUBix2kErGGpAnHbaaWI5FYxIHRHiInVGiIvUGSEXpP4IcZE6IxSjzuA8NCmKahzADARTp051fTZlyhT485//rF6PGzdO/V23bp3alsD306dPt7dZv369ax/9/f0qgwH9Hv/ibzj0Pmwb+l6nqalJ/dPBmyqNgYNcDyEMqSNCXKTOCHGROiPkgtQfIS5SZ4RC1pkk61pRUxlipoJ3333X9dnixYth4sSJ6jWGAuDk/KmnnnJZRtDt4qijjlLv8e/WrVth7ty59jZPP/208kpAbQLa5vnnn1eWGQItNPvuu6+dGQG34cehbeg4giAIgiAIgiAIglCpFNU4cMUVV8CsWbNUWMF7772n0gf++te/hssuu8yOm/jGN74B3/3ud5V4IaYg/OIXv6jSNGCaQfI0OPPMM5WI4ezZs+Gll16Cyy+/XIkV4nbI5z73OaVjcPHFF8Nbb70F9913H9x2222usICvf/3r8Oijj8Ktt94K77zzDlx//fXw2muvqX0JgiAIgiAIgiAIQiVT1LCCww47DB566CEVv3/jjTcqT4Gf/vSn8PnPf97e5qqrroKOjg74yle+ojwEjj32WDWJb25utrf5v//7PzWJP+WUU1SWgnPPPRd+9rOfuTIcPP7448rocMghh8CoUaPg2muvVfskjj76aGWc+Pa3v63EEffee2+VqeCAAw4o4BURBEEQBEEQBEEQhCozDiAf+chH1D8/0HsADQf4zw/MTIAT+yAOOuggeOGFFwK3wZSK+E8QBEEQBEEQBEEQqomihhUIgiAIgiAIgiAIglB8xDggCIIgCIIgCIIgCFWOGAcEQRAEQRAEQRAEocoR44AgCIIgCIIgCIIgVDliHBAEQRAEQRAEQRCEKkeMA4IgCIIgCIIgCIJQ5YhxQBAEQRAEQRAEQRCqnPpiF0AQBEEQBEEQBEEQikFqIA2zl22G9Tu6YczgZjh88gioq62BakSMA4IgCIIgCIIgCELV8ejCNXDDw4tgzbZu+7PxQ5vhunOmwpkHjIdqQ8IKBEEQBEEQBEEQhKozDHzt7nkuwwCydlu3+hy/rzbEOCAIgiAIgiAIgiBUVSgBegykDd+lrb/4PW5XTYhxQBAEQRAEQRAEQagaUGNA9xjgoEkAv8ftqgkxDgiCIAiCIAiCIAhVA4oPJrldpSDGAUEQBEEQBEEQBKFqwKwESW5XKYhxQBAEQRAEQRAEQagaMF0hZiXwS1hYY2UtwO2qCTEOCIIgCIIgCIIgCFVDXW2NSleI6AaCGusvfo/bVRNiHBAEQRAEQRAEQRCqijMPGA+/vGAGjBvqDh0YN7RZfY7fVxv1xS6AIAiCIAiCIAiCIBQaNACcNnUcHPG9J2FjRy9cdtKecOVp+1adxwAhngOCIAiCIAiCIAhCVYKGgLq6jDFg8qi2qjUMIGIcEARBEARBEARBEKqW1EDa+jsA1YwYBwRBEARBEARBEISqpd82DkBVI8YBQRAEQRAEQRAEoWpJpSzjQDrzt1oR44AgCIIgCIIgCIJQtdieA6nqdh0Q44AgCIIgCIIgCIJQtdiaA2moasQ4IAiCIAiCIAiCIFQt/ZYQ4YBlJKhWxDggCIIgCIIgCIIgVCVoECCbQL8YBwRBEARBEARBEASh+uAihAMiSCgIgiAIgiAIgiAI1Uc/ExpIieeAIAiCIAiCIAiCIFSv3gAiYQWCIAiCIAiCIAiCUIVwb4EBMQ4IgiAIgiAIgiAIQvXBvQVSojkgCIIgCIIgCIIgCNXtOZASzwFBEARBEARBEARBqHLPgQExDgiCIAiCIAiCIAhC1ZGSbAU2YhwQBEEQBEEQBEEQoNqzFaSq3DhQX+wCCEIhwAd99rLNsH5HN4wZ3AyHTx4BdbU1xS6WIAiCIAiCIAilojmQFuOAIFQ0jy5cAzc8vAjWbOu2Pxs/tBmuO2cqnHnA+KKWTRAEQRAEQRCE0tAcGKhyzwEJKxAq3jDwtbvnuQwDyNpt3epz/F4QBEEQBEEQhOqEew70i3FAECr3QUePAdMjTp/h99UeWyQIgiAIgiAI1Yp4DjiIcUCoWFBjQPcY4OCjj9/jdoIgCIIgCIIgVB8pLkiYFuOAIFQkKD6Y5HaCIAiCIAiCIFQW/SyVYb94DghCZYJZCZLcThAEQRAEQRCEyoKHGA+IcUAQKhNMV4hZCfwSFuLn+D1uJwiCIAiCIAhC9cG9BVJiHBCEyqSutkalKzRBBgP8HrcTBEEQBEEQBKH64AaBlBgHBKFyOfOA8fDLC2bA6LYm1+fjhjarz/F7QRAEQRAEQRCqE5fnQLq6jQP1xS6AIOQbNABMHtUGZ/z0efX+NxceCiftO0Y8BgRBEARBEAShQsBVf8xChmLjqCmGocNRxvuubAUDYhwQhKri0InDxTAgCIIgCIIgCBXCowvXwA0PL3KlMUdtMQwhDvMUFs0BBwkrEKqCfrEICoIgCIIgCEJFGga+dvc8l2EAWbutW32O3wchmgMOYhwQqgJmG4Aqf+YFQRAEQRAEoSLAyTx6DJiG9/QZfh806e9PsVSG6eqeKIhxQKg6z4Fqf+gFQRAEQRAEoRJAjQHdY4CDo378HrfzgxsO+qt8FVGMA0JVwA0CYhwQBEEQBEEQhPIHxQdz3Y4bBAbEOCAIlQ93F6r2WCJBEARBEARBqAQwK0Gu27myFaSre54gxgGhKuAPepU/84IgCIIgCIJQEWC6QsxK4JeHDD/H73G7KJ4D/WxBsRoR44BQFYgKqSAIgiAIgiBUFpieHNMVIrqBgN7j90FpzPncYKDKVxHFOCBUBfLQC4IgCIIgCELlceYB4+GXF8yAcUPdoQP4Hj/H74PgngOpKl9EFOOAUBWIcUAQBEEQBEEQKhM0ALx49ckwdkiTev/Zw3ZX78MMA4h4GDuIcUCoQuNAUYsiCIIgCIIgCELCYOhAbU0mfGC34YMCQwl8hcvT1T1REOOAUBWI54AgCIIgCIIgVDa9/QOeUIEweLaCAedlVSLGAaEqkFgiQRAEQRAEQagO48BAjPG+K1vBQHVbB8Q4IFQF3FtAHAcEQRAEQRAEofLoSWXjOcAXEaGqEeOAUBW4YonEc0AQBEEQBEEQKop0Om17DsTRDuCGhIEqX0UU44BQFfAGotofekEQBEEQBEGoNPr4YiB7HQZfOOyvcteB+mIXQBAKgQgSCoIgCIXqb2Yv2wzrd3TDmMHNcPjkEZEVswVBEITs6WUT+3ieA0yQMA1VjRgHhKpAUhkKgiAI+ebRhWvghocXwZpt3fZn44c2w3XnTI2Ua1sQBKEUKEUjZ5Qy9fSlXNvH2Xc2v6tExDggVAXy0AuCIAj5Ngx87e55oPcwa7d1q89/ecEMMRAUgVKc5AhCKVOKRs6oZXJ5DsTJViDaZDZiHBCqAgkrEARBEPLZx+DA1dS74Gc4FcXvT5s6TiamVT7JEYRSphSNnHHKRGKEOXkOpKt7niCChEJVwB/6Kn/mBUEQhITBlWk+AdXBbge/x+2Ewk4o9PtCEwr8XhCE6EZOBL8v5Mp63DJlaxzg2QpSA2mV9aBaEeOAUBVwK2C1uwsJgiAIyYIu60luJ1TeJEcQSp1SNHLGLVNPAp4DSDU3DWIcEKoCCSsQBEEQ8gXGsie5nVB5kxxBKHUKZeTEMfkrSzfB3+avUn+DJvFxy5REtgKkmg2HojkgVAVcaESMA4IgCEKSoMgdxrKjy7qph0GVgXFDM2J4Qv4RTw5BKE0jZ1wdkLhlSkJzoNrnCuI5IFQF3HqoGQcFQRAEISdQZBAHt4guN0jv8XsRIywM4skhCNkbOf1aKfx8fA5Gzmx0QOKWqScBzQHT+2qiqMaB66+/Hmpqalz/9ttvP/v77u5uuOyyy2DkyJHQ1tYG5557Lqxbt861j+XLl8PZZ58NLS0tMGbMGPjmN78J/f39rm2effZZmDFjBjQ1NcFee+0Fv//97z1luf3222HSpEnQ3NwMRxxxBMyePTuPZy4UmhSzCFS7CqkgCIKQPLjqharZ6CHAwfeSxrCyJjmCUOlGTkjYyJmtDkhcw2tSngMpMQ4Uj/333x/WrFlj/3vxxRft76644gp4+OGH4YEHHoDnnnsOVq9eDZ/85Cft71OplDIM9Pb2wssvvwx/+MMf1MT/2muvtbdZtmyZ2uakk06C+fPnwze+8Q245JJL4LHHHrO3ue++++DKK6+E6667DubNmwfTpk2DM844A9avX1/AKyHkExaCVNUKpIIgCEL+QAPAi1efDLtYBoLLT9pTvRfDQOVMcgShGoycYwY3JWrkzEUHxC7TkPAyZZ2tgIUfIwNiHCge9fX1MG7cOPvfqFGj1Ofbtm2D3/72t/DjH/8YTj75ZDjkkEPgd7/7nTICzJo1S23z+OOPw6JFi+Duu++G6dOnw1lnnQU33XST8gJAgwFyxx13wOTJk+HWW2+FKVOmwOWXXw6f+tSn4Cc/+YldBjzGpZdeCl/+8pdh6tSp6jfoiXDXXXcV6aoIefUckLACQRAEIU/ghLOpoU693mvMYJmAFgmaUIxsbXR9Lp4cghAMPhv3/8tR9vtvtU/J2ciZqw4IHnvmvx/HyrSfsUy9qVRWnsK6IaG/io0DRRckXLJkCeyyyy7Knf+oo46Cm2++GSZMmABz586Fvr4+OPXUU+1tMeQAv3vllVfgyCOPVH8PPPBAGDt2rL0Nrvh/7Wtfg7feegsOPvhgtQ3fB22DHgQIGhHwWNdcc439fW1trfoN/taPnp4e9Y/Yvn27+otlxn/VDl2DUrkWff1OY9HX318y5apmSq2OCKWP1BmhXOpMv2WFlv6muJyy7ygY+tlpcP5v50BNDcAfv3woHDpxuDLYRLkv0uYIcamUOtPX75R/wvAmGEj1w4AzlI7NyJb6yNv5Xbte9vnEEYOMZerqcbbp6x+IfB/6mFEB6enthb6+2rKpM0nWt6IaBzC2H8MA9t13XxVScMMNN8Bxxx0HCxcuhLVr10JjYyMMGzbM9Rs0BOB3CP7lhgH6nr4L2gYn811dXbBlyxYVnmDa5p133vEtOxoxsLw66M2AXgdChieeeAJKgaXL8AHPPORz570ONSuq1yJYapRKHRHKB6kzQqnXmY5O9Byogfnz34DG1fMLemzBzVK1dlMPuIi4cdEseOzt+PuQNkeotjqzttOZJs6aPRd63s9t3IwL8cMa62Crcuw2eVOlYVgjwIZFs2CmzzO6pccp06uzX4Pupd4yzVuL+854bq3fsAFmzpwZqXybNmfabOLJp56G4e4ohpKuM52d6oaVv3EAwwCIgw46SBkLJk6cCPfffz8MGjQIShn0NECdAgKNDbvvvjucfvrpMGTIEKh20IKFlfy0006DhoaGYhcHXn14EcDaleo1akq0T9+l2EWqekqtjgilj9QZoVzqzM1vPYcuhnDAQQdB+4xdC3ZcwcvsDzYDvPWaen3mWWfFCvOQNkeIS6XUmbfX7AB4I+NBPeXAg6D94NzbsYZJ6+Df7n1DvebT+swTWQPf/eQ0OGN/92ItZ/nmToB5GW26A6ZNh/aDvGEOa1/6AGDZYvV62IiR0N5+WKSy/eqDVwA6dtjvjz/xRNh9eEvZ1BnyYK+IsAIOegnss88+8N5776kLhC7/W7dudXkPYLYC1CZA8K+eVYCyGfBt9AwH+B4n8GiAqKurU/9M29A+TGDmA/yngze1nBuDpCmV65Fm1sCa2rqSKJNQWnVEKB+kzgilXmcoXBXDFKWuFhfs84naunpoqI/vKixtjlBtdYY/N30DNYmcy0em7wb19XUqKwEXJ0QdEBQIDdU0YGVKpc1l6k874330Fopabl1ioLa2vuD3L5c6k2RZiy5IyNm5cycsXboUxo8frwQI8USfeuop+/t3331XpS5EbQIE/y5YsMCVVQAtLzjxR2FB2obvg7ahfWDoAh6LbzMwMKDe0zZC+cOFRiSVoSAIgpBPBqx+poo1rUoG3uXTfREEIZg+JuTdwzIAJJXRpaUhMwX9/BG7RxY75BkFen3UxXm2gjiigvq2qSpuK4pqHPjP//xPlaLwgw8+UFkIPvGJT6hV/PPPPx+GDh0KF198sXLdf+aZZ5RoIGYTwAk7ihEi6MKPRoAvfOEL8MYbb6j0hN/+9rfhsssus1f1v/rVr8L7778PV111ldIQ+MUvfqHCFjBNIoHHuPPOO1UqxLffflsJGnZ0dKjjCZUBf+gllaEgCIJQCIO0TEaLD78H1Zy7XBDiwJ+V7r4clAgNYGhPDSqEAsDowc2RQ336mEEAxQZNcKNBnPZXbxtSVdxWFDWsYOXKlcoQsGnTJhg9ejQce+yxKk0hvkYw3SC65J177rkqMwBmGcDJPYGGhH/84x9qMo9Gg9bWVrjwwgvhxhtvtLfBNIb//Oc/lTHgtttug9122w1+85vfqH0R5513HmzYsAGuvfZaJWCIaREfffRRj0ihUCGeA5LKUBAEQSiIcaDYJRF4/1/N6ckEIQ58It6TsHGAP4udvdH3zZ/fSJ4DzNMgfN/u/aWquK0oqnHg3nvvDfwe0xvefvvt6p8fKGAYpkR54oknwuuvvx64zeWXX67+CZUJf8hlJUcQBEHIJ9TliKdaiYUVVPGAXxCy9hxIMKxA339nb3/sFLG6EYDDP4/lOaAZElJV3FaUlOaAIOQLMQ4IgiAIBfccqOIBZkmGFUj/LwiR4KvuSYcVoNE0G8+B3pjGgZw0Bwaqt60Q44BQfcaBKn7gBUEQhPxDk1DpbYoP7/Kl/xeE+GEFSRsH+GPY2RMjrMAlSGh+lnv6U1k97x7NgXT1thViHBCqMFtBUYsiCIIgVDg0KJW5aPERzQFByFWQMNmwAh7f3xnD8MB/5+s5kErGc2CgituKomoOCEKh4BZAiQEVBEEQCuI5IP1N0eH3oJpdhQUhDn3sWeGr8UnAn8OuGJoDfS7PAXOZuNEgzvNO2zbU1ajjoLEAP5u9bDOs39ENYwY3w+GTR0TOrFDOiHFAqMJsBTI4EARBEPI3GaX5qGjclFhYgdwPQYhEiq3SJ+854DyHHVmGFfT1+4UVZGccIK+Exrpa6EulYNbSTXDFffNhzbZue5vxQ5vhunOmwpkHjIdKRsIKhCoUJCxqUQRBEIQKRvqb0vUclMUBQYi/Sp+05gDPDNCVbVhBhFSGcXQDqG1oaqhTf3/61BKXYQBZu60bvnb3PHh04RqoZMQ4IFQF3EopKweCIAhCvuADUulvio+EFQhCjtkKEk5lyNvIjp7oYQV84h9FcyCObgDNExoCwgZobzc8vKii2xIxDghVAW8gqllkRBAEQcgvbHHLDi8QioekMhSE3MIKevryqTkQx3OA6yAkl8oQ5wXUNKRDtsXv0aMAtQgqFdEcEKrQc6CoRREEQRCqxXNAOpyiw72PK3m1TxBKIawgiogfH5NjtgL07qmpCRf662cPM0+1yOFGg6jtLy9PbUS9QTy/SkWMA0IVpjKUwYEgCIKQH0RzoHQ9B7hXhyAI0doxv1V6HYzFR5f7MBE/rjmAx8H9N1ux/pGzFSToOcC1DJojlANBw0elImEFQtU1cpJaShAEQSiMcUD6m2LD+3w+CRAEwZ8+V7aCVCTDAIr1RRHx05/DqKEF+RIk5EaEYS0NgdvWWAYP9IioVMQ4IFQFkspQEARBKARijC4t+BxCjDWCkIUgYUgqQ2zz0GMgHVHETx+HY2hBFLjngF9YATcaRB3vc0+G5gDPAYo4QE8IPVSikhDjgFCF6tFFLYogCIJQwfAJqHQ3JSZIKI4DghB7Nb27P6ML4AdqDOgeA0Eifrq7f2fEjAX9McMK0DgQxUDLy9NQl5kaf+noiTCipdG13bihzfDLC2a4QiQqEdEcEKoCcfMUBEEQCoH0N6WFpDIUhPhw8T98hHBFvqm+LidxPtrO4zkQMayAewtEMQ4geKi6kEV+Kk99bY3tEbD/LkPhmD1HwaV/nAsTRrTALeceZBRXrETEc0CovsGaDA4EQRCEPCGChKUFvwdirBGEaOgT+KDQgqjifLRdf7bGAZ5e0WAcwPG9rkUQxSBIWgY48a+3Jv/YVpDX8dghTXDUniOrwjCAiHFAqApksCYIgiAUXB1fJqMl1f9HVS8XhGqHx/cjPQG6ALiijiJ9NRFF/FKaIGFnb/ywApPmgEmkMIpxgHsO1FopFbGt6LWOR6EG1UJ1na1QtYibpyAIQmW05a8s3QR/m79K/S1FN3G3IGFRiyJ4UhnKDRGEKOgT+KB0hriijiJ9UUX8+CQ/jucAD3XojWociKE5gOWrI8+BgTT0WedcbcYB0RwQqgK+WiDGAUEQhPIjag7tYiOT0dKCd/mlaEwShFKkzxNWEDyBxzYYxfqu/vMC2NbV5xLx09tofcIeNZUhL5NJc8D0Gc9EEOo5UFdrGwfwM/JOqDbjQHWdrVC1uNWKZXBQbPAevLpsM8zdWKP+yj0RBCGpHNqllTqvmCUR9IlI1LznglDtHlV8lT5KOkMEDQCXnbSn/f7cGbvCi1ef7DHe6uXriBxWECxISJ81MAXCSJ4DKa/nQL/LOFAdWgOEeA4IVQFvUGSwVkqrf3Xwv0teK8nVP0EQSoOwHNo4bMPvT5s6riQEoySMrbSQxQGhksmXR5Wuz4HpDKPAQwSaGuqMbXK2goQ8HAH3gZ5ZtWz/ZBzArAr9A/3Ka4jEBiNnK6hxBAlFc0AQKhjJVlAalNPqnyAIpUHcHNqlNBmNkmNbyC8SViBUKvkcU+m6AGFhBcTObscLYOOOHuM2uqt/1LACXVPA731jfa0zyQ+3DbiyFdTZYQWO6KEYBwShAuFuRbKSU5qrfwh+L4O3yhFmK+frJde3dIibQ7vYSHac0kI8OYRKJN9jqjipDDk7e5hxYKfZONCfdVhBOtA40GOVsQmNA3Z4QEzPgVoyDgzYXseN9cX3SCskElYgVAW8kZOYw9Jf/cN8skL5C7OV6/WS61taxM2hXWzEGF1aSFiBUInke0ylpwqM6jmww2Uc6DVuoz+HUT0H9Ik+ZRMgelMpx3PAzjoQZb+O5kAt8xygtlw8BwShApHUUoUhaLW13Fb/ShUJzcjv9Sqn61st3g1xc2gXGx66Vpl3pLzgj4W+YikI5Uq+x1T6sxKUypDTEclzwL2vjqjZCsI8B6wyNvKsAxEG/Y7nQK3yHqDfVWtYgXgOCBUPxnzyNq5SB9DFJmy1tdxW/0qRchNmK7frVU7Xt5q8GyiHNhpnouTQLi1jtPQ3xYbfA9EcEiqFfI+pPIKEWWgOoNAgGgtam+pDPAf6Xd+htwMaNbDsaPT1CxHQMxbQe+45gOEBsTwHapzfkWdCtRkHqutshapEb4TEzTN5oqy2ltvqXylSbsJs5Xa9yuX6lpN3Q1JQDu3mBvewBXNo4+elZBBxhRUMVKe3RykhYYVCJZLvMRXF21tz5ejGAeY54Oc94JetAPuuY295Gs6/cxZ8/d756i++pz7N4zkQYBywPQAiODyQAaG+zixI2FhlqQzFOCBUPHojJGOD4oji0OqeiVJc/StFJDQjv9erHK5vNQt7ogHgSGugO333oXDPpUcac2gXG24Q4MbosIGvkB/4oyCeA0KleVQhNXkYU9HYua2xPlZYwQ7mOeBnHKD+iQwPGFYQxejN05IHZiuoq7U9AKIIEpLQIV6retIqkFSGglC56J4ClThoLiZxVltp9a+1sa7kV/9KEQnNyO/1KofrWy7eDfmi2xqgjhsySIlslaIx0S1IWL3eHqUYViD9v1BJ0JgKx1BJj6loIt7WXJ+V58AQ63cbdvT6Gh4GW+EGnT19kYzefp4C+vu4goQ8W0EthTCkmOZAfXVNl6vrbIWqRPcckLCCZIm72oqd1flHTFCvd28dgLsvOrQkV/9KEQnNyO/1KofrWw7eDfmEVK1LuR13CRKm01Xt7VEK8OsqgoRCpYFjJxxD0WT88pP2TGRMRc8K6QVEMQ5ge0fGgcmjWtXfDQbPAWojBzc3qL9bOvsiGb23dfUFGgfIu6Gpvi5WKkOuOVBneRwMVLEgYXWdrVCV6G6EpTyoLEeyWW2lWzCsEeAIJjYjRHcj1JHQjNzdLsvh+paDd0M+6bIGqKXcjvPJKJaz2r09SiqsoITrjSBki5rUWv3S5FFtifRR5GrfZhsHwifZODmn9o+MAxt3+GsODLYMGtSuh+EXRmC/t40DzHMgZraCOltzgBsHqmtMJcYBoQo9B4pWlIokm9VWaoijRbAJJjdC6rAJCc0Ivl5jh0Rzu6Ttyd0xbPtCUw7eDYUxDkDJoocVVLu3R7Hhk4Mo4mSCUI7QuCrKSnkUaD801ujpT0XWG8DF9wkjWgI0BzL7HjKowegBEBWavAeFFZCRI7LnQC15HKSht180BwShItFdNcV1s/iiODRYk1uRHThBveDITGjGPmPbSlaYrVTA6/LsN0+03//oUwcFXi/8/JLjJqvXg5vqSur65luEqtQpt7ACLGe1e3sUG15XSrneCEIuUNUmEb1cccIK6iJ7DlBIAYoYjh7cFJqtgEIhMAvBuCHhRm9y+UfBQaPmABMkpG2jZCixsxUw48CAy3OguqbL1XW2QlUiqQxLTxSH7onciuyhaziytalkhdlKCVJFRg7YbWjo9aJmA/+W2vXNpwhV+RgHoGThg1F8We3eHsWG9/lRVhEFoZzrua7on3tYQUNkzYGdlucAihiOaiPjgFeQMKWFLCBXn7VfqNGb2tZBlqi1nkGhx+A5EGVB0OQ5kEqnbe8JCSsQhApDjAOFFcXZw4ozu+iYSb6rrbbnQMFLWTlQvl/J2x0NfpniqBejOj5XOy+1523fsW3q/cen71Iy3g35Au9DJ4UVDJSP5kC1e3sUG15VpL0UKr2e6672ubZjbeQ5EMH1f0dPnz3pH97aqF5/sLEDXlm6ySgMimKHZLg/Zq+RxhBA3A8ZvclgQRmvaBwUFFYQxThgaw7UOYKESnPACisgT4VqobrOVqhKPMYBmZHmDWyMyaI7aVSr72BXPAdyh9znSnmSVMoTtjD6rIYiI0pUmtcYny9SksYBVaVPLnFViG5dKRt5ednoZTV7e5RUmIe0l0KFQu1OUv1VXxapDMlzAFfc/+1Pr6vXmzp64fw7Z8Gxtzxtp2yl/hjd9Vsa6myvMGwHn/7PE1z7PGTCMBg6qFH9hsY9LVa/581WkLIFCTFEgB8rCDI61NXW2qkM+fGqLazArbgkCBWIpDIskihOQAdFhu2BdGVPZvJJn9UpSn3OfsIWBLk9It39KbUSUYpQMXXV5kqED05Lud7zW8HLiQPf06aOg0NuegK2dvXBFafuA5efvFfFG3VKSpCwhOuNIORCOmHPAT2VYU8U44ClObBsY6fnu7XbuuFrd89TxlDuxj+osR46elPQ0ZPZv/6IPvH2evUPQ696LN0D8hzo1UQSuecAn+RHz1ZQ4xgVeCrDEu3/80V1na1QleiDyFIeVFYCUVb2JKwgd6jTKtFF7bJ3LeZGxSgrJsWCVkKTGhCWMp2W3gBSygvAbkFC93c8pnXvscmkHBNiPPulXHEEIRHNgYQECa0+hTL36PH9JnZ0Z8IKTFCpbnh4EfSlMm05TsRJ8LCrL2NYIO8Ck3HB9hxotDwHArIVxPIcYMaKWvpdSlIZCkLFojeUMjbILzTxCmqQJawgd8h1UNxks1OQD4Ong+ruHShrT51KgefCLuV67xYkTPsORGWiWoxUhnLNhcqE2p18eQ5EMZK/vWZH4Pe4xzXbumHV1i7Hc8AKK0DPAXw+b3n0Xd/fEi2NtWbNAZatoDbbbAU13HOgOjUHJKxAqHj0iYAMDvILDdqDGmT6Tm5FApoDYmHJIqwgupshhRUUCjzu7GWbVc57TG2HCvZBq8t0XtUQVkCZCkq93ofpW1AbWcrnUElwQ5L0/0Ilgn2aE1aQzpNxILyP2WRIW2iCQghwMt5ihQigZ1im7wvfR5dVFt2bgTwHlOZAXXaeA/UslSHtTzQHBKHCNQdKUXm8krBDBgIaZHtwXLBSVXBYgQx2I8EvU5RLxlfiCxVWgO6U6HKJKysExlmikr2fYB3d/1IVTcyb50AJn67bOOD9XjwHivnsyzUXKg9erRPzHNDCCqIYyWt4zuAAcPJOAoBkHHjpvQ1KeDAKNI7XBQldmgMs60AczYFayziA7TRdSzI0VAtiHBAqHr1hEEGi/ELXVzfKcOg7uRXZQ52WDHajwY2CcVYS9BXrfBoGUKwpHSDiZDIQ2M9blXkOpMvYc4C+F+NAYeD3IKhfEoTKqOO59wW4gEOPSpywAhIK9KPGytAywkpz+P7GnTDngy3q9R9nLY9cvmEtjUZDiB1WwDQH+mN5DmAKROea0v6rLaygus5WqEoklWFhoesbyXNAxmlZQxZyuYbR4EbBaJoDPKxgIO9tFHoMpENEnEyTyWoVJCxlI29YZgwqewmfQkXB70cpa1UIQrbwat3bn3sd5/2fk8oQU8kG73sna6P1tXZ6j55wtPu/zV8dSehQZ4/RreZUhla4QVN9nR2ONxDHc6AOBWNrPWmMqy2soLrOVqhKdCuqrLTmF7q+kTQHClaqyqNXBAljwS9TpFSGXJAwz2EFGGfJQwn8RJxwO79BHNWHqkllWMKNR5DnAA6ubc8B6YsKAq8r4q2RP/DavrJ0E/xt/ir1N5drneS+qoGkPQf4PtoszwEkbCLfYaUyvOiYScpDgIPvyQMuF0+3Gp6tQDcOsJV+Mg5Eyk5k9Z8qm0yN43HQW6WpDCWsQKh49HZSjAP5xXGZDd9GbkX29Fmdokww8iNKxmP4820cQPHBbLej8+qvulSG6bL0UuF1TyY8RchWUML1ppzJRi+lEPuqFpLWHOCeAxRWQMaBZiu7gImdlnHg2L1Hwf87eyp8/PYXYcGq7XDZSXvClafta0/Y10UQHdQZM7hJiRXiRJ3c/INSGdrGgYGY2Qpqnb6V+lVJZSgIFYZuRZUBWX6hyxs0eLdFC00ut7JiEAnRHMjBtThutoI8GwcwK0G22yWdvqpcBAlLudpzQ5RezrjhLULuSFhBYfRSdO8n0kvxy1uf731Vax1PQpyWC/JiqkFKmNMT0hfu7M4YB9qaGtTkfFRbk3o/cWSrK+tOV29muzBO2W+0+jtt96Fw71eOVK8bamvsybrXOJBixgEnPCCqMaReaQ7U2n0q/bTaNAfEc0CoeLxunUUrSlVd76C869RY69MZWTHIwjhQ+XPCooQVuDQHIqRwygVMV4j1HAfA6QARJ9xOh8ZG1RZWUMorwHy86jEOiOdAweGXWQQJC6uXgm0Xfn/a1HGBKVmT3le1wdvDJLzIaFENPezxWqO3AHpuhfWFOyzPAQpF8Jug4yQ8CvvvMhSeemcDNNfX2c9xfV0tNNbXmbMVMEFCWuxPxdYcAI8xWjQHBKHC0CepslqTX+yJf5DnAIkWsk1kxSAetDogE4z8eA7wARYfJOQDHHyhAcwEF3EyDYgdY1zlW4k62WpTKbfjQd4BfHIqj25pPvtCYfRS8rmvaiPNmv8kPQdI8Z9CCcLSGZLnwGBLxNAvY8AQ6/sg0DvggF2GWscdsA0W+DlO/nXjAI6F6PjvrNkeK5Whk62gxv4dN4SIcUAQKgwaDFAjVcorThUlSBjQINtq3QmotVcrZCGXwW5+NAfcngP5T2WInjEo1tTaVOcr4mSCzqUqwgp6nXMs5WrP65r+fLq+k/asIPDLLH1I6eil5HNf1R1WMJCgcSAzTWy2JuNBfSEaqMmQbnsOWMv3Ka1MUewXuw0fBC2URrE3BX39Tpl04wAuHh17y9OwpbNPvf/WQwvhkYVrM+UaSIeGq9qeA0pzoMbgOVBdnioSViBUPDTIR8tf/0BK3LDzDA14A7MVaIKEcVYMjtpzZNJFLktEcyAefCwQZX7ABw/59hwg0ADw8tJN8L+vfKhWVn71hUNVKEGQC62TyrDy60FXXzl6DvgbncRQXQzDYFGLUnHkopeSz31VG4kbB5hAH/aFtPu5H25Rrv6mPqmDCcaSiKGf5wD1r18+ZhL8ee5K2G6t+CPDWhpga2efus+DGi2jRH8K+shzoL4GGq3JOp4reZ3qrSn128+8sw7unvVhYLgq9xyos8pMhhA0DNRY3gTVgngOCBUPNUJk+SvlQWUlYKcpHIguSCgrBjlkK5CVsCxyz8cLK6DcyYVU5EdjJhrCQuN0q0mQkA0+S7neuwUJ/T0HSvkcKjZbgawO5EUvxa+Vws/H++il5HNf1UbSuhq0D3x2cEV+zfZu24MT35vCPClTAa7q08q+X8YAej9jwnC4+qz91OsDdhkC91x6JHzn7Cn2fposbQFs+8mboYF5DvT0p3y9TonXPtwaGq7qylZQU+Pq96stpACpvjMWqg5qhKgxEeNAfqE+IDCsQBMklBWD+IjmQC5xx1ByYQV6nuioq8pVFVZQJtkK+DMZ5DkgYQXFSGVY1KJUHFwvpSamXkrQviDHfVUb3Aipi/RlA03E0Rsgqg7UNsulH1f1yXU/zHMAv0exQWREW5MyiNMzit8NarS0DvrQOGBN4FFzoC7zOXoYBHmd+qGHq9L5ooBinVVmCt2kc6gmxDggVJHnAKmmFrlA1RJWEME4QP2ZrBjEHwhQx1XKk6RSgi8YRpl4FyOsgK++pCLOYmjiUw1hBeRVUc6ChK5sBSV8DpX67ItBJn96KaiPEkcvJWhfumBdNvuqJpL2HMAVeT9MOlBoKPjCb19Vr3f2pOD8O2cpD4PVW7uN40EKW8CJeIOtH5ByGbpxzG4LIfYNQB9LN0iewD05GEJ4uKpJc4CghcVqQjQHhKozDkRxKRayhwa8QQNfPayAVgzQGq0jKwZeJG45/2EFfCW+kJ4DNAGOOsCrJs8BVyrDEp7kuQUJo3sVCIUIK5CLng9w0o4pBg++8XEVP/71U/aGfz9l76z6bNzX6q1dcOM/3o6svVLtJK058ObKbZEn1tu6eo0x/+hhQKv6fp4DeE8brbE5Gbjt8IG6WhhkGQdwMYQ8Ini2giSMxBiuatIcICSsQBAqWpBQshXkG5x0pbMIK+ArBi2WGxkhKwZeeOcvg938pDPj1zUst3Newgoi3Fd83mizajAOuD0HoGRJBRiiJKyg8IhxoDCoNHDWxGqP0a05Teb5wkEU7ZVqh9drPX13Nmzq6I203dptXaGZppC+lNvAzifjTVrmAcdzoAaaG5xp6o7uTNhCfZ2jOUBepbnUDgxXtT0H6pxUhoQYBwShggcG9IDLgKxQivBBngPe7RE0AHxs+i7q9e7DBylxmhevPlkMAxqU0gcRW1cWxoEI8+j+IocVkNtlEPz5qYawArfmQOmeL7fTSFhB8eGPhlzz/ELhULkaYShsLomJbjXAqzVdu1wYYmUbCGNzR2+kmP+VW7pc71OuEAHyHBhwlV+FFVh6BMgOK6MBGg3IoIChBn46FWHwcFUe5lCvpS2stjSGiBgHhIqHOhfHDanIBapgXAPfGJoDJvB+yYqBGd75y2A3i1znkbIVONv0FEGQEMsbNgHWn7dKN3xiruty0BxwZysICCuo8PtVKvDnSDwH8gsZVXONe6f2N4mJbjXA20OeaSdb9hrTFmlijSKCUdjJUhXqngONmucA3Xv0EKhl35PhHI0GtkGhf0AtHv3o09M8x2wLMHDo4aouzYEa8RwQzQGh+jwHSnhQWS3um05YQY3vdzxtmeBGwgqSTS8Xnq2gkGEF7rh6fRWDo7dlmAe6qdYdllNJdJaJ5kBkQcISPodqDikSooH1F2POMWYbXbNxBZbqdK51m/q4agiXSl5zIPc6PsCCArAHSvtMrIcOaoy0P13Uj7vxUzaAXu2eY9YDpLm+VhkOtlNYATcoWNuOGZIxUowd0gTfap+i6uOs9zfBbU8tgeP2HgVvr9kOG3f2usJVsfzkleoYKzIGiaCyVwNiHBCqTnNABgfFNw64Xbz1wXPhXbnLDX3AhJPdGs3aXalgdXl12WbY1NlvD0ijeJe4J2zhx+H50AtVF3EAxFfKsO1iXpUe9GcMB4URvUHLEm4wLOVmPMhzgIeLiNdPYeDNpbipJwOq02OsOXcpx5Vkqt+5rl7TBBcfJWznxIMwTohZ7gYVuv6TR7Uo4zi/z3xijfcG7zuKDwY9WaM0DwPuxq97DvCwAgTTGaLIJXkfKM0BJmKI3gMPv7Favd9rdBt85KBd1H7nLd+iPttl6CC48rR94BO/eFm9v+OCGUo8k9cp7jlQL4KEYhwQqi9bQZR4YyEJ123/7YLibslwwMXHBDd65x+2wlwpPPbWOrhhXh1snfWa/dl4bQXAD17NohgI+SSiUNkKOnvdrpdhq2/6s5OEO2mpgteCp60qZSNvkOeAO2tGQYtVtXBPoVKuN+VkGPBTp6fPcg0r4H0cvq6rYI+opOt4EsYB6ntwUn/vV46CB15bAf/1lwUqewTqQNHEOizTVNovawuFDriyFXjDChBKZ8g1Byj9IXLcD56Gtdt71OuXlm5SKRSxTCQsiO0x70sPnjDcY2yiYypRzRrRHKg+c4hQdVCjQA2QDA7yR9R42mDPgcx7nAiI262ZXiZIWC0rkDgg/bd734Ctvd4BKQ5M8PsggupceFhBYYwDFFMZ9b7q51HJ8bn6PSjlpiEoXSE3Okn7VhgkW0Fy4PWLpk6fW1vEDZ0SWhBXDDp3PRO65igYiBPmk6eMMfZRPNOUHuOPHgYftwSmuSeeem89kybPAT2sgNIZ0rGxTDSeR8gwoI8J3lu/Q73Ha0H7zpTFe21cmgO14jlQfWcsQLV7DlTDRKpY8A4piuaAeq3H5LL3hcwvX95hBVBFA1J3x02njt9HrXPRwgoKrznA9QZUGUJcoE1hBZWKHtpRyu14UIy7ZCsofTFSwR/UGIiiTr9sY0dOx+llbZmEgoTj6QtydJHlmgDIiJZGwAV1/BgzFJgMBF86eqJ6jTH+lGlq6i5DjJ4kpmwFuuYAfd5kew5QKkOvaCCHjvTEonX2sXtCdJpc2QpqNc0BMQ4IQgUbByzrJI4NSjkNVjUJEmZ+o+2DfSChBdHDCqp5QIpnj9/jdkmFFfDBFQ5aCnGN9VWZMNfcagor0AVKS7kNTwVlK4jpwSLkDr/Ocs1zA8UHo0Au4EmFFQjBeMRpczSo2K791kQZXfzRQIBs3OleqSfSLNMBZZpCgT9E7z9N2QqwzNiu92lhBYMaal11Cifrr32Y0RPwA/eAOgXq2Gm354Cp/+fGkFrNOFANIZs6YhwQKh4ajPG4IRkf5Ac+8A1aoXG5wPlYlBHJWGBGdx+v9NWwqAPSoO3cq7nB+8E6qV/SQnixxNUc0BeHKnkQrXsOlHIbzm+DPhDlBp9KN+qVZJo3ueY5gSKwUeD56bOBGzorOVwqKTzCp7mGddiT5VqPqKCfccCe8LNVfTIueDwHuOYA0w/Ae+14DtQYNQdwsh51TEDHCgsr4NkK6iSVoRgHhOrTHEBEdyA/8MlKtmEF/N509uW2+lCp6KsC6TIfO2F9eGXpJvjb/FXqr153og5Ig7YLMkjpmCYQhTAOdMTUHNC/17UoKgnyIqKB5EC5hhVwzYESPodKIs6zLwSD2WFQBDZsLXXcULc6fS59nIQVhKO3M7kaVMjNnrvYjxoc7DlAzxaP2afXeoicy3OAjc1V9gHSHLDa+kF6WEFtbeQxgclzIFRzoE7CCiRbgVDxUMfCrX/YEFjtjVCEfNJBrrX8rXgOmMHUPZxynmT4pcTiGQhoQOqXLqnGEj/C7aKFsoQZB7wDq27tmueDnXE1BzwDrjK3EgVAbQGKXm3u77XDw0oxhWdQ2BR/Vsv4sS0rROchOYLU6Tm52mBKMawA6xGGruGqdZw0uoXA46GUo0FFd+13eQ7s8GoOqGMajAOO54A5FBK35WNznMTbx7ZCEshzgMLu0KMArz3u2q+e4VGHDGqAbV196ljcWGJqA3jZ68RzQDwHhMqHGk3+gMv4oACDsKBsBa7Bmv8+xDhQ2ZoDlBJL1xPQMxDQgDSD+1ypG8fvgwZq7nRmENlzgFYtClEXdc+BsMm+PsgplUF0PiDPjdYmx6pbqtXena7QP2yqXJ/bcoPfgwp+RAoGqdO3NrpXWMYOdrwFkk1lWPznBPsiTJF3/p2z4Ov3zld/8X1YlpxCoV/uXPuClMlzICSsIMhzQK8P3DMho01QY5fbL6yAdoEGC9x+uKWBoENHdzIlON4I9D5WtoL60jAAFRIxDggVDzVC/AEvZZfUqhAkDNjOFVYgxgEjustgKYuz5ZISi2cgwAHp/3x2GgzVxgPoMYADVfIyiJbqKfqKfFtzfeHCCmJqDujfV0NYQWtjfcm340GChC7NgRItf0VnK6hg75pCgu3tpw7dTb2eOn6wUqe//6tHJbZyzZ+TYhs9oxqxi4k+BsjVoOKs3nuNAxt8jAPUntVyzQFrgq+nuaa3NBEn1/2M54A7rKDZEiQkGqzfDB3UYCwHjQkOnjDcPrZLkNBQnUijgRsqqtlzQMIKhIqH+hUeNySDskIMwtK+nViQcrzLc0BSGRrRO/5yrM9xMhCg8jFyxv5jYcd7KbjmtUzXdeVp+8BlJ+0VybUzjko8ZSrAMU6LtTrW0196mgNesbvKnfhQW9DaVPrGAT6x0csoyvmFJ8gYLWQPXdaRbU2qjV6+qTMxIwyfzBXTOBBmxMaeB78/beq4ooYYJO85YAorIM0Bc1gBX30nKFsBNxbx55FCB9BLoKuPBAndYQXkvadP1rmQ4YwJw+HCoye6wj3+/sZqu1w9XHMgKFuBQZCwUYwDglB5UCflCiuo3DF0ycd26oOzoPcSVlC5YQXZZiDgNQJTJkUdkMUJK+CDHCesIP+NRoemORC2+ubJbV3BPtNdllcFGWuQUrWFuAwAQZ4DZfjcliNxnn0hOjSJo3rMjZO5hhW4PQfSZWXELgaeVIE5pzI0CRKS5kBPYBl4KkD6vV84FYn/NarsFv0uzwE9rMDep8E4cOxeI+Fj03d1b8eOHTlbgSGVYYMYBwSh8qDxskuQsERXnCpKkNBncBCUnUB/r6d2E8yTwFKdJAWRbQaCPnaucQagUcUy+cAKDQ9N1sCkEGEFJLiURFhBKYtn5eI5gIKEpe454PJS8XhGBefbForj0SbEh+oytcNJ6mmUiiBhEml0ixFWkGu2gj7bc8DpM0ZHTGXo9hzwChLyfpu2bbSOg5N4W0Rcy1ZAoNEA6xfvk/cdO9hTHgpvUNkKUsHtru71UF9bY5dTjAOCUNGeA6I5UFDNAZ9rrE9k9T6MDyo6JazACLeCl2t9zjYDAT/1OK6rQbnndexBQW0tNFsDlO4ihBWEGT/8wgqiZIAoN8hzoxzCCrhhVC+iux4WsFBVTFQtHCEe/R7PgXRingOlElaQRBrdQuDxUEoqrMCgObCpo1e1cfoKu0mQMNRzgIwDVj/rEiS0sxW4J+eL1+1QYpC8f7v+4UVq1Z/3b06mBLfngO5VgYYVPdNCLUuFIIKEReS///u/VUqib3zjG/Zn3d3dcNlll8HIkSOhra0Nzj33XFi3bp3rd8uXL4ezzz4bWlpaYMyYMfDNb34T+vvdA6xnn30WZsyYAU1NTbDXXnvB73//e8/xb7/9dpg0aRI0NzfDEUccAbNnz87j2QqFhNoBfOipzSpmrGdYTvdyxi0647NNQAxu5nvndbeEFVSs5oA7AwFEzkDAPQfiuJvG8RwgowMONgY1FjBbgXaMuJ4DOKgqB/GsbOjs6zd4DkBZew5UUttfykgqw/xAE6p8eA4EhRUUcgxFRmy/6SF+Pj4kjW4hGEhckNAKK2Cr5iMtzQG83ltRIECDDskFCU3ZClzGgRq3cQAn8b0hYQX3v7bS07+hN4Pev9GxB3RBQo+3KngMCnXsHKpRc6AkznjOnDnwq1/9Cg466CDX51dccQU8/PDD8MADD8Bzzz0Hq1evhk9+8pP296lUShkGent74eWXX4Y//OEPauJ/7bXX2tssW7ZMbXPSSSfB/PnzlfHhkksugccee8ze5r777oMrr7wSrrvuOpg3bx5MmzYNzjjjDFi/fn2BroCQT+yBPlMhLdaYrNTT4eQKb3P9xNE8GgMBxgLJVhA1rCBdUSmxgjIQuD0Hop93NqkMcaDQrGIh0XOgEJoD8cIK9EFOT99ArAwQ5QQZCt2aA6V5HkFeKi4DqkxUCwK/zOVY90sV22PAqvBJZhjwCyso9BgqWyN20Y0DA8l7DqB7/bCWBt/QAjv9IfPSJVFB/tzR2BB3Td4H5LqPhgE9rEA3DkDE/o0bJoI0B/hYlX5Tb/B+qCaKbhzYuXMnfP7zn4c777wThg/PpJ1Atm3bBr/97W/hxz/+MZx88slwyCGHwO9+9ztlBJg1a5ba5vHHH4dFixbB3XffDdOnT4ezzjoLbrrpJuUFgAYD5I477oDJkyfDrbfeClOmTIHLL78cPvWpT8FPfvIT+1h4jEsvvRS+/OUvw9SpU9Vv0BPhrrvuKsIVEZKGNxTonaI+K8KgrFJX9DjulQPzNh5PgYD3ElYQ0ThQxuNdNAB8coYjJHTJsZPhxatP9nV/73MZoOJ4DkBszQEc2JDnQCG8WOIaB/RnbMn6HZHFs8oJvA4fbOqwXVpLfXItgoSlRVDGCCH3fiiVD88BtvJNxynWGIqM2MOtiXHcNLqFQG8K+3I0ZusZA4gR1jX4u8FrwxYkjOg5wPfNPQf0sAJdcyBq/+byHGCdpT7+54aDeR9uUeXjIRNkpKgmiq45gGEDuLJ/6qmnwne/+13787lz50JfX5/6nNhvv/1gwoQJ8Morr8CRRx6p/h544IEwduxYextc8f/a174Gb731Fhx88MFqG74P2obCF9CIgMe65ppr7O9ra2vVb/C3fvT09Kh/xPbt29VfLDP+q3boGpTCtbAbyYEBIINmby/ep8JVf2xsrv/7WyHpcN6CE/ceWXQLdC70sPuNVmTT/e+xDHdEr/bMDDArbme3PE8mujWhxp7e8r5O3NhRA2kYSPXDgGEujufYP+A8H719/ZHPG7cl+vtTgb/r7s18h4sZtFDd0ZP/a7yzu8/zPAUdE58dzmafFFM6a7Z2QF/fECgHHntrHXx35juwdnumv71vzgqt7agtub6Ir0Shxwo/di8Le8QV13J+bssFfaLa3dsbWWQsav3BY7z24RZYv6MHxgxugkMnDi/rvjwKfamUEyfe16f6Ifu7kDY2jF6m8YL9XXdPb6Qx1HF7joDXV2xN/D6csu8o+O5Hp8Jl974BTfW18NsvzrD3rZ9nMdoc3q5QH5bb9c/srxacNgrb4pVbutTrnz+zVP0bN6QJvt2+n0ozTGPtmjRr19IpT1vX3ZP5i3N/+oxW57HcNFmvSWfqUH1tPEMT9W/pAad+9rD+n48b8Jxu/Oc79ncX/m6OOieu2VAL7jY8HyRRZ5IsY1GNA/fee69y48ewAp21a9dCY2MjDBs2zPU5GgLwO9qGGwboe/ouaBuczHd1dcGWLVtUeIJpm3fecSqMzs033ww33HCD53P0ZkCvAyHDE088UewiwJp1OAiohbcWLoCBFL6ugaefeQZGFVA/Zsm2Gli7vS7E4tkDP7/vUdh7aPmuaizb4TQrPT29MHPmTM8223rdTc+sWa/Cmrec77eq65TpKN5fsQpmznQmA0KGxR9k6jTx/AsvwLI2KFuWsfOZs+h9mJl6z3fbPmYcWLDwLZi5eWGkYyxYi7/LPINL318GM2cuDa3HPV1dsGYl1r9aeOudxTCz079PSIItOzN1v7E2Db0DNTBr9hzYucS/PXh3m3NOyPo1WNbwVZb335oPM1e+DqXOG5tq4K7FVM9rPNOB2x54Go4amy65vmjHDqcNS6UGXO3golXOPdu4abOxjRSSpT/l3A/knzMftY1+UQmqP1hP//JBLWztdY4xrDENn5w0ANNGlm9/HsaatZl2e/uOnaoe4ziH6vbqtetyqtud3c49e/2NN2H14jcjjaGO+N4TsLM/P/cB7zOe38BACja9PQsee7t02pwFm919wWvzXof08uzPefnyzL1dsvhdmNnxjm9bvHZ7N1x+73y4aJ8BWLseP6+FhQsXQNv6N9X3H1h96Y6dHXZ92KDsC/Vq8k6fbd+SOd7sua9DV3dmnP7ySy/A0kHucWUUqH9bup2OvRNWrNrhjDHmvAbdS9OB58Q/W7TgTZi59g0oBLnUmc7OzvI3DqxYsQK+/vWvqwuBIoDlBnoaoE4BgcaG3XffHU4//XQYMqQ8VmTyCVqw8N6edtpp0NDgdsUqNA9smAuwdRMcPH0aPLzqHejp7ofjTzgBJo1sLVgZHn5zDbYwodvtsf90aD+o+C5q2TLngy0ACzPGvtr6BmhvP8OzjXIJnPu8/f7Qww6Hw/YYZb+/bclLAF0ZF+KhI0ZDe/shBSl7OTH74bcB1EQww9HHHAMH7joUypWnHlgAsCHjEtrXPBTa24/ybVdev+dJ+/0+++0H7cdOjnSMTbOWAyzLTO4nTpoE7e37+W77KrolLnwNhgxugyl7j4Hn1y6DXScE/yYJvjkHz20Ahrc1w7rtPTBjxiFw6pQxvtsPfm8jwKJ59vsjDtwXlnatUL/1zwDRBJefd3zJr2riSuzNt2I7YUqblSn70xta4PoLg8+lGH3Rre++ANCdWWFL19RAe3u7/d2yZ98HWJ4xfg0bPhza2w8vSJmqmf949QmX3/Vpp5/uynoRRFj9wZXH373yhud529ZbA79bXAf/89lpalW1Erlv3WsA2zZD06AWaG8/Dl58bxPAornqu5Gjcuu7vzXvKbTqqNf7TpkKI1obI42huGEg6ftQs3AtwOI3AWpqjWObYrY59YvWAbzrTGD3P/AgaD/YCdeLy+P3vwmwcS0csP9UOOPICYFtMV7xR9a1wJ6jWgG2boaDp02D9oN3Ud8uXLUdfrJwFjQ2D4L29uPVZ0s3dADMfwmaG50x4kOb5sG72zbC1AMOgr8sfwetqnDKSSfChBEt8Nbq7fDThZlw8iD0/g09SH721mxVP4ePagHYskltN/3gGapfDetfiMMOORjOOmAc5JMk6gx5sJe1cQBd+VHwD7MIELiC//zzz8PPf/5zJRiILv9bt251eQ9gtoJx4zI3Cf/qWQUomwHfRs9wgO9xAj9o0CCoq6tT/0zb0D5MYOYD/KeDN7XYk+FSohSuB3kUNjbU27FQtXX1BS3X+GGtkbcr9vXKhZraOtfg3nQutXVu16eaujrXdnyQ1dNv3ke1owsR43Uv5+vEIwiWb+6C+vp6Wx8kSHMgDbXRz7vG8bSoqQn+HdVjdD1uacpsh5n09N9gHcf4RsxxjamsULE620k3uj6SO+WwQY1qgg8Ry8mvx/Uf3V/F32Ip0kbxrP2huSmjOl3KvLZ0kx1K4Ae6Dr++cgcctefIkuqLuBc7zknd7RtPqeutU6VGknW8WOgxxrX18ft/U/3Ba/O9R94NdHXH7886aNeyu2ZR6LdOHGO61bVhMeTYkuVSt7nmALZrUcdQ+bwP1N5iPH5QH1WMNqfW0Bfkcmy6+k0N9aqNDWqLyWtjZGtmTtTU6DxfTY0NnvEgXUfUHKDPmhsy09EU1Nhhhi3Njer7wS3euVaU/q3J2jc+/i75qtra0HPioBGjUPcxlzqTZBmLprJwyimnwIIFC1QGAfp36KGHKnFCeo0n+tRTT9m/effdd1XqwqOOyqwq4V/cB88qgJYXnPijsCBtw/dB29A+MHQBxQ75NhjzjO9pG6FyBAmLlcqwXNLh5ApXhPcTfdRFdIMFCd1xdEIGLq5TysJsUeHiSTu6+2GbIU1SrtkK4uQ65zmPKcdytyaOmbRqNhcjHNxcH0lwUW/HcFBF4lkollWq4llRwMloktsVEv2+uDNllE+2gkrIroPXXr/MSfX/aDSpRAHQqFA72mf95ddVzyWfiw4N9ndhY6ggkroP7mcXSgq9PLlni7BEA+tqIrex3ZanBxckpMwFpmwFdQbRv4wgoZWtoM6creDrp+wdqX+j/ad0QcKBdKx+o0EECQvH4MGD4YADDnB91traCiNHjrQ/v/jii5Xr/ogRI9SE/9/+7d/UhB3FCBF04UcjwBe+8AX4wQ9+oPQFvv3tbyuRQ1rV/+pXv6o8Ea666iq46KKL4Omnn4b7778f/vnPf9rHxWNceOGFyiBx+OGHw09/+lPo6OhQ2QuE8oenZClWKkNKh4MreqWcDifR/N4+F9mTujAg1ZekMjTD1XVLcaASF30gs3xzJwxrMa9u9w1kl60gHStbgZNn2c5WwIwDpJqt74VUs7OZhO+0jAOo2kyDofBsBeb0VXjs06aOg0NuekLlo77wqIlw7Tn7l1X7gqvUSW5XSLxtHObNLq9sBfmo48XA9KjHaTfybcAqZ88Muo52SsOE6jb+lv8c+4egMVRUcjUk8nPKlCmmcEUhUxnmaJyhc8WMAVHb2DrLKMBT/wVnK3C2a7QMAV1MbNkvWwF6iv37KXuHPjd+qQzxWo0bMijSOfGyVRNFz1YQBKYbxMwB5557rsoMgFkGfvGLX9jfYzjAP/7xD5WdAI0GaFzASf6NN95ob4NpDNEQcMUVV8Btt90Gu+22G/zmN79R+yLOO+882LBhA1x77bXKwIBpER999FGPSKFQntBAra621kllWIRBGa3o/cf9b0AHm/SixRM7vXIYaIXhSmvjMwHzegr4d3JdYhyINJku5UlGFPTB+l/mrYSOnpSxw+d2Ea4oHMtwFXK5XJ4D9WQccNJ2YS7lYNXsRWpyHmeQT4awtqZ614pHrAEh+fnSwMg6/ISRrWUz4SBopRAno35XYfTgppL0tjK1aXUkUFgGxoF81fFiYOqHkvIcyNWAhQYYvI7c+2B8nscDSRojqP2lv67Jcw7XWO/fyAuBxlDffPBN5WFGjGhtgM0dfXk3JPJTKrVn12scyNVzwFndD2uLM7H+zdBiGdJ5GkAyAJjavTqymCqjeOY1Hxs3WJ+R9579eV2tKldYOBkdG68NNw7gqUXpX4iomU0qiZIyDjz77LOu9yhUePvtt6t/fkycODFUEfXEE0+E118PVma+/PLL1T+hksMKHMtmsdw5sXN7+p31cP9rK2HXYYPgR5+eVlYrBWHwy4qv0aVTj8sbiOE50KW5cgvmVYFyz9ute0L8/uUP1T/TQLkvgbAC7uZtgudhbtLCCuK4EkeJhdc9B1qb6owDKnM5IXBASOEamFa03OArhXp8KXHZSXuWZNsZ1Mbxe1qqUQX5quPFwNTX+xmu4xJ10mQyYBXDMyNpY0Qq0HMg+zbH046x91jOJet3wq2PL4bdhg+CH35qGhwycTic8MNnsroPcXCFTZRYn6tX6VzLRwYZDAuI6vn6y+feV69pnO1evXe79at9M40KWp3vZOF19D0Z6An06IsCGSnQeMXDCvA+hp1TOovjVRLVZw4Rqtg4UOtoDhRxVEYrhBhXjAOrUhzchl3PV5Zugr/NX6X+Bq2EmSY3Ydvwe5NLWEFQOcsdffBU7qfm5+5JA2Ue48xTGWYbVhBWF+j64sCIXBrJUJWvWHjSHGhtrHcGNWHGAa0d4wMwhAZEOS4iFQ0//QQaex67l5PlpJTQ65df3Utqkpo05az3oGO6xEn1BTTBQGpihAuGeWYg+H2SfRYZI3Sjj6mNjQq1k054wUAimgP6b73GcLC9rHAMhaFYdB/yGbbJn9c4XmuFQB/T6gb3uOgTeGqLVdYIn1h/uv/cI4B+79YccDzzCLyHyM4e5jlg7Qf7Q/qe7zMMx3PAfT3oPtI5tWp5TccNbVaLd045qm+qXFKeA4KQV+NATY096C7mZIpWCMtxshq28uCdrKRBM/p6jQEBxgJs0PF93E69GO6ahUTv+Et1khEFvL8rt2TSvoW5MOvZCuI8Q3zbsJ9xEVOK/6ewgnzFwtvGgaZ65jkQPMDTn51eFlaA39Gguhw9BwjSTzjie0/Cxo5e+O7HD4AfP/4ubO7sK1mjh35f+MCdG3BK1eOnnPUedPi1R6MSvk2y76UJht7fBIULFtozI19hIrrnAH8ec7nGQZ4D/D2/t3Qf/vOBN1wTzCTDNks5JEgvj24ojgvp15CgIILXcFRbE3zqjldgeEsD/OLzh7g8X+k2mT0HgjUHaALeaWkOoGGAe52ikZ7GPZE9B6zf47XgngO8LHhOjyxYA397Yw18dNoucP7hE9Q5fez2F2HV1q6qNQ5U3xkLVZ6toHiaA/okoNwmdFFWHnR3bZOHhieMwCDexYkbWpCPFZKS9xwosYFKHHAAHCSexAfKHs2BGAOgOGEF/WzwQu6Om3b2KA8UdGFNOvMItkfzV2yz7y2NmeIKEvLrQYO7zHZQ1mDbXW/dh+m7D1NaRKWs9h/UprkmUCVa/krKrsOfERrkJ93/4wTjxatPhn3Gtqn35x22u3rvNyEttGdGvrIqUDuJf7FN5UbInIwDhiws7u/dHgsEXu8LjpyoXk8e1Qr3XHpk4H2IC+83ctFUyAd6U5KYIKE2EUfjNXni6p6vdP/5pJ9ec6NckOcAaQ7o3gFcd4D6gjDIsIHFcgkSavduk6VXceK+o+1zqmPHl7ACQahw4wA1RmGTg3xCVu1ymtBFdYPkgmj0O9O+gt7r14UsyUmWs9Ss/nHxuFmW6CQjCnEHytlrDvDXIcYB6/pu6uiFy+7JxCSu39GjUrlhbOtHp41PzIWV0sXd8dxS9f7NldvgqXfWZxVW4Er/5RJgKnPrADfYqBjY0q73QaFSSU2g8km27vKlCL/EDUygLGnwWrQ0ZiZO6JIcdG0K7ZmRL2MEd//Huszbq1xi3nlqW/VeDzOwxhmmMRR9NGRQQ+Jhmy7PgRwn36UvSEjjZn2SnvGk6zEs2tD14YKEPMSAjNd2+IHJc8BaPNMn5DxjATc+BFHHPQdc/aH7Wm3c2aP+oleE81vwlK2aqL4zFqoObqUkL6XihhVkrJQlOi7MaeVhyfodrs9NcxKvWFfwhCdOxoJqyTtdSdkK4g6U3dkKop83NwiG/YwGLzhR37Sz1+OB8uvnl8FXjp8MI9v84y9z8XKhEIZFq7eHlNM/rMAUY5lP8q3xwVelyAOsRG0DnjYu7ZN+s5QNxH56D3HreLHhzz3lK8+XJ41JmK8UPDPyZYzQjQFJud3rHmGe7AU+ngN823wYRHm/wT2zSgH9UuRqHLDT+WoTcVrB7+5P+ZaBT/r5RN5+PmzDg/Ndk+Y5wDUGMsetiz1Z56nLXYKEWvu8YYfBOFDr9WqoJkRzQKh4Si+sIBW5DKWSAznqigLmVOeYJiV6nxXmSRBHlLCShLSC4B1dKa+gRgHrNFZpv8eBK00PpPqz9hxwaw6kY11fTtoq09/fWAO/+NwMOO/Xs9Tnd1wwI1bMbpCXC/HE2+sCNTcCwwpShVPWLoTGR79LWLb47Xi2ngPcIFCixffoPRx0/WNq0P7vJ+8FXz91n7LwGAgKK8g1HjvsWGET06BMHPnwzMglq0IQugI9N9bmco25kTNQc8DwAFEZchFE9IMfr9TaHr1Py/X8+biZQ5kDsH/R+ya65/wz9/f0fFheYAbPAQq71cMKmlzGgYieAwbDhP4ajSCbO3vt1Lim3zaI54AgVB68ISI3o+KGFfRHmqCQuzG6Mn/93vnqL74vRsx81BUFVA/mmAYIQQNn/p46gDiaA6UgpFWILAk0OKJ4+HKOKcdOmOIYdUwDZT5ujDPp5ZuGPf/LNnQEfk8eKG+vcVb2D9ptWKzBfJiXC4K5vIO8XIJcSV2eA3l0gS2Uxgdvxx0PsNIaoFPd0qslf+sS5irB8utgnaZS7jmmrawMAwi/F7Z6eZE9BwrtmZGvMBHeruieAzllK/B4DujtnP91dlzX82Ac4JoDJdbp6n1akIE7niCh/wo+pfclBgyChHyST/UlSHPAFiSs18MK4msO8PAGDm93N3f0Kg803JRnYqhzGQfKq81LAjEOCBUPNQS42kRtVrEGZThgp0F7UOdVaqJ6Ud0gJ41qzSKswOw5QIaGOGEFxRbSKpRBh2Ium6wOsxQnSXGgleCRAWmSCO45EGd1ig+ewn62rSuazgVqEmQ7GE7Cy8WO8bQqPNf86E05z02+2rtCanzwASV3Fy01TGVyaw6UR1hBoVZj8w0991hlbI+TPD0P9sQ04nUiIcMRrQ3q/UXHTEpUQE8/FralY4Y4q6O5GiPcoqdpd6q/AmcrcL6LbqCJCz+/0vMcgGQ9B6zf6/H95P5vMg6YPAf4z72eA7UGz4GUcbXeHVYQbbLup03A290Nlt7AiNYmrdw1nrJVE9V3xkLVkXIJWRV3UEkuU0FlKEVRvagrD3qhzWEFujHAvOpGq8lxwgqKKaRVSIMODY6owyx34wDFN959yRH2Z3ddeKhxoNw/UJPVAChOfvlBjdG6xiHNmUF9Nis1SXi50DlRPeCDde6am6+2opAaH9xzwNEcKL16b7rWfsaBcvAc4PWqXMrLoTJzo1K+ngfabZyJqcrEYU2Sdh3eklfPDGxLH/3G8fb7mz95QE7GCN09OynNgbCwAttYZQwrID2C5Ff2+aQy12wApZ/K0Bk366vxtMrfradUJs8BVocxHaGTmjfcc4A8RRu0sAK3IGFEzwE2wefwerPR0hQapekH1UtYgSBUn+ZAsVZsKKRAlcFnoFWqonpR3CA9KbxM2QoCPAf45rbnQMxUhvlYIQmj0AYdmoiSOFCprWLEhQZaPCzl4AnDjQPlJLIVhE0qxw4JnriTB8peYzKpy7IZjIV5uSCtTXWBXi707NBqjiusgL3OV/0olMZHJk2a047bHmAlWO9N7Tr/qJRzpZvAMlL5y8XTgUNFxkmKsziQZ8+BmNfJEWrLv6s6b2+mjh+akzFCFyRMSnNA/61uBKa2zXSdaVKbj1AqVxrSEnsW9DqtG1iyFiQ0TIybyTighxUwQxzHDgm07iu1I3wCTiGShB5WkDfPAUuMkOsN8DJzo2I1IcYBoeKxB5U1NXYMUrFWWjtYWj6/zqWURfXIDXLvMZnwgQuOnOBaefALEeDoA0y/wfLgZgor6M+qnDP//Tj7/fc/kdsKSRiFNujQJLDJEgcqsXFK7IkfDfa4y6Lf6lv2mgNmI5S5TM7rIA+UNDMH6Wk8c/FyIY7aIzgVFw1Wbc8BVgZuKMjXQLZQGh+8/LhqZBt5S7Deh3kOlEu2AmM9KkPPAbrG+BjZk5Q8rfrqMdVRoe3zLRyK8EPkcjxuNKL3SaXp1D0FdK8smrimAj0Hkr+Wrue45DQHIFHPAdPqPkH9jSeswLom+m+ieQ64f+MXVpAxDscXJOTwdozSGI5mmQoQ6mOqUW8AEeOAUBCiiLTlS8jN7Tng/qzQ7OxmngM+ZSgFUb2o+ZwnjHC7QernZOqgA5W82etswgo4/ChTd8lthSSMQht0aKWdPAfKYZLhB68P6FpInbHf4CZ7zwFzPTNB9faU/cYEesrwSUY2qa38vHHamjIDoQkj3BoeOnQe5rCC/BsHCqXxwdsRzJtdCsKyfpgm0PzyxzFSlQKFMDLlE7rcONinepOvxQG693HT6NF15c9svtBDAaJsbxqXeVb30XNA8yTIFq8AofdYVDYdapPzLUhYCENONmWjiXjuqQzTRvd+t3FAz5rkFSR0ew64nw8estBY53gGmI5LY504k3U0IpiGffzSbKQ0hprnQL11nGoMKUAklaGQd6KkucpnKixuHHAGB1D0sAK/VZh8pR1KEqeRj5eJwPSZX4q5thyNA3zCnG8rfyENOpkVGmtSaHkOlOOKnmkgiCrEuDLcl0r5ru7x8XOc1RG/uG/jMaz6stfYNvj1Fw+FaTc8Bjt7UvDDTx0En5yxmzF2uS/LgT2li/v8nbNg1rLN8KWjJynjwM+fWRo6yaDjG8MKCmAcKFRKNrfnAM9WACUHb3dwIIv1290WsXpYBs+tq7wJX/BCpOq1NQeY52C+noc42Qo41I7lK8UihxvUwq5D0LjsuL1Hu7bFtorXZ3yJ9d5PMT4IP40BIkjUmcIK8iJI6DJ+DJRUPaeiYV/Q35vKWRPBHjcbJuPU3/REECTk2QW8ngNckFDzHPBkK6jzNVYEgWUZ0K4FHwtsCPUcqIVqRIwDQl557K118G/3vuGZ5JJIG66aIfg6aJtcDATUYXEhq6KFFVhKrEFl4ANuKLCoXlSokfdmHjBv5/7M/Z5vYgor0F3XIpfRlXYov/d7S0ePslD7jUeSNOjwgVMlZCvgLqM4QAhb+UhGcyB4236e/rS2BtqaGpRxYMr4Ica8zfrruOA+h7U02uniNlkDlrB9egQJXdkKCuMOTt4P1/99Eazd7kwixiVk3PV4DrB2vBQn17ysZOhyuV+7smaUXvkL5TmQzwUBDrWNWGVonJ9EvTFN+Oj6ZK85kP/64OoXA8pJArt+47IffWaa63OVylBf8R8YgKZa94pwFOg6oCcZGgJ8PQcM9zEo5CBXXNkYIt6rQtdzvGYdyjiQTCrDhqCwgn6fVIZ+mgOaV4dLc4CFFAaFFegCiWHgsfXxH68bFFYwanCjscwNVRpWIMYBIW/g83fzzHd8Rdrwkbv+72+pV0HbYMOKK2vZTIa5kBVasMnoWKzJ1M6ePvt1kOGZBtz/9ZcFsLWzLy8D7lygzlkf3EbRHNA7dHdqL+fz1sbcPAeytfLHBTv/y/70urEOc5Iy6PBOnzwHymGS4Qf36sBVAer8/QZ3bs+BdHapDEOef8fbqNY1cOnxqDObJ+O5rnDqMZrhYQW1nnrOPQfy7QKL7dHx+4yGqdc+Zqdk+39nJ2fA5NchswIMJWsUo2cxMxmtKftsBXwCmdSEK2zimaRwrJ3KUBn6rBXMHCfhfhM+Es+NO8m3wwoKEMfu1vgZyEpgF2v1Dx59x/U5nrPezmRbX+g6tDTWZYwDWjmpDzR5JziZDJK/lvxxjdKmRlkcS7qeZ3SI+nIyNOE1pXOlVX8O9Tc9WlgBzwzCIQOD7jkQlC5Qz0hA3gr4Wwxviep9oYc48HJwQcJRmudAXW11ew5U51kLBWHp9hpYuz3z4JnAxxO/56tNSQu56e6oxRaywtXHqAND7DQuOW6y/f70qWPzKqqXneeA+fPAsIKAAUQqQc0Bd2xlfm540CCKwD7m9s8lNwjgVnDyHCjHWGD9fNTziWm9rM7Y5O2BA6C+dO6pDMM1B9yrJmQc0GOCXZ4DCblxZrwVot1XJ6ygzlM+/rrQxqPRg5sT9Wyi+6Fy1deWh+YAltEJfzB7mODHpXgOfsa7pFbcC5nZxU6vpjQHcj+PoJS1FIMdK9xpwEnfWwjPAX7qfh51UQR212ljO+U5EEFzKAp0HVoMHlF6ufV7aafdzHtYQZjhFuC7AYtjSddzO6zAGhPk4jnAjTF1ET0H9IwyHApN0LN5cM8BLkasCxTiM3f7M++p1zu6++H8O2fBsbc8HSk9tKn8KUMqQ0+2ghqr7xfjgCAky3ZnwTtnshVy4x1HbQmkMuzgmgMRyrBqi3Peg5sbSialit3IZxVW4G9A4N9hGrecwgoScvn22zdar3/yxLuBgygEDz281e2ylgvU6fNJZBnbBpzzsQYQNGAwDbB7tcFsvGwF7PVAtMEpDWpogKCv7PGVt1zdOLmHU1TPAXr+aCWHD5p5eQohnsXLytu5JKD7QatJpFZdgBDt2Lg81ciIEdE4WorwepREv1nozC5OWAFLZZjleUQxbMTVuHGHvxXacyCd2HgL20KP50CWxg66DoMa64zXJSjUJVvdh6TFHKMsjiVZz4P0Z+LCjVQmt3oyRnNBQn659dV6arf18BmuZ6Cv0NN7MsZtZ2Le3PsizEBgNA5YzxyOLTd3ZIwDH2zscHuo1Va354CEFQh5Y0hDcvvKVsjN4zlQ7FSG2qAZra1BaVlWbO60X3dmkdIvX1Cnr6965RxWwNzSmizr9NINO2K5kZnKkqQgocmltJBpJ2lFGDst6ltL0b06KjSIoU6YjASmwV2vFuMYRxU8TrYCfWUjiudArgN7p+571Z19f6NpDrjCCgqsMs+PwYVXk9w3XRc760wJ1ns77pYpZfN2Ur+nJW4bcK/SDpRfZhd6rpTXSY5aFWGGDWKjNeGIgkvUtACeA7zt82uzshlv4YQvSraiKFC5yHvQK1Do37bRNcxFEDGJbAVRF8eSqufUxlBflUtd0jVedMgYzRdueN+jixj6ZisI0BxAg0KU8JawsGMuekhgvcBx3LV/w7DmDF+9e55LC6KOjAOaMGK1kJVJpK+vD1asWAHvvvsubN6cjNVLqDz2HJKGcUOaAtNc4ffjhuQvFZZuCSx2KsMd2qA5rBzLXcaB7FbQ8xmH6vECiLAqFqRTQNvjbfrx44vV6zdXbo/lRubsy1veXPFzKS1k2klnMp1/9e1CQIMYWp0nNWKTi62eOimW50CssAL3SrWfcSDJgb29mlJba8yGEFTHndUijBVNFyxbgd+9SNo4wAUiEXtFvgSNAzzu1vZwSPsbtErdsOfOVpC7daDQqXq5SFrU5yrXiZzeTgXhFjXNv+dAlKwtUVKU6m7YuK+kNAeoLSWFem9qQ/9JOjccZJNeNvqCQzqRxbHE6nnavaqfy4KIrgMUJZUhv9RezwGz5kBdgHEAwwqS8DIyLfx/uKlTjePWW3oDJm+Euir3HIh81jt27IBf/vKXcMIJJ8CQIUNg0qRJMGXKFBg9ejRMnDgRLr30UpgzZ05+SyuUFfhsfbt9P+N31CRc/9H94fqPTg3cJhchN13IyolVhZLwHAhawcAGetXWrtL0HPDTHNC9AtJRPAe8+8XOY1tXX1ZuZKaBVhKeA1H0BUwkkefdOJmury26hkZewgrIc8Bwz4IEAcNwTdDS0eoOlYUm370pLXUTH6QmKEhYF1uQsM5TP4rpOZB0WAFNSmlFyvEAg9INK1Ar1eETslI37CWd9SLKxDPJNtPxHMjdOBB1ImcSQfODu94XJqwAQie4lDHJBJ3Z107Y0/U5GuB141G2xo4+JkjI3+vfI0HeCsmn3uSvB3JeHMtHPXdC4NLJtGERPQd42+CbrYAWlVgGsaCwgiS8jHRhQ2T+ii2hWhCEGAcC+PGPf6yMAb/73e/g1FNPhb/+9a8wf/58WLx4Mbzyyitw3XXXQX9/P5x++ulw5plnwpIlS/JfcqEsOGP/sUqRVRcbQdV9UmolZf7hLQ2+22SL7jlAKznFckfVB81B/QtaRN0D7tLxHKCJkCeVoceTAGJ5DgQNjnjDHaXT58dOIv4wqkupTtJpJ7kbPg1CS331MU5YAbkBmu6ZbhyII+DFr1HYirOziu/WHPCoMycZVmCvpnDdhYzIE4bV/G3+KvXXFDPMjQM0IK9szwEo2XrPQ6NM2gge40AJnoO/C3fu++MTz5oCpOp1pzLMzTgQZtggWq1JbRT4BLrQYQVB/SKNy9os1359XHbkHiPDNQeyvM5U51qsjEW4X95mB+mp5FNrhY9dwu5VlMWxZOu5W5AwFy8U8rQ0Tax5liQuSMiNXPo5OZ4DllYV85Ij9DkCHjsJLyPTKXQFePaQN8JGy6ugWgUJI2kOoEfA888/D/vvv7/x+8MPPxwuuugiuOOOO5QB4YUXXoC999476bIKZQp2Mgfu+j689uFWmDp+MHznI/t74sdxG2z7v/Z/85S1+LcXHhY7xjzMApoRJCruoBKVVqMODLneQMl6DoTEzxo9BwKMA/NXbA08LncjO2pP9+AkiZzESccGThzZknh2iV42ma7IsAJN2ZjT49EcSOdVc6BBDyvQV7ASHNg7rpZOWMHabV0qnMYvRzbVcT6wUsrejYU3DvDBYeLGAc1YY8eOl2C95/oIJiOGR3OgBM/BfyU2mZVtmnjq2i35SNXLjTW5GlPJsIEebDq453QWBp98CBJiHcQ+EvssnDjxsVScFL94Hxat2Q4/e+o92G3YIPjhp6fZ+1qwcpvnGfWL/48LrXqT5wDtixTseX+u30tXGEzCxhZ+r6K0PbQ4dtWDb7oE9fJRz23NAcr2oxnSszHOkOecDhmjubHc5TlQ4+M5YKeZjOA5UF9jG+PQazTtF5oc4n3hZ+AIo9vyitjc0ZOV5lVVGAfuueeeSDtramqCr371q7mWSahAOnszjQiqtodN6rBhCdsmKo77UqaBKHq2Am2CHzRIIb2BMYObVGxUKWkO6O5h/iED3g5K769NaWWSmKjzYycRyxnVir3LsGa4+JjJcNM/385LZ0KdvtIcKLKGRj6zFZgGlh7PgViaA+bXxjJpMZG+mgOp/AoSLly93bMdz5FN7Rg3DpABw6XoXQBjKD9G8mEF7nacrk8pLro7BmmWrSBdvtkK3OEpye0XJ0YoJPaxn7+o6vk508bDT887OPE2ky6vuh8RhT6jGDa++eCbLmP/2CHNdlrmOPc06ZS7JsFcblCMksqQQ9tj5gA+LtPj+ZPUHHA8B7hxYMAR23P17ZpxIOC7XHF5OUYcU+A1x7Hc92e+A2OHNKk6no+JJpWNhJxz0VkyaQJEFSSsMYQi6NkKTCkPSROEvkMjBzfGceObOk5E74tsL/PL729Sfxet2aE0r/gzVA1Up7+EUHBo1VvPV2tqkIIa9CAXW+M+rc6PjIfFjlXVQwP8jBR0ngh2KEgpGQfouuuDc+/A1/vbIG8DPbQkl4m6S5AwgUFXVJfSPUe3wRGWy+VOzVMkCehcVFiBPUkq7QlGrGwF2kCCQ5NzWpjQjU9B7UM8zwGz5kCQcSLXgSifVAbVMToKTgBoEI3tmu5xwQ0ZhUllOJC3ECh9sOoI/ZVevacyqew4hnKWW7aCoFXaXMH7SYr02Kbnw5hK/Q3eCjI85ro4gBOEi4+dbBvv77n0SJj578dl9bz1J2hg9BPM5Xo97tXvgcjtkjeNqz4pN2UryE1zYJAVVuC9TqxOBngrJG1448eK45VAP0OBRTSw5KOe6+K0uQkSOmMME44gYcqYpUWHzpcMFibPgczxnPc0DiBjHHoIZBN2bPIcwGtUE1NUdG1MzauqSmW4fv166O3thd122029R52B66+/XoURHHrooXDTTTdBS0tLvsoqlDE7rcFiT0CDRQMPvwY9zCIetE/dc6Bo2Qr0sAJDOfTzXLBqu+2qG5b6sBBgGZyUNPpAN7dUhlPGDwk8dhQ3MtN+k3CHDbNip1nHM6S5wXi/k4AGTlyQsNTjlqMaO/iE3DRQpsl5S0MddPSmXAPGsPYhjnGA9hsnW4H+XS6r4x9scocU6eCWeJ7rrLhIHJDh9etLpWwDLB/MF8JTik+IdnRHzOMVET21pOOuDyWHbeRhA98gQcJSNHBETRuXBE7u8/yI8Zk8B5I4D2cCm5nwUb70uPtPSrckatq32z57MDteOnL5dDd1vayJZisYcGcr4O0ZtmXu0AjNIOHSHEi2TvHLFWdlnsqUTyOt7Tlg9VV4KLxO2Rgi6Lr5/ZaOwSfQNAYxCRhSn25rDmgCswR6C9A+eQpB8jLyC5UJgpcHPR5w//uOHQwLVrnDYsJIR0ydWJWeA5iR4A9/+IP9/oc//CHceeedcNhhh8Hf//53uOKKK/JRRqGiPAf8G2tHqX4gK4u4CWqM6Tkudl74sGwFYany/v7Gaig2vH/zGgP0bQ3GgYiD41zFqtxCh8nc7yAr9mcP2129xkna4OaM3bWrL5W4AjXXHHDiSKFs4akZkXrLSGBysaUYR3I3pec7SvvgrrfxVqob6+qMq2dJpiFzJpXRPU66rHYVy0nGFSpjL/PSKoTnAL9faLhJ0ptFH6zmKzwsrmdaWIy7KZtIkHG0FOF1Ph/1KIrHYC7Y94NlK0qiOyBjoBNHnd11Ssr7KGrat0Wrt8Wqe/0RPQewHTd5E+QUOlfveERRP2EKZ3D9dqBAngMx2nu/xZQksTUHuP5MlgMD23PAzzjQ4C9IqHsDBGkO6F4GvOx6CkXcBxrhPjZ911jeF9z5gYxNowY3GcU2R7QGe66mI6ROrErjwJtvvgknnXSS/f6Pf/wj/OxnP4Mf/ehHcO+998LDDz+cjzIKZQ42qOQSr3cwHGow8I+7EQ62iAcp2NsrTlYLYYoBLRRYFpwscng5oqTK+/7Mt4s+mOSDIE+2gggD36CYW/o9hheMDXAjizKIdw26EhQmwuO/ePXJdid48bGT1Pu9xrTZHVybZRzIR2gBn0xT/1hZYQXhgoSkYo33PXr74F9vdXS3R3/PgeQECXkqw+EhgxSCt2uesIICew7oWRT0EIwk9q2340kaedGAhOKPGF/69Xvnq7/4Pq4bKV12vI+m51N3Ry52ex4rrCAvxgH3JDtpTNkKkjgPqt96HLX+OoykvI+iCuZyD4co3hpUvjC9l4znQPDEPSq0b1xJpn7BnliGPD9uz4GEjQNZihzb3hd5zEZBp9pkZRLIyTigtbdRwgp4/6XjZCtwPyv6BJ9nBuAhBrnAMyLwcQOO475w1AT1/vi9R6nQIBRLz5c4dUWGFXz5y19Wf1evXq3SGqK3AIYXvPvuu/DQQw/BY489BgMDAyrsALMWIHfddVd+Sy7knSDF2zh0sgYkqLFyGQTSaaCooKgWcZOCPY/jRYqZylAXI1TlYOccJVXeuu09kZT684lrMh/iKRAlrMDkcotxqM998yQ44LpHVdqZWz8zDT4+fVdV/6KGl/D6lLR7IT4G1IHuNrxFlYu7x+M/tFKjMQhDC1CIMx+T6UrKVuA1Dhg8B6wBamsTeQ4MRG4fRg/OaHdEmRzomgN+xgFexlw9RJwJcA1MGRctvIY0OrjngB1WwFZ1kq7/JvT7hWFQPMViEvvOV1gBeZ6kA8QfowpRucIKrMvO9+vVHCjtZ5fXnXz0mzTJiirwlktYgZ5vPRfIi8m0KhzneQtykc+HYO7QQQ2xjudMbLW2T5voUtrVoG2iQobNertdSxmFVnn5qF13eenkwbMom3tFfVxS2T5MUDvCV9+zvf52tgI/QUKDBo894TdM6vXnzk9zwOU5oKU2zBZeHBJStLNtWZdn33GD1ZiadL6SetYq3jiA6QkRTGd48cUXw1lnnQX33XcfLFiwQHkMIJs2bVKhBWIUqAyyie/3o5O50gdZxvU0MTSujGqlM22nx6oWM5UhrSBjWXACgLFPvLPJ5TyLltoqxBgQzXPAJ+1UbQ0Ma2mErm3dsPeYNtswEHUQn9Sgy2QoO3jCMPs7291RWwFH7wE0DmxPOP6aJn9KzbciNAfcYQX6SpFRc8AKK8Dbus5SCA+Dp10KDSvQNAeaImgOJGUcUF4AbGAUpNL80OurMr8xhBXkU5jLhN6mYns3qq0pEUNzyi+VYQL1PmqsdtQ4U+7Gnq6xBqEx2sxSg9LK5V9zIE+eAwPJpTI0eTE5cdT+3iHRsxVk34ZETfu2z9jBzvHihBUEeE1l3huMA9kKEtphBbXesIIAzwHdwJR0SJ/bcyCOAagQmgNghwIou2Q6+/One43hwKY0fo7ngME4YPQc0LIVUHuupy/kngNZpiD0Ozbpg/ByOClyM9skkTqxKgUJzz77bOUZ8NGPfhT++te/wlVXXWV/N3v2bJg6dWo+yigUmCRXUfSc11E9B3gjGtVKZ9pOd18qZipD0hvASSN1fryzyeU8S0W92uM5YBiEedwRXUYhcHUwpGSNdSjuIJ7vN5dBl8lQRhkkeEdKf2kiiboDG3b0JJ7znWsOFDNMJino3sQRJKR6gYxqi+aVwXM2Rw0rcDQH3BNvfbvMeaQTm8SQMXOXoc2254MpR/aDc1fZzwudH11PPpgvhPFIP3+q90kYmj2eA7XJhdPE9UwLM3Rwz4GatEFzwOM5ACVNwQQJ8+Y5QEY3R5wsifOgtkiPo44tVpdQaFLUtG8uL5ZIgoQ0VsnUBXI174viOZBjWAFOEHVjscdzIMDVv1Q8B+wV8zyGFVBbiHUc7xG2/9mkM8T2+pq/LFSv127vMabxI+NADw8r4B5TiXgOJBNWUGvQHKA64108zD11YqUQyzTzgx/8AC655BIVXoDig1yA8NVXX4WvfvWr+SijUEByie/3g6fgC/IccK1Is0Y0LIUcfj7ex5qnD/KLmcqQBsutjfXGrAlRUuWNaG0sutXSpTmgD3T1MIMoYQWGWE26TzQJxNRocQbxfF+5DLr8hO7Wb8+oxPOVNX0FfHCeMhbYx6mvjLACun40CKwLOCdqP1pZ/uuDJwyP1D60WaEISNicko5N95IGLbRaaG/H6lWQnkoUeFtF1wBXOlDPYs/Rrer9YZOGq/c0SHM8bRwDBtV1V376PA5K7WNo9wuNodkKyRbSyBvHYyuKLoEde1vrhD/QwB3/ll+2An+vh0T2n+d4bLrcGFJIC5OJGgfIRdnQj0UhSe8jEswdO8Rfr8edVjP8eO7QKf9zRCOCx/Cf5T11+jivR5TXAMA0BgwGiyThu4sz0adt89lPc20Nuy+IqWFB7fWWTkeXwtRek3u+S3PAZ8LPP3MMTe723Og54KN3kIvnABk16Fml+s8XDnJNnViVngPNzc0qXaEJTGkolD+5xPdHUegPGkD7xezlYs3jOacR2qQYkykyDqBCKr3mxeDn6cenD92t6FZLt4Cg9l0Ez4EBNvHCwYZJkJA8BwbbngN9dsaLqIP9bGNA4xjKeAfJV/SRIZYoYdJp3bgRopLCCqiDJndCs+aAW5AQwa2itA93vfiB/XnY809lsj0HImgO5Ow5oIXUUDnxNYlMYd5v4yq1lcqQl73gngPaM7a9qy8xd319EGfKApAtUT2xPtjYCT99cnGoR53tAaIECd3l5OXFPsm02lpq5FvY0nHxzY/nADcs2e1lAudBz5fj+cDbgvhK9vrrbME6ePw+o2HqtY+p998+ewp8+ZjJjhhjOt7x+D3HcybXbN2QofflUfcf2CfU1no9ojyaA/x4yQgi+hH32unbmsYhSWl7ca9L+5rF1L6I2l7bYQWGPobavFw9B/ikPhe4J4PuOeCED7rLcWYOqRMrhWSuvlAx5CPunQvxBa0OBOWCdizijjt3FGsePfzUQNDgoBjq7mQkQTE1U0fNz1N3lSZX9f3GOfGCpbiS5AkzMHkOWP0JTWZM+ecdz4FMY76zJxU77CJbZeE4ApHIys2drsEidXCUzjB5z4HMueDqQEVkK6DrFiOsgDQHaHUqirXfVM/8cFZBal1l6wnMVpCM5oBKuUbGAaucNCDuZl5Y/DxUKIJ23VzGgQJMQPVjvLFyayxPnyj7pthQR5Aw9/OK4pk2bkgT3DN7eSSPOldYgRbjzgfr1P75ZdnJNaViUvC2Mz+pDPMbj227W6tsBdY1T1BzgMqfRLaCuCu9Udh77GDXpIbPF6MYMfh96Ul5V4r5e1MGg1xFanWPKH3CG5RCMmk3/uxFJ53QDD4mSipDirueM28Lls42yYXBZstYbfQcMAgS0mfkSULXIyhbQWNCYQV84k+GLcdzwN2vJJE6saqMA2eeeSbMmjUrdLsdO3bALbfcArfffnsSZROKQD7i3tElPEi0JqoFHQf4T1x5gv3+vz95oMvF1oTuOVDMbAU4wUXamhuMYQUEns+dXzxUvUY1ckyxgqlW9GtZLHiZ0yHGANN9pHtCLtumQRW1w05YQX/s8JJcB7VRDWDbrcm/Lkg4uKkhL54DNOmrmGwFA+ZsBaZzMhkHSISKUkxSbubzDtvd6IKfeR01lVN0z4Fc3aJ5WIEt4KSFrOipUPmqqOM54P4N3y6f6MfYsMPtmprLc+bNVpCcsBx5bJmgtub8wyfA2u3RBs7c+0k3YvBrRHVKP4ckJwz5DiNLAj81/HyGFSSZypAmfNnGowcJ6mVLkMihK0Y/Qjn9wvM8E3HMFGB9RpO8bHUkHB0ar0cUCfIS/BBBmQyKqjlguG5JhVyZwgqoD4xz/eMsDPKwAhoDBgkSejwHNMFfo+ZAQmEF3JPBT3MgqbSJlUSkq//pT38azj33XCU4ePXVV8MDDzwAL730EsydOxeefPJJ+NnPfgaf+cxnYPz48TBv3jw455xz8l9yIS/kEt8fJawgaBAQJWaPf3rArkMjuKM61lTEWbGHgoLns3DVNvW6p68fai0Va7/zpIYe0w6h1RINCkhU1/p84tKG0FcKtNPxWxVzew443+mxaBiCQXUoyiCeh5fkKkgY1QBGHTFf0Vdlz5vngGMccNzPoWzRjSp+gld8QI6eNCZtAvWZVRmGtzS6XfDZ7sI8LfRUTna2goDBZ66TG5equjaY4urRpuPj9s4Km9f9Np8q2XpZCJZuO+fnzKM5kHA7Tp4nFMake55MGpXRfIgycKbLjmXUBUNNxgH+WdIThiToK5DmQN6yFeRLkJApteM5BPWLQSShjRNnn7zti3LN+Xlx46jH6MA0B6i9zPY6cx0a3SOqL8hzwKM5kGzHyKt/9qEjA3nR9qJNebabOH1SnIXBJordVxkR0qGChJ5sBVp7TvBJelJhBdxzgMIhdHHLavMKSExzANMXXnDBBcoogCkMf/3rX8O2bdtsaywaDc444wyYM2cOTJkyJdKBhdIkKO49W7XODs0VFgf4pvzX7tgxn0lzzA6YtndiVa3PLWGoQsQU6Wrdry7bEuoWS+5gNGGilVIUdyxUubPRHAjLXqB+b3sOeFfO7IF1jds4QBoNNIi/6sE37RV7XcHdPrZrRSb+ICUsrQ0xzMo17xtWkHS2AjvNU01FhRXQwECPMeWQOnJTQ8Y4YHJlpbe6xwa/Rqm42QqiaA7kOBDlMZu64YMGMTx1FMJXqYPCCgqRnUW/D8NbmxJLC+X1HEhezA/bjrdWb4f/efo9tcJ015cOs9vWOPmvN+zsieY5oBlH42ZjKRT59kAxqf0niUvLw+pXkjgWFyfF66LHo2N7Q56KQehGhai/y9b9nTerccZQel0weQ7Q/nDyiP1e1tkKmA6N7hGlGwCCBBYT9xwICH2N43HwRh60vbgRjNrJOMamOGn8eD3o7k+p/jFIkDC65kBd4mEFdaawAp9sBUIWgoRNTU3KQID/EDQOdHV1wciRI6GhITM4FioDmoBhOhOuWmqagEWhM6LnAI/f1XPo+jWyYeieA/R36fqdylUzl/RauaSFpKK/9N4mOGi3YaGrqeRej4PXQpQ7+2wFmifBQIDBxrCKo1uU7VSGzBCA57lqaxfc9I+31YTyfy86wmggydVzIIpAJNJLq7t6WEGesxVkNAfKX5Cw3yeswCxISJ4DdWq7XoMiNtUhbjzyhBWEtB26d4ufccAdL5zbPeAxmx7Ngf7gsILakLCCYngOdPWmEksLldJWePKVkpaucxrSrkF5nIHzw2+stsvqaA5Y58HKS8Ycqpf5EAMuh1SGjuZAvsIKnDEAtS1JGJW4/giW3TtpRQNR+H70sQ4+v7lOjII8mnhfEWVl2ddzQO/rU2iodTy71DY5ZivAPk73iNLLzI9hSq+YJNl6ebgMbKl0XrS96La6+4KBvCwM1tbUqvAFPCaGFgxpbggUJLQ1BzR9jiDPgaTCClzGAQor0I0UCR2rksj6igwdOhTGjRsnhoEKBSdgN3zUceH+0acOCo3v92On5grrl87QlO8+aJsoHTw1Rk5+7MzfJ99en3fXzaCVIOI3L75vHHDxdHW8UXti0bqiu5yasguYvjN9z7cJEiSkFR47rECrQ9yVzU8sJluBKJOhjGLsiJGtjZ6Vb28qw/xkK+Aul0Fp/8oF3ahC7oSmyYIprIBvx70D9OvOdxfWdNCAsy4krMCd2zw5QULbcKalJcQJt+s31uHxN/ogmk9eCpEuTx+IYygQPT9jYgrJ+u1b145JutqT8QX7KF6X4oQ0cYONn+dARhzP/ezmY8KQBNzrKpXXbAV58hywHgOsM0mGFeiCn16l/oGsnpsktBfcBoC0vwdVhOvAt+FtSirIc8AOKxjIWZDQE1agXZ8g4eF8ZivIOnRkYCAv2l6O5oBjHIj7TFF7TULQfu01HoPuMYXX8LA4Hd3gr3vmEbTPzG/yZxyg20GGTwkr8CLmEsEXdGEnpuwyJOsHqFMT0fP3HAjvWPnHURpnWs1DDwh0DR1I+3dW2cZ65aJ2v2lnr1Gt27GcZ675oMbagpU7lhtk2i/uDXw7Jxq40LmZ3BypX7A9B7Q6ZHdIaf96kFQsJ3aIJ+w9Wr2ePKpVCUTe9tnp9vc0cbPvWb2eyjA5zwE8p1VbM9kR1mztUtZ7pIwdB2zjip3K0A4rCPIcqDWqvfPX+nWPk63ATp1HYQV1deawAlZ5cxnU44DdfnYMmgNUf3HyylfL+YAsKKygMJ4D7vOncBp8fv5++bH25z/69LTYhmY9W4EtLJdwxSf1bTycfs3CdAnofKh9w9uhaw44Ro5a2wBK9zAfE4Yk6Muzkcmp4/nxHOD3w77miXsOpL1pfCM+c55JdgJGEpcAXsCEOUq4HR+LubyRDPH9tG/qA3NOZWgIKwjyDvDqEeTPOBCnvuqhI/nQ9uKGR+pDs3mmsB371CG7qdenThmjxjum9tpOZ2i1mX4T/sxnuuaAu3/NZ7YCXp7mRh/PATEOeBDjgOALxXnnOrnyrvpGCSvwmfDFsNziSvp3/rZQvV66oUOpPv/h5Q8DfxMnvVYYuawE8dVhtc32TBxrvssdJYUWHxR4shVoegImd3caDJNXhNFzwCBI6Bfv6euJEhB3GZceq85iedBTgT8O+mSs0RNWkIznAKmYP794o3p/z5wV8OPHF5e95wB10I1ZChLygRe/DNu7NM+BiJoDWD9pP1SWSJoDObSRLndzNtGnFcmw1buwsAI83XzrDujNuv7MEgdGEJKNnq0AEqWLaTqY2hUcIJ9rDZyR2z83wzNw5gYbx3ineQ7UMs8B67t8TBiSICyLUC7gtdINJ0nDU7wlKkjI+iB89nXjWNTz0cuieyclHVbADxdlZZ9v4jY4ekOsbEFCzX07ybACrxCifxucTThhEHH1GvxEE+OKK0eBipPRn/HvQ6NA9xlDXv08M510hsGhAnE8B3goQWJhBSzMoUWrl0FlrnYiaw4I1QeP2c3Fqu+d2EXxHMhNkNAv1l8X9Mqn62YuK0GOSFu82LFcyq0LJ/rpGfCOzpOtgE308D6bJiTUXwWt/HoECbv96xAOpgZBXYiVP7fBIFnHqdPkq2n0mW7QGZyg54BffaZndPW2Lij/sAJLkNAewJvCClL2ZN2kWcHvuddzwPxah7c9uiCh3nbxY+cyqOfGilqXcNqA59lH7wFdWAm3520FDor1c8Rj1PpOPXOH7hfFovJ2P1sld/03dXX51RzgYRv4XLe6oyEUmzscHZ6DJwzz1TrBMvppDqDngG7g4DG/uWo0JAmvf0lf76SMa0HQIfBeBOmZxAHvozutn1dzQNdC8cMr7Jd0WIFmHIjpUcfLE+SNlDGQWMaBHD0H7FR3hrCCoIwxujEgH8asbESOTakMyRPpyvvfcHnpZqvtxY1gtvedwYATRcya2kFywzdBoZbUJwdNtG1DqHUddKFwUyrDpHQAqM9AqN/UQ5mSMkRUEmIcEHzZmZBxgDd8mX35TPwjeAVEGWRGifUvhOtmFLX7Ea2NxpUgXZBwVFt+XU79Jp+kZ+Bym/WZjPH3yiugJ8RzQBPkMgsS1nm8WPRVG7+6meuExGRU0kMITAYD8ojwM2zEJUp9fnftDrVdOVrAnbACtyChafDV2+cIEtK5uiYvrC5t92gOON8FZXfQV/EL4TnAx3A40ecpV3WDBKYzxHZDX4l2wjEGjIYK3DZgrJczdC0w/erWzj6XcYZPlLJx6fZqDmS/ryB4u+JnxN6woyewXeGeA7rmAF8xs+8x2wdNGHQjbbYThiRwiaklfL2DVriTPgY2L6Zrng0mYVK9LmbrOZCEkSRIuDmuUK/fPaLfkjHQ5TmQcypDx2Aclq0gKEwiv9kKotdX9wKI8zt8np98ex08OHcVTBjRArece1DW2acczQFn3MjradTFH669QpNpE05YgeU5oOlFRfMcqA3wHEgorICVhwwaVFYynpTjuCnfZGUu2bp1K/zmN7+Ba665BjZvzrgxz5s3D1atWpV0+YQisrOnL5GVV31iF8kN3Od4UUTmosT6QwFcN7nrmF/T8/kjJhgbJid+PfPd9N2H5q3cQZNPk56By41bu5VOWIH/IEwXJOT3kfreMEFCnmParz7xY+fqXqh7DvDJF3kM0Gd6WAEKcuYyGI1Sn3Eik0QoTCmFFRhTGbKwArPngNsoyffhDl8JKo/zG1rZoLLhPXYLeiWjOcCPqfQD2KCJ6p7pPR+Q2QPCVNqYOSHfoScpZhzQn1keC5zNah5dZ2orndhxyKvngImNVqrCzPHT/hlylHHAbQDlYVPU7Ov3BQfqGKpw5B6Zthz/ZisGnARB8es57zvHehE7rMDO7pLbPk1GQs8kPOL59Oc5rEBvR+OK6rmyFRgyoJB7uVuQ0J1PPpcMNnr8fF8xPQcCxA+zDc2hyTV6Gvq58EcrG7CsHG7PDVr8iSpm3RnBc4BCR2ydliieA1q2Am8qQ6Y5kIdsBWTQoLL6lUPIwjjw5ptvwj777AO33HIL/OhHP1KGAuQvf/mLMhYIFao54DNQSlKQMMpKb5S44Wxd6/PhukkrQbjyw6EOb8aE4cbf6S7qbdZEMx/ljpNCK2wVUJ/4mzpnum90DVzWeKa4i7RZrvl6aAofpEQRuEwsrMAeoLABk7XaqBt0KKwAT0nP2BGHUlUxTwonM4ceVhBfc0D/DW/D+FdBg2I+6KNBFh+0uAbIAWm0svYcwFVltmqiZyjo6vW6eeNveFhBT8r9m1wHypG0SKzPMK0V0sHa/Vwzh3g0B6y/QR4g2cBTRXIvAn/jQHDWCY8gIcuCYce/G84Bvx/e0mgbW4q5ssVXYwfK0HOAT5qS8hzQ64YpW0HU86E0nfnyHKCxRLZhBX56J1ROWo3lgoRNtEKbRYgElo+PIxzlfavvDfCE0M9Hv7a54lpwyEFzgGML+uV43+2UnbXOGATrYNzFH16mQM8Bq0/s7g8XJNS9Af225QaB+nymMrSuFdUXSWXoJfYVufLKK+FLX/oSLFmyBJqbnQlPe3s7PP/883F3J5Qw3C00lzg4fdU30kqvz/GiDDKjutbztCnZpNeKCq0EHbjrEPX+X0/cE6aMGxx4DnpYAbnX44RTt+bmWu64k093tgJt4GG9NXkF2NtoBgRTBoo6LVsBNuIul98IngN8YJJrHKcdVqClLaSymXQi0EpNnV0uugOlqmKeFHRNaSIeRZAQB6S0vdvzxP2b7V3MtV2ri34TS16/aVzB2wo9hVkSkxv+HKmwAuYKySes+ns7vl0ZB1hYgV0Xnf1kOyEiIUwUdP36vfPVX3yvrzbRtRjWYnnMcM2BVI6aA/akOnMf6PIk7Q3hNg547yfe4y2djkedsX1j3gF6+ANfqdKzFXiP5R7AFgu+MBDnescxKKnXeTpPLtpJBpmcBWo9WUu8xoFsPQf68u45YN4udliB5iXA20VqL+PE5dvH0Dy3uEeU+j5A90W/r0l7DsQNyXC29Tcq0Cp9rqlw7aKlQYV1IUvW7YRZ72+KtfjjCitoiB5WEOg5QONBloI6zHMgqbACfgxdc0A8BxLUHJgzZw786le/8ny+6667wtq1a+PuTihh+IRGtz7HgVZ9cWKL+/Rzm4uSiSCKcSBKrD82eu0HjIU/v74a9hs3GK47Z/+sY72igPslN/N9xw2GV97fFLgSo080Wxrq7U7mkInD4MX3Mr//6XnT4Jxpu+ZU7riTTz837jA9Aa/ngHdyp2craG10miiM3W9qq/NmK4hQn3IdJJB13GQc0EMNeAeHdX5TR6+VsWBQVseOUp/RCFFoFfOk4C6kmb/+A3jHc6AukucA1x3wZtbIpDfTcVatHEE5vqLhZxzIJXSFzhUPx1MZmowDqDlgn4N1SE9YgdVe43XqS/Vn/Qxko0UyxAorwOuE//B5SNxzIE9hBS6jo+F+YupZjrF9s37G3dipnFysMMhzILMfsxt1oQkSoM1Z3DZHo1GsFdUa7pUEiXoOKEHCgWQ0B5K430Fu7O4Y/XiaA+62zzHU6gYTMhhkc0+5MazRIEhoEtkzvc72+EHwQ8dpT/00B3j7npTnAD53W61MPX+c9SE8/Mbq2ItE5K1GBgATdN+jpDL0aA5Y9zIwW4GmR5At1M6qMlv1ksapojngT+yr39TUBNu3b/d8vnjxYhg9OpMLXKgMkgor6LAaGnKTjJZ6ztxQRslVHpQmhsBVfBoHjmxrzCnWKypciT8s37KTyiezXYvlOYAdyWo24JoyPn5aMJ24KbR456yvenlSGZrCCqzP6NxMMZA0qMZzI+s1d1PmAxG/lTVX9ouEwwp4HdZTGfJzp4HNLJ+Vs6S0KyaObCnbDk4Px3CEBtPB2QrsdH9cV8DfwOkxZIU8e/x68pV5U9ytX3mjwif5+kpGd2+A5gAbkFF5l27YCXOsVSC8To64YbogWiSkOcANw9lMMPWymDUH8ug5YMhsw0MK/I7vGDgdzxPHc8DykqnjfYC5LHQ9/frLQsHrdRRBwjjxzbxe5Lpy6gcVOUq/GxU96xHeK70vjFrP9WuaxGo3Pz+9/uSkOWAMK7AM9uya2NkKsmgTuZEV+9JGPawgSJBQT2VYgpoDehlpIp6rLhIJpZJhgNDfR1kkovodTZAwFSpI6K854J6C0sIKD7vKFSoP9t/2mEETiE3KS6GqjQMf/ehH4cYbb4S+vkyFw5WV5cuXw9VXXw3nnntuPsoolHG2AvwddSjDLXdT/xjxeJ4DQY0zxfq3WZNqYogVBz526CBPCpZ8w12YnHzLEElzoJWtoC/f1BkaFxuHuDl3g7IV6GkKgwbPQakM+cSMdAe4scqVytAvTCVLF0AdXHHmuXzxn1tzwD1owcEMuWKv257psK9/eJHRFTtX7Qp6psiVuyLCCgzhAggOvp0VcUeQkLcDen3jngP6IDysjfEMXAwK0PoqXLYx8Dw8gP7SGEvP9mIKK0C37TueW6peo3voVX9+075mJg+LvGiRWAM/vDe0qkTPrOsZTyBbATUPiWsOcEFCQ5uxQTMOBBk/M6KDbm0ErjkQFv9O2xbbc8CdyjBZg5IuRpuPvpiruDv9bm7HMaU0zTYloZ7yMJeFGPvYWprFXCa44WEF7pR2/LNsNAfoucP7xbVU7LCCGIKESdenKAtYJoKMo7bnQA5lxX1+uKkjq9+axKypTC0BxgHnvoeHFfhlK9CdA3j77heKFBc7HXGdYyi3DdpauJrgEPuK3HrrrbBz504YM2YMdHV1wQknnAB77bUXDB48GL73ve/F3Z1QwmRcoSHr2DF9YDvU8hzoy8ENPM4gEydU5x8xQb0+ad/RcM+lR8IVp+1jd5A0yC+YcYBNAGyl6pDVS0qLh4Ntmizwa6OvYGQLTT5HWinSgvQMgty4qYNwrP3+g2eTAYHnbSdMGQsipTLkYnE53GN9IIjH48fs0fIvv/TexljKwHG1K3YdljEQfPvsKfC9jx+oXheoChc2rEC7r3xS/ObKbXYdCTJWcc8BfSLp13z0h+Rgduf6HkhkckMTBO4xQK89mgNMkJCO972Zbxt1LfiqUVzNgWy1SPC+2Gk8LeOAa/U5iwmDna3AuicU7pFkaj1lBHTpmqQC0xgiplPh3k81PmEFeI3CdBOobiWhXp8LcVz/4xqU8hFvr8OvOXkt59rn9+ZTcyCBxjxoEcXlUZdDWAH9llTr3WEF/oLEYVBbQf1BvdYf6OfjWpXPMrQjKm6vi+h1lRuA9DpOY+RcyorPUzahv35i1hS6Fk1zIDysQJ+UmwzwOC66/uG37Drgp22TtXEAvei0MYNoDiSoOTB06FB44okn4MUXX1SZC9BQMGPGDDj11FPj7kooYfChoXCAXKzZ1PDhgL/VskL6hhVEGEDGjV2ljmTK+CEqdOC99TvsgTJ1ZvlKoaRjW1aZarLfypcuSIiDzJaGOtc9ScpzgE8+MSbrS7+fo97/+yl7wddP2cfT2OurPUavgHr/wTvdWkeXgO8785e7lJEYI/dkiZTKMCHPAT2VHNYbtyBhRhGYrsuPn1jsu3JWY62cnTZ1XFZhAPibRitubtruw2zhoUIZuAoRVmASJMQBwnV/zwwckEvvft0xQAW0CdzAGTWsgAa9fmJJfBCsHw/LYt2eWJhcMjOrzui14q85EKVe92XZzsXWIrHuVw3LJ//q+5tgn7GDtXYbSlJzAO8rrxKmSXm8sALHCEybmcJA/AwcdM6mtJSFJE4ayrgGJdPzk9ewAh+vpHxkKwha4MDJHF4DfHb0yWKu7uVhCv5xPQfcqQy9v9VXkHlbmZW+CI192Ipv5jzMGhxBKYuTuJbZeK7qcKOFfk0obCwXw1jU527YoAaXwXicQQcEryctOgVrDkRPZchTK+KYVzckxNG2ycU4QONKPHymHE6Yl5CjcYA49thj1T+hMtEzDGTbcNHKEarO2ytvfjHiETqtKKKFQZNsp3FwPAdyTWsUFbtBrGP5lgeiaQ4gLU31HuNAUp4DBN//7sPNcey8w/Vz1abOwHRtIwkSsklSa6M3rIAP3H0FCbN0AdTRr7ESWmPHxCLz1d312uqi38oZGquygeqGUjy3DO9Jx14Xkj5PWIH72fAbONA9mLd8M5wzbRf1Wr8MPFuBNwTGZ1LGXL/DjAOmHOVBA6ooiuoEXoceg+cANxZEaZfTWa7Yhwlh1liDS3JHpev5p1eX2/ogGE7zq+ffh3Nn7Oo51zg4k2qKSbXOLcF6rxthTEbHjTt6Q+sQNwDo2Qr4oDgsW0FJhhWEXO+4BiXPKnAezpWuL1Yde+Uwx3rj8SZjafyC6rlJqJEWTZLNVuA2XueSjo/vyxRS5WgOpOx2iwy82XkOuL0mnRSt9Dz4G2G8XhJJew6YjxuG31gE26/OBAQJoz53t39uBvz4ycUw98MtcPJ+Y+DOLx7q6ed43Y6UytAaH0X1HOCXDetKWChSEgsquucAguXQjc5CDsYB1BsI4tprr427S6EE4au0uXRY5DnQ2ljvxI5FSGXo16jz8W2UCREdiwb2zqQcCu45kDJ4DvidZ6+1WsTVW3EQsUHbLknPAWRnT5/vYJng10u/Bx49AcPp2QaEIEFC1lij4j8XN9M9ByKFqeTQ8XomDRhWoK3m8bIlaek3QeeC19hxWy5j44AWVuDkRA7O0Uw8NG81fPvs/dUzFeQ5oH+X9mnSYmkOeCY32d0Hk3sjtRE8Dl69NwgSRjtGdlokaJiJ4o76/oYOj3AogsaFnz+zNKsy69eVro9d7xOcS+pGQFMqQ91zwGSc4F4guubAgEl3JsRzQDd+6ivP+cyyEzWsgMq0dlsXjGhthC0dvdEMSp6wguTbMZ4hwjam5uw5oN0TDCvQhQW1c/EzcuoG/ySuQVDoQNx0fG7PAWaY1I0D1jXBeu3owcR/QO3c83Zq25pgzwHuJZHnVIZR0m2b4NfBFe7IwlFySa+JzxN6YvrVHXrujtxzJAx9KaNPhM+pqd3g/UtQWEGT7jkQIEjINQf4M48LZXFCkbJZUKFTxDHjvOVb3N4+ojmQnHHgoYcecr1HYcJly5ZBfX097LnnnmIcqBD0+NVsOyxygUXXcJqg+8aIR7Box53wcZE43nDhYK3QgoRud9PgSZ3u8YC0MFHCfHkO8Puur1gSrpV+7drRW3IRNw3CoggS8j4LvU68goRMOCxCmEouHS+PQ6bj6XWYly1JS78J7grnxNBBxYUV4PMdNnBA0E2SBg7BmgMxwwo8mgN1gdkK+Lkk4jlgXYcgzYE4NqFsngHSIrnqwTdhO7uWujsqln/OB06ebI5exOwECS3NAS2sIEnNAf06m9oVXXPAdLu5e60e/mD0HPA5BUedfSB2isAkcetFRFsNN2EyKHnz0ufBcyDtTS2Z66RR16PQJz2mfi3MyBm3DQkyErk9B8x9NJU7DN6Hc6M4FyDlxoGMR1v211n3mnQ8B2gxZ6BongPZpkd2j22d8nPDL94nHJeS4TMOeL3HDx0Eyzc7YtV+z52eTtCvHeSZbgLDCjTtLlOWAdKKwTrD7wnWlbihSHHAtunnT79n/b4HLv7Da67+n4xJ4jmQgHHg9ddf93yGqQ2/9KUvwSc+8Ym4uxNKFL6CnMugl1aRcGJrWnmLm2KHd1TZeA7YIlBFECTkA0PuwRDFtc5POTZpzwE+mfIzPLg9B8z3J1oqQxIkdL6jFTbeKZmNA/E8B/SON87qm75yqwsSIp1WPcc+cMyQ6K7Y2eCsrIQrnpdTWIHuOYD3KO7AIShbgZ+XS9ywAr9sBUkYB7yaAwbjQB8zeESYbuBp4O6znXfhpHPJ+p1w6+OL1fuffGYafHT6rq7rg8+SnlXBj+wECd2eA/kIp9Gfc1PbqnsOmNs38GSccFIZMuNAyLNL29Lzns+43CB4ndbP169MJkzxzZ44/Tx4DlCfgpfb5K2WWLYCj7u7s00UI2ecaxBmJOLNUK5hBW7PAa/RgTKT0POC9VoPDcuqf7MeckdzwPKk0bz2AjUHEjY2mbJrRPHa8dPF0dt2/Crb8HfysMSU4Vs6ewMMuWR0NN+brghihK77rgkSmibaPLMQvyd47eKGIkUlrG16dOFajxerkIDmAGfIkCFwww03wDnnnANf+MIXktilUHKeA1kaB6wBF6pXh3kORIkRjytISJ0ZTTycnN9OB5/k6lMQfEUpbHDrpznAG1u8RsX2HPCslmheAab76GQr8A4guAuoJ1tB3FSGBq8GPGTc1bcwzQFuuEBXO3LFzsjJhSsDx4W7vYd5oJQD5J5Kg0HuRhp34KBXN16f/eqqb/3UXA2bQrIVZMqc3X2wXdEN2QpIsMo0ieWnpNc3AgeLmzp6c/OeYW3BPuMGe+pvnFWdXAQJdc+BJKu9yUNIrxdrtnW5rrUprIC71+qeAyY9Al/dGcpW0B8cXpNEXG4QfhozcVbD//P0feBrJ+7lKVtBshWwFc0wrZ+ssxXgimhAqtQ4z4fuGq8TxUjEn3Xd2KAvwoStVvtlK6DPmyyPKrfROgHNAasf0MMK6NzQaID9cFC2gqQXfvTHHctSV1uXtZAhF5elc4yyv6Bj/PS8aWrie8+cFXDCPqPgri8d7nruwrRMyDMt1DhQ7/YcCBIk5GG0bs+B2tjaNlGI0jbd/Mjbdp3NZ1hWuZJYoMW2bdvUP6Ey0N2kcw0rwFVvauxNsZzeSWf2oQdRNAcyYQWF9Rxwxz4GT+pItFHXHCB2H9GSJ8+BPt+VNFPnpg+OnZAB//PTwwrcgxXwNNZOWjQS7nG7pvkJXJoGnjSwipNmUJ80ZLIVpI3PC54TuWJjhxaWFjInQUIlbAkFNXAlDdYffTDIDUs0cAjquoc01/vGMPP6rF8iv0tGA0x9wGAbB6y4WxwM6U1HtoJqfNJI0Gt9RZ6Mdnjt6Pg/+NRBMHaI15Aybbeh0GatKOViQOI6AiYPgTirOjl5DuipDBNsu3UjDJ8IYbtwzH8/bbdBdNRZyzb5lpWnrKV2khv2wvoACovCCVDUuNxZSzep/OB/m78qsTzhfMLFDa5xVsP3GN3mI26b38mcHlYQpvUTlR5jKkN/d/c4z0dQZqgwIxGC3/N2SJ8EerQRQq6Fn+cAHYNWkAk0DOTiOcA1dfhfXXOgyTque+LtvS9JEqYrYQKffb+FL30BJpdwFyoaXi983pCRrU2+2aZ8jQNWmYLECOOmMiT9COVhw84RNyVtG0T/ZbYLKlHapnXbHS8wfSFAyMJz4Gc/+5mn4q9Zswb++Mc/wllnnZVk2YRK8BywBlMqW0FdXc6eA3wgFcWVWp942CJQA4UPK+C5zEOzFWiu1rolF1PSIEl7DvjF9XP4IEjvLJ00heFhBYHZCgxhBeQ54FGKjhBWQL/LZvVNjy9VmgNaGcgIRueEBgDczzV/fhPun7sSTt5vNNz5xcMSsVDTs4HHKvewgszKFbh1QUiQUK2i+IviEadOHes70eJx8lHDClJ+mgNaWBRvo3CAjM9ib4LGATq+N6zAWqlhxT9tylg4d8ZucNANj6k295QpY+Cpt9crI+KONdtzHihzQ6FJfBONM3QN8uI5oAlH0WVKNKzAkLI0zD31Z0+9B1PHD3G7yhs9B9KuOoP9kJ5z229Sjs/B+u3RJuGX/WmeK1VZNnoEesgVb+v6s10N99UZSsbzJmpYgaPzkHwqQ33Mwu9r2Opo1AliVCPRknU7ffc3YCin3yKxvq3bayrtWkEmktIcaPAJK3DCGerUOJVfZ64xhW1x4poDehhMzLCMzD7MmgNq2xw8Z6hOo+GUxrmm8tmaAz5lp3awOWZYgWnsRvD6QHUIP5r1/mb1bNCCiu7RaQpFyoc+AWkiCDkYB37yk5+43tfW1sLo0aPhwgsvhGuuuSbu7oSKz1bgCBI2WIJjvgJyfAXZL5Vhlp4DtOrHB5WFFiTkrsNRUxlSB4kD1EffWmt///qKrerv29bAPy9hBX6eA67JvPs76iAcPQGT5wC4wwpM2QpcYQV1gcaBqGEFs5dtykoV1xNWYNAcsMMKmEYE3ufJARb8bOCrEFzxPJsqXGjV87C6RGEFZMWn86SBw7ceWgibO3pdxjIcyOw1JnONEb26ubIVeIwD0ZTx/TQH+LOLZcF6kmu2ApPnAK3MoPcVrtpTTCg/vpps1tbA2MHN8H5Ph73igs9hEunbeGpbk+cAHhsnyfOWZ9oljh7ukE05vJoDyYcVmIwDUdxTdYOi417LsipYO4iTrYDOGb8e2dYY6Ry4YSAbPYIo4oJ4Dlj2OKvhvn2+Z7KVD0FCxyATNGnKyXMAvYgCJo5RjJxEkIEx6qSH1wOvur97W/zebyLoSdVqCivweA5gKkOvMGJSYQX0lyanbpFAx6tADznIFZMBPspkPigjh97m5GIcG+DaGgGeG/SZ3zNJ475B2n319xzQBAkNISp0L3Fe8bHbX7LKC3D+nbNcBkxsR5MYk8TVJxBBwgSMA5iZQKh8diQUVmB7DjBBQj9Dw0Bcz4EII0N9km2rFafQnTldWOPAgNe90de1mSm4B61cPbFonfo+KSEqft+zyVbguP9G9xwwpbBkDhO25wCVTe/Uonii6G5kQegDMJOKuT6AI8MFdYKmFD5JwJ9DvMbZxtAWQ/XcBL+O+mCQT7SxTLhC9aXfz4HhjWn4nwsOg4cXrIP75qxwGRLpOuBlwWeLPAfQqOLJVuBzzfr9Uhlqqtx8IpMZKPVlbUQ1pYGi11T/hjQ3ZIwD2kqN2taqZ8NaMh5Fa62VZq44nUs7xw0Cfmk7R7U12eXkQpC4+nPCvqPh3tkrMuXI4hrp2QrykcLTlMowinuqblA0hRXongM8W0FYH4BM33145JVnThw9gqjigjgZq4WaWKvhfZFDv9J57XepPc45laFWV3ASrJ+LPnEkI+eV97/hep50j5sgA2PUSQ8uxvhd06CsCjpBgqvOJN1tWMgIEjoZZ3IVJPRkK0i5PRZcWYkCvApyxdTWRNm/J6yD/UY3tOZiHKPikaHYr3zhngMUChw8PaT+elNHjwphssMdAzwHNjOhRD8DZjbpCnWitE2j25pggyUwq/f1QoKaA0Jleg6QQn42g15se5ZtzOS+xhU/xwIcPlDwd/n1TgSC6PHRHOBx5IUzDvBY8eBVI4qjxwFklJWrpM7BpTkQKVtB2sdzoCa6IGE6eJLkDSsITznGj8OF2aKgD8C4GJtftgKKReZhIOo8EjYO8MEDXr9s3GSz0V3IF9xlmTwG7HZCGygNWE9BWwPAEZNHOMZGQ30caoXdYN3A+2e6PP6pDL2r+K6wgpTZcyCXyQ13Nyfo+LSSQ+dE7/nxqR5g7mpuCMN2z1nFy8U4EOw5wPd/Tfu+8LFpu6jXZx4wFl68+mTYd+xgZ7ssiqF7DthaGwm23SYjYDZptkxhBVTVXN/VBp+DLtT6nbOnxjIMEGlmwPAjjrgg93KhWGEdfXrQ6xuiFjyhTgK+ohrmrREVvQ8K8xwgcPJzzrSM8XXiiBa459Ij4eR9x0S+BmEaLPg5fk+aRKb96TpBQW2WPlnlxlxHkNDd5yWXylA3Dlgr3ppRQs9KlPmOdGuSq0+mOqMLIEYysLAy6WOL/oQ9B8zjL7cHhp8gYVBYAY4R/vX/Ml4wG3f2Kg+AB+euzBzfYByoCVANSudhHBukY0Bcctxk+7V4DiRgHOjo6IDvfOc7cPTRR8Nee+0Fe+yxh+ufUBnQJJEmVHGNA4+9tQ5umFcHzyzeqN4/MHcl/OSJJZEFCZPKVuD1HPC6zBdKzI27XdEcMiys4L0NOyOvXCUdTqJ3XFHugRMy4PUK8BoQ/D0HeAczOERzwM8NU7+v++8yJNLASlfFNWUr0AdUVDYyQhFORoaB5D0HMFtBSD3KVtCqKOk9rXtOVny8fe40VTSxyrw35fSmuoVpnci+hCtIQeEtkTUHyHPAqg+8jcIsFUjWngPa5Jcfn4x0QwbVu9042TlRPaD2epO1IqJ0KWoS9hzQFLa9Whh1MHFUq3o9uq1Z3acoYrPZZCtIspp6BAmzyJahysTKWqMLElr1A2Ncw7x++EQB1cdv+uci43akPxNGkKEjjrggLy+thpPhinuLXMoG31E9B5J0A/dqDjBjao7NsSmTRZDmAKfPSsWHQqG4SkrPMU1o/QR2kajibby585QrIKuCjv4dP28e+6+XMRePOS64y/tQMnLoQoimtoW8CpIUJDTVGb/wV47n+ruyFSQnSEg/Ra8qU9+oH8M3lWGIICEtLqBRgEPnsmyDo3dBLAoJf41iwIyLnzA0PSeHTByeec+MhkIOYQWXXHIJPPfccypl4fjx4wNToAjlC8VQ40rUqq1dsVbEsPH4t3vf8ExAtllxcKu3ZtJB6egpdpIwDtDEkQb2Thwvs4DnwZXRBBWXaw74uTdSB6kLQyYlwOLHjgjGAT4B0udctleAdb1NhpegbRzrt9dzgFbndZfOqJ4D+M4v7pMPrPQVY/06ZIwDfmEFXuXmJN1l+SoQDpriTpKiClrpugv5gu4dD8fgk3JcZWmyUjvZE0Tra9MA1DZO1dZCW2O9CkVBF3eaWCP4M9zOP42od6Lu0hzQPAewvjieMrkJEro9B2pd9Y8mYLSKz9sOmvQMtzwH6CseVpDLwJOHEviFFfDVfefeeA0p2dhPuMo/4rjkJ9d26885Cm1FcU/VDYr0qOOzqWsO8FzgYdkKeF26+s9v+pb7S0dPhJ8+9V7o+QUZOmKlotTKi4PwF5ZshP97dbl6f8AuQ+Bvlx8Lf39jVbgB1yNIOFCQLEG5rih7RXHdivSZY6QDf0vnSr9zdEsGIk16rvv7W65QOS7e9psX3g8wZEDka+4xDkTwHFAhMzlpDpCR0e05QEYTWwiRPAdYGfu075I0NvF6j+2qGgdEOD/dQOHKVpCgICFffKqP4Lnpd9+pHTRpDkTxMHp28Qa1HR9HbTOEE+RzHEuYdAwu/d85aixpjz0kpCAZ48AjjzwC//znP+GYY46J+1OhDI0DNNiM2mm7Gw+z4ei99Ts9jYcnTaGfIKFLfCaC50C/e5WaJlPcTTYfqxUmaEASRYyK3K3HWHG8SQuwGI+ZGnC51voJEururhyasETxHKAJIb6lXMsmYTZy2d7W1ati23Qjr6+GhWeFZMAeWH3nb2/Bhh3mgVVoKsPUgGfARc8L1TMil5ROYSuofIUgalhB1M73iUVrC2Ic0D179M4a2wHLNuS43tdY14AGoAbNATRz4KAVb/HLSzfBJw/e1d4GY1nx/vkZ5pw6aNYc0LMVZAS46Lvs7rNu+OCv6TkcQmEFfYawAqse6KEzSpAwgThrd7aC4HaBC5KZdF1y8RxwUhnmL1sBep2gkRQnQlGE5HSDIvcc0DUHeNhUkOeAKU2mH/fOWQHjhjTDuu3Z5wmP03+Y6tFbq52VQTJIcQO8b7YCfeKUB0O9OZUhJJytwKuM76et4RgHTJPdvkjjEeynDp04Ag793pPq/RWn7gOXn7yXMdZcN4ToBrX+LD0H6HfkNWX0HMjiflJ59dS2VIcckWmvcYAm1zRmyJfmQJPVh0TZv379+fskBQldWTk0UV/X8ane+YYVkHGgLisPI2w79cWF0YMLN47VwfrIy5Lpq1P2c1hoEeZyIbbJZPjw4TBihH8nI1QGJOQ1whK4imociNJ4UN5mHbd7ebhoYZSBoe45QJNy3igXKqyATomnsfLrW8hKPm3CsNA87yZX+GzQVwT9BAmjaA6YMhH4CRJmfuf+SwNn9EL5zK9esTtOjG37mhXrFuqyqn1O2+HACmM9ie99/AAVF+0nxGfKf66L75BLHWXkIIIs+NmgHzeuIGHUzveulz4oiPaAvkqkd9Zug+FABM+BzOvlm7tgo5XZ4Dt/XQgn3/qsvU1DSIYHxz3efS9xQOjKVsA8DGzX1yxXJKncXBiJXpMhE4X+EJx0YTtIzxZWAVqhHm6110Q2ngNYl9AI97f5q9RffN/BngFuWNV/lyl3jW3gcVyBk/Ic0Op9gk13l+ahQR5KZFBsIysV46JjJnnaDbcgodlzQK2uBhiI47QXa7f3wPmHTwh1NQ8aBIfFsvuVDc/1xSUbYOGqbfZnFAbDPTGiisbmI1uBe9IUX6PFBE0saNUcr0l0z4GU0XOAVrujpkPlq9Z7jG4NaDd1I7nXaO6HVzCSGwfcLvwE94rJZnLueJPVmsMK7OvlnQDTuVIGhSTrEx970v6jjIuD6oXHcyCH8rqMYDVRPAfCwgq87V02GizIDMuFH2KGdOYDujb0DIveQELGgZtuugmuvfZa6OzsjPtToYzYSZoDtudAsiuTpu2ieAXE1hzQOhpqB1xhBQXyHOBiVGGreVwJOExYJWzgFxU9hMEvZ7k7W4H2nW0c8FcrNhkH6DOeBoxi29azFX6Ep7MLTGWor5CwsvDVk33HDQ68fkGaA07Ig9lzwJ6YJeQuS+eg1+eog12aBIRRUyDtAT1tlf6aXzfHcyDz3rQ68ur7m43tx3rmfhvqzk1GCK1O0AqZ4zngbKevbsXFmVA6n+khUDyuGwc29Oxx8U5qr42eAxHqCD5zx97ytDLCff3e+eovvt/Z4wiVckMBh18P3SjGB73ZeQ647wldp2TDCtzXmU/S0ADwhaMyE/Dj9x4FB+46RL0+YNehnv24BQnd5bQNSnXBGWviThImjWoxxtfi+yhpDIPEBXWojaa6csFvZ7ueN9K7cHsOpCNOPpNvb0zGmlzbNTIcUfsfR3PAL6zANjREbEP49dX7QD6u0I0NerGCrnmQ5wDVZWMqw4CV6zD0bDG6IKGeJaE/IKwgyf6L74v6+Wi6V1q9yHsqw2jZCvyMUJ0BngPZaLCYtJiyMWAmBR2Dzl/XFhKyNA7ceuut8Nhjj8HYsWPhwAMPhBkzZrj+CRWmORBTkDDbxsPfPVjbhn0cKVuBrjlg0MjA/SQ5yAzLT881B3zDCphir5+wCrL7iEHJpTH0GAey8BywqokdVhAgBMcngbQdvx5R1bP941m1gScbcPNz8DMu+IUV8GwFrZZoj5/mgJ3SKbGwAvckKa7LeNRJQD4Egkwr068v3+K5bjxcQl+lVOdQ4/YAoG3w+z++8qHv+RBhk2V9lTosW0HGcyA3bQlTOA0NWuh4FFZAq/d2LDX7DWUrcGW0iJhWLCiLBX/EOkM0B3iYhe3CGhCKFAXHS8MdHpZsKkO354AnZaoVMjJllyEwojXjJmt67LiBU0+5yOPfqSsKGsBHBftT7AfQA2qM5cJ7+tRMpoio/QP1M7Qiy8FQC+4N5ldXEDTm4ve8//BrY/WJcD6Mkeawglw9B1KubE7KcyCiu35wWEH0NiTIMyPIc8AbbpedcaDP13PAyZCSlSChnWHK7SWE7eArSzfa31M95efjiBXmV3OA2rco9yrIc0AXJMylXtr1vDZatoL+MM2BxtqsPIyGNNd7PAC4Rxx+n40BMymoDUBNmcx70RxIRHPg4x//eNyfCGUIqdbH9RyIIuCED6fJfSiK54BJ2T5oQq6vTPoJaOKu8mlA5EV1xaKGeA7QpEMXVtm4owdu+ufbdtxdkhkqcMKLq4N+YQV85S8VFlYQ4NbGY8vpM/q7aktXZPXsqIKEbtdm57Vf9gy9s8RzwueAhxXoaRZJZJGwB0lJeQ5oLu9hRiYTWJcuPmYS/PalDwouEISTBjT66PdWv4ekcO9yY7Ve254DmugVPhumPMo6dKn8Fmed+PaomgO19mAsV88BPlDhopy0soj/sL7is0nn4fIc8IQV1NntWlAdiZLFItxzwDEOOIYbtyEl8xqSy1aQoBe6njJSjyt3XMnrAo1y3ACghxVwg1JQFok4sdrcHbdOMxTFXYnDtuGI2cvhucUblUHgmjP3g2/9daEKqcjU+7RaNY+SXvcjVsq+QM2BALf1pDCleMvVOEAGu1bL9RrbJl3Y2NdzwOpPaJLLBQnV55E9B1IB3gF8LBVsgAk6XpBnh+3xYPQcyP460+o/jn2wv0DhReL8O1+12387I4HBENJMYscJGgfs9pZ5RuWqOeBNZTiQTFaOOv/2KTRbQYDnANdgwSOY9tB+0HhPu8Pff/mYyXDbU0tUm4VaGfi3kHH/3NiESFhBQsaB6667Lu5PhDKDx5jSSlTUDsst4IRNh/fBG9bSYGwM+CH8PQeir0BhI0ibNNVlGjq/dsAkkJgkLvGwECG5jFHDPQnUhVVoxVUfwCbhOYDiMR2bOu3Jmb4a7nbPd8QETWEFpttob8Pi8+kzuh5+ExATvvGsnpUc7uY6EMM4YK3cNjfApo5e1anQBLFFy6RAcemEPkjCv1w5N27HSNfeVm0PiZ/349Sp4yIZB5IUCKLVRlNRabWRVg9wctnrEdZyew7oqyNRDRlhYnY0QPPLVkD1xQmPcTwHshVUc1zRnc9MnguYXgqPj4NKvQ4YBQmV5kD4QDlOKrtwzYFaz8qa2zDnb8zzezbsfedgFIurOaAbrKitxRXLoOO7PcTcdc0OjQnJVmAKK/AbjF/7Ebc7Lk04wjyi/KA85zix2G+XIZ4wiPkrtkRKr7t8U2cWmgN58Bzg9yNECDhuWEFLkzNBpbLjc4p9hN+50H3p9Ymhj9qGBIUVuFztUxnPSN2LJSvPgdSAPQkNSmVIdSWusQeP98HGDvV6wcptyhNMLx0VCbNoqfeusALNcyDBMBXHc40LLoafX5Dmg96WkmEkKSNYNtkKqB3U76vuYaQb+clwfdCuwzy/4X3ZdmsRClNLF0L02N9zQMIKEjUOIFu3boUHH3wQli5dCt/85jeVQOG8efNUqMGuuzqq0EJ5hxTQRD5uI4+Nx/98dhp8+y/zYStbyBvV1qhyo/qlDnFbu32MAzE8B3iZaSLqNxHLd2w1PzeV4zpANZlbdPWVaII8Bvx0AXK572gc+MAa2GFHoRsH9GtFXhc4aKDTDIrJ0zMa8M9oe931LAj/gSdE9BwINkRQZ4lu3co4wDQH2qzBoX8qQ6eTNq2ajw/IkhB0rvokKa4SPU68cBJE6UV1oiicxyFKCiT8Hr1jHLf0lOtZoPunaw7Q51ENGXTt/FPIuVep/cIKXCvldUl5DriNga7j19eq1Zyt0KcmcC1NVAecbfCeYpWgU8uEFbiPkauHSGeEbAW6QKPL28hwicKeDa/nAOQtleFQq8/TjYbccyBI68POSMAmo463iuM5EBT/rk8oLj9pT3hg7kpX6jripP3GuM/DKieF1MWlsy/TlnX2pVyaPXTtN+yIlpZsO2tbfMMKPN5d+fAcYOFKWbaXOlQXWi3PAbyHdN9Vmjv0JPAxgtFvnXCoAVde+cieA/3+ngMmows9k3qdDfIKpecX2x3qB/FY3E2cVulz1RzQ24DXV2wN3P7FJRtdZVSvSQchD54DXBcmTrhgkPcFiXcmUf9d9dweXw4EeA4EGwdaDIKEBHmyTrvhMbUw8qNPHQT/XLAGnnl3g3El3p3WMNMuDDYIvBbUOCCChIHEDrZ48803YZ999oFbbrkFfvSjHylDAfKXv/wFrrnmmri7E0oQmjDgQ7RsQ8aKS4OEqJyx/1i4bkbKnjxh4/HHi48IjBHnDWPQ6pLptQk+IKGBvV9YQb4zFvTrngMBMbO80dYF7ghaZSAXxSTDCtBbxBZuNKzg652dk6bL+SzI7U73LuDb0anvOaYtNLatJkyQ0DNAyk5zgK4xGSywU3E0B+pdHaqerYDOcUtHr288N34eNTOAE1ZA2Teyq7/4bJ99oNkgkQ+BoCgr01zjwKT+rwsS6l4ZaMjQ3epNkLukX/NhEsx0hxVQKkFncBEnBjWu5gCB5aEJBK44DRh/U2tnNaBBcpSBehwPEW48Np0DlpuOqcdVZ7YbiKx1QM+GJ1tBlh4zuWgO0EoTXtPAsIIBr64AbcdDUYI8B/R7NW334fDQv2bSR+M+7774cKPiOR7HXpnO0nOAjD9YLPImQ4O+nS6zNfwZ08Ni/J4Lr4t7HjwH2IoqtZe5eiiQQbnV4DnAMxgE/RbPXQkZ2q7wlnEgYtl43096GFFC6jwiwtqYimcqof1Su6OOlcJz5QsvtXY917MVRL3OQRoWfuyw2iF+Pl6xwuSMTVzwz9FUCN+/NzsEMw7ongO5CBKydifIeGGLP6fNfYIdVmDQHODgPaawyv3GD2GaB94xA5+Ab7FC/9piLAAlCRWF2kdJZZiQceDKK6+EL33pS7BkyRJobnYGFO3t7fD888/H3Z1QYmAj/clfvKReY8Px//66MHBAGETmmcs8eIdMGuHE1Pmqyzuv/dzBYhkHrI4COy5dwM2z3zwMSlz7Z2XFdpuKYToHl8eDj3GAlNNplSgJqLMd3Nxg3yuT7oBfZxdFzZd7F/B7oYcV4GA0LEsDuVBT2kcdveM2rULHCitgscjU6VLnSDRa4SsEneO6HT2B8dw8M4A+QOPXUE9lSEYmCu+Iwz5j29RfXYAsHwJBcbOYOFke+D2zOnPbc8A9QMP3nz5kt8D9Y7UkjwM/zwGqJ6aVe9fKH9su12wFfLXZKavXOMGfSz8PBy5KyFMZBrWXcVLZ6SJaBC+PrrXh8trhoWERtA7w+74UiUdpHjNFCCvAyV/Qqr9JeJY2c77jYqLesuj1iIugtjTUwbF7j7brI67wE9zwnrVxgN1fcgFWYQXWuUwZPyS0rowd0qQ0C0zlCvQcyEsqQ2+Kt1y9B6gNoNVVHD8M6Er5Pv0S72/wnlIdttPjRbxvrrAC6/mIIsarG5LpO1Omkov/MMcTf471ij/P2FfzyV9czYEoXmVBmAzIdohGgtZD2pU7rCCC50CAWKQ+vsotlaFjBPNr87kwtl9/FRZWYDSYK08ZtwGXw/uordbiI44zi4GTrYC0pESQ0ETsqzJnzhz4l3/5F8/nGE6wdu3aWPv65S9/CQcddBAMGTJE/TvqqKPgkUcesb/v7u6Gyy67DEaOHAltbW1w7rnnwrp161z7WL58OZx99tnQ0tICY8aMUWEO/f3uieyzzz6rMik0NTXBXnvtBb///e89Zbn99tth0qRJyuBxxBFHwOzZs6HaIOstuv7rbO/uzyrvOV9dIxd5P3fHKBN/PhiM6jmAE1XyGPDVHMiz5wAfiKBVNyj2kQZSvJHXIVc+PMekXGtplQgHddQxmMIW9A7Fdpll5aB7rZ+frr1Qaw0JqE+k7/F2+WVpoHzjGP7AV3L93ey8x+adcNRsBWQc4Ct1tHLknLe+2hs+SEqzVXO/VHL07NmaA3YqQzbYjVkNqJ6dtf84OGGfUer1eYftHkvhPCpxs5iYVj7CPAdohRVp1FbdScEdJ9xhYqC8zQoSJOQx9nou7rg4IRNskK09+ngMGqTjKjdfoeZQKFjmN9GMAzyLhd+kj/bb0dtvbHOMMbnairlejjCPEno29PRmYfcwiVSGvmEFDXWBngsuzwH7PNwGVKyHdrsUwXMA21x+fK6Uz7NHRMkQEAbeX92LEOsRXxEMqyv/dvLenkmwCd2LJN+pDLk7fC59vq05Q6EAA6gxYI03Qj0H3NdFz1YQdYLozlYQ7DnADQ76M4NGDL+Vewyjo3Lakyo0DvB+nHkK6PoUpnPRjd+z3t8Uy2PAsz/XolL+NQd4PcomrID3EWSIizJOCMNeuefZfkLqhan8QYKEOnaoXb9jHDB5DvBQBworoHFcoSGju3gOJGwcwAn29u3bPZ8vXrwYRo8eHWtfu+22G/z3f/83zJ07F1577TU4+eST4WMf+xi89VZGnfSKK66Ahx9+GB544AF47rnnYPXq1fDJT37S/n0qlVKGgd7eXnj55ZfhD3/4g5r4X3vttfY2y5YtU9ucdNJJMH/+fPjGN74Bl1xyiUrHSNx3333KIwLFFlE7Ydq0aXDGGWfA+vXroVqIGhMct/FylL/dcblBg0v+u6BtwlaNqMPkrvn6QDqfKxbu/TPPgRq+4mvyHEiHWjRpgBhl5TtuWAFadJvjeA5oq/4uQUKfbZ1UX+Z9UINN6bnOmDpWvf/49F3g/MN3d7mlhbmskpsnH6C6NQfCPAcorKDB40XTqsXl6WEgcdLkPLFobah7NdVTO1sB976I+WxS54h1afKotqwVzqMQZWWaq66bJtvO5DPz3pju0Ko/MyYMh08evIud0u3+fznK+q13NTeozeKQ2CRdN3L/5Z4Dfl4sYVC9rw/yHGBhBfhcmrwNePpZ+k1UF18/YxwZBXYf3qL+4mFNRkPuwaGHWbg1B9KxPUqoGng9ByB/ngNaP+VoDtTaddAYEkArjMxzgDZzjBzB8e96m0YilNww3Gq1PXyl372aHL9fwPPl+9tqDeTxeaS6ibeS6sqYIRmjG0Ht+RGTR7jKEjVbQZKTuaCwglwnYrbmgDXBoRCBsHh3vL6udIAp53dxUxnyfitIkFB/r9dZNK6Hjf3QSEAZSJRBg91PFValZVmh9lC/Bibj92X/h+LV8aF2ibctukhikpoDvL2Nk6oxaEJOYZs0tsgprICltvXz3PDoHxjGPk4qwyieA3WOccAW1TX38tR2FzusgIZoojmQsHHgox/9KNx4443Q19dnW4Rw9f7qq69WK/txOOecc1Q4wt577610DL73ve8pD4FZs2bBtm3b4Le//S38+Mc/VkaDQw45BH73u98pIwB+jzz++OOwaNEiuPvuu2H69Olw1llnwU033aS8ANBggNxxxx0wefJkuPXWW2HKlClw+eWXw6c+9Sn4yU9+YpcDj3HppZfCl7/8ZZg6dar6DXoi3HXXXVAtxI0JjgK2FdTYYedBGQPwc2MsVASvgCjpDj2eA/XhxoE82wZcAxR8ZhxBQsPAkHk8+MFFgCgWNqn0lSgUY09CYmgO8HPhObFd27KiZlJ90edm4wC93mfcYHv13hEDJONAsCcKiTfygSfvhMNW2OgakOYAiQ+awwrM2Qqi8Nf5q0Pdq22FXUOYTFwXa/580LXk55YkfGXaD65xYJrQkvur7TlgWG2hyRxOTieOzBg8Rg1usp97NUEIMMy5wwV8NAes+mZ7GODEKUfPAdOqi8lzgVZzcALn5zlA6WfpN0H6Jjo46XvhqpPs94dNGg7/deZ+6vXItkbj6rJzDuAYgjU1b5MHSDbZMLyaAwl6DmipDPUJmCmswChIyEIHdOFCqjN8tTWq5wBNtskwTG00vxe5eg5w92DuOaC83axzJiMQ1pUHv3p05nxqauCeS4+E8UOabUMLF8zTY+Lt89QmQ/kw0ptWVHOpOyptobVT8hzoNxgHTOeiG6JxX9TeJJrK0FB/CH3++c66HaFjPzw3LuTmtD3WZJQZUv00B/y8E8jNPC7nHzbBKpvzGV1zxwsjD54DzKMzSnuv30+X54B1DykEJ7dUhuANKwjJTMHDTXQjaSTPAeZNZ9LNMbXd1KbEEZ1OEuoPnWwFElZgIvbdwUk2Tq7Rhb+rqwtOOOEEFU6AIQE4uc8W9AJAD4GOjg61L/QmQAPEqaeeam+z3377wYQJE+CVV16BI488Uv098MADVZYEAlf8v/a1rynvg4MPPlhtw/dB26AHAYJGBDwWF1Osra1Vv8Hf+tHT06P+EeRNgWUmw0k5sWZrR+Tt+voy6Y2CwGvAm6H0QL/LbN/Z3eNSQ/XGQqWM17GfDTiwIQ261l09GQMRdly0nSqHge7eXujrC28Ms6Wn1xF5VGVJW6uPhnPoNJTbBOWC39HVDRF02ELZ1pU5bktDDTRZ7vEd3T2eMugdWE9PH+Cl67XOEamxzg/Lx3/fzQayA6l+2zqJ1we3o32nB9zXpcWKIdzW2Wt3/G3WwAwH7ca6YnV8NFjrYc9mL9u+yzq2H6Tr0GoJ9JARBfs63bheW+M+XxhI2dsqXQDD/msska/NlgunCfwdDqoWrd7qqkcpFkLV09sLdTGa9G5LlRxvdbN1v3d09eat/Tpl31Eqi8m1Dy+CzR3uY0zfbYj6no5NA4ludm/6rEELjkPxsxpKqcXuf591TnjFaiFz33r7UtDTl7m2aJirse5CT1+/8VwpTAXrMP++zv5d5ng9Vl1WgzFrG799htFrlRvL5hje3bUFy+M8l332b/D4/JhDm+tcv6H9RC0bH8zi0XZ2Z65da0OdmgyhYWJbRzcMbdKzmFjPLsZyWs8/tdF4j4h+FPS0ynHwboNh3JAmpcLv92xg/PpaS6Uf2+++vhoYsOJF9fbFeD523Qjejiaz2P7xfqoOGlzGg3p1PdN23fJrH7ENS9vXIbOdfW3T+J33ehBd1uKGXbbefuiw7kOT1S9Qm8if2Z1dzpiE6mkcsH3lbO3I7A+bUFvIi9UjOl5bcx0cOmGI3Tbv6OpxGZb92mg9JCzb5ycIvPZ0PwZYe9nd0wsN2jMWpf5wAyq1m1i/6b6TYRzPTT+Xji5vX297g9U6iwNRrkFHj7tf5b/RNQi6sY+2vk9p/femHd4MGCbo/nd290JjrTMRxP3y1WKVLcUaZykvI2s8c/3f38paV8DE4ZOGwS+fc54thAwtdF+xTUqqPtGYIaNdEVxfeZ3BbVzfsTEfPSNknMc+Odvy2gbI/n5IW+MOfYyM9YDT1d0Lfay/wHG4La6sj2UMUJ1V9Zjq1YD5WdfTLuNhizFXoqra7dN/Fou+iP1UlH0UxTgwdOhQeOKJJ+DFF19UmQt27typ4vn1CXhUFixYoIwBqC+AXgMPPfSQWr3HEIDGxkYYNsydMxMNAaRtgH+5YYC+p++CtsHJPBo3tmzZogwTpm3eeecd33LffPPNcMMNN3g+R28G9DooN97fhk9M+OT4/bfmw8yVr0faJ7dQP/Pkk5AZN2Sq3D8feRy46HGmwXCq44aNm2HmzJmefb63DFujTIu0fsMG4zbEsh2Zffb3dNvbre00V/unnn4GRiWX0t3DJmUsr1eDQizL4tWZ671ixUqYOXO5a9uVyk5TDwN9vYHnVwd1kIIaeOzJpxMp+/LVeINqYMmiBdC1A69xDbz06mvQ8Z67S9+yNbMd8fgTT0BbA0Bmvpe5ti+9gOKk9WrSz8+hs9/Z5pmnn4bamkyde/rZZ2HsIICNGzP7fmP+61CzwjnuB+sy12vp8lUwSP28FjavX63+Ygdnuk5dXZl9pXrx4tfA/DcXQOu6N9V3czc69f2dJUthZt8S4zXBetnbnynv8qXvqt9s3IYVq0ZNFpe887bruXlv8Tswcwd+Bq76hhOKXvt0uGU9E4184OAeeK4j3IL9+qL31Dlv27JJnXPG+J0p36OPPg5xjPHvfpB5lpZ/uAy2N6bt6ztz5grIJ+dNqIFfvu1ua2q7trruYcfOzL17ZdZs2PZu2vXs48AM+6A3NmXuIW8rXl+f+WzTxg2wpBfDwurgwxUr4JlnP1TXKdXfBzt3YkWtgVdnz4bti73D1Q8+zBxn6XuLYWYX3vMMq617ubMz057Mt46/fetWWLYUParqYOkHH8LMmctiX5O3V2b2tXql0x6sXO60dcirr7wEG9dmPntj4SLYuRzLXg/dXZ2ua7dulVO3X335RVhp/ebdxUtc5+NHRqw+U5FWrNsMr6cwZVgdbFy3GurSuO8aeOypZ2HXVvfvunsy9+zFF563n/PtOztU2Vavcc5l5Sp3HWsfVwN3ba/1fTZOH9MJ/7s9cz5PPvEEoMzHu1Z/tW3b9sA2koN1xg8c1/alMuc8+4Vn7fOf+dgTMNjqp7aoMtTA3NmzYPX6zPm8/c47MHOn87wjW63tXpszBz5QfVAdfPDhcpg58wNYviLzuyXvvmNNMOpg1ZrVMHPmStc+lqq1BudhfnPhW7BGtfF10NWxQ51zp2qja+HlV1+D7qWZevyh1edlypvZLg6be9zHXbJ8Vaat3bQBeroy9/6ll1+GtRmdYli+M7N9TSrTzvdabe4LL70Km7dm+hBk0xb3822fJ+vP1fHeex9m9mMblxzrrHu1cMGb0Lz2Dae9fOwJ1xgkav1RzYe1j/cXZ9r/1WvWwtbezPXZvhXbglpYvtzbt2/vdV/fJ556Bjqta7bU2tfWiPdtkdVOIR9q44gVVj0jnnrmWRhnDUvXb3B/t27lB5HGfukUPtQ18OwLL0CrOoV6ZXzEsvb3OmOCNatWwtNPLnfGejMfgSdX1cBa6xkOOYqnDUB2a0nDys5aOHD4ACzYUquMqPPmvJppY3bstK9XV3emHAvfwDFqnTJMxH0G/Fhh1fXenm7YtKFLXcP5b7wJLapO+deZeWysgaxbnxm34tiixxpb9OxEo38tvLlgIQzfuCCr8qUGMueO46puqw3Xz5/XXeRJbdyLtop0OvP9C888FTqe2K6e8VqYM/d12Lwl87zPmzcXepYZPKr63ePG2S+/AO+5o5IKwjZr/PrhikzbtnVzZixVKjwR0E+F0dmZSUFeFOPAihUrYPfdd4djjz1W/cuVfffdVxkCMIzgwQcfhAsvvFDpC5Q66GmAOgUEGhvwupx++ulKXLHcwBWYB2993ncFB8EVnsvPOz5STDJasB5+1Knk7WedoVZw/+PVJ5Q1+cSTT7EF5WwXyFlP2u+HDBsG7e2Z1Iec1/7xNsDazMBy2PCR0N5+mG8ZXsUQiIWvwdDBbdDenkkD9f6GDrj5jUw2Bs5xx58Ak0e1Gq/Lax9ugfU7epSo2aETh2cVk/3hpk6A11+Exvp6aG8/A9a9/CH87cN3Yfwuu0B7+0Gubd9YuQ3gzVdhcOsgaG8/3nef17/xDPR29sFRxxwPe1vK87nwy2WvAOzYAccfdRi89/KH8P6OTTD1wGnQPj0Tu038fOlLAJ2Op8nJp5wCo9qaYNPOHoDXMs/uqSefBN+b/wLU1Nap8yVUvNkcHHwDnH7aqfCduc+o18cedzzsPaYN/rBqNsCOrXDoITNUrLjNgrVw3/tvwqChI2E0ujdvWAdT954Mr6z/EAZq3McgbnjzGayIMGxIG2za0AH7Tdkf2o/MuCL2vL4aYElmhLvr7hOhvX2K8Zooy/6sp9Trow+dDg8uWwADtehe3QdNjQ0w/aB94M8fLLK3n3bgAdBuaSIgH2zK1LfGhgb48Sf2h5tmvuPKVY5x9v/vrP1U/ORzd70Weo+m7rMHvLjuAxg3ZjS0tx+iViH+89XMc3PqaafZoolRePXhRQBrVsKUffaCCSNa4MFlC6Ft+Chobz8U8knL4g0Ab7sNjBN33xXa2w+03/92xSxY2bEdDp5xCJwyZYxT3rUrlaX/tNNOg8b3tsDvFs+Hwayt6Jy3CmDpWzB2zBg4YM+R8Pfl78LYcbvAccftATD/ZWhuaoRhQwepfR966KFwwj6jPc/7/f87F2DDZhg8diKcceYU+3nHe3kLth11Daq+pResBVj8JoweNQL232sUPLJyCYzfdTdobz8g9jVZ+vRSgBVLYdLECdDengm/mPvPd+DFdc6A/+QTT4B1c1bAK+uXw+6T94LD9xoJ8NZrMIS1b8j2OSvgH8szE9aRe0+HSc3b4MV1K2CPPfaE9tP2Di2LijOfnXkuU/XNMGHyLgArlsG+e06CNYs3wI7NXXDIEUfDjAluw/01c5/CZUk4+aQTYXtXP/xk4SxoaGqG9vYT4C+b5gFsyeQlHzNuPLS3T7N/144aEW+tg+/OfMf2EODPxtF7joT//d7TmW3POlP1IyPe3wy/WPQatLa5z92vL8IBF9aZhoYGfzHWVzPH+Gj7GXDd60+r0KPjTjgJdhk2SH3+/YXPoZsUnHj8sbB69gqYtX4V7L3PvtB+4h6uff3Pe5n28agjD4em5dvgkZXvqbFBe/v+8Ph9bwJsXAv77z9VxWX/+YO3YczYcdDePt21j1nvb1b3lthr733VMwrvvgljR41Q/d5Dm+bBe9s3wr77HwjtVpaO2R9k+jykoSm4/zCxZP1OgHkv2++bB49AazDsMm4cdG/sgPXdHXD4EUcqTQG7j13wGowcmrkPf1w9G1Z2bIUDps+Av615F1WlM/tpMd+nl//2Flqz7Pe7T5wE7e2ZMJakeHDDXICtm2D6tGnwkenj4cpZmXHJyaeeCiNZCE7U+qPc4l97Xnk3zZh2ENz//lswcvQY6MfPO3bCruPGwOJtG2HseG/fvnJLF8DcF+z3xxx7PPxi8RzVT+G+Hlz2FjQOaoH29uNCyzVv5jsAqzPtw+ix7mfq8fsz9Yw46pjjYMr4TGje/62ZA7B9i/3dCYceAAuffT9w7IfeECOHDIKdm7vgsCOOyly3119SfSC2hbcseh62WeEC2IaddeY+8F9zMs8T7D4dHnnVsiaFMHRQo+12ztsAHBPd+eIHsMv4cbBgy3rlCn7M0YfD/yyaA82DWqG9PTMX+ZbVBh1z1OFw57tzoaYuM95KAjUuW/AqtLYMgl13GQoLtqyDKVP3h/YjMmMKvzrT99YGe6yhznE4Pr+HZzxQZmWu0aRdx8GS7eth3/2mQPsxk2KXDVf8v/5Kpl6fduop0NGbgu/NfxFqtfPfsMMZoyFHH3s87DWmzT0+m50Zn51z9pmhSv7YBmFdn3LAQfDazuUAHTvgyMMPg+P2zggcc25a8Cx0MLHzj511WlEyFty9Zg4s27EFRoweC7B5gz2WKjZ9EfqpMEx6gAUzDqCiPxoFLrjgAhVeMHx4Rh06W9A7ADMIIKgrgNkQbrvtNjjvvPOUy//WrVtd3gOYrWDcuHHqNf7VswpQNgO+jZ7hAN/jBH7QoEFQV1en/pm2oX34CTPiPx28qdne2GKCJb7+o/urmDA/rjpzPzW4jgoPb8LfYUODMdkYs5aurXNdpxSkPL81Xcc0c1/D3Qdd6wHLOo4xmrRdY6N5e5zE6vvCGDmM8+YxcthZYWx0XDX3GktvQYmXYR2x4uDTkHnvPsdMuXGboPPLuHD2QQpqE6lzJLQ3rK3ZDvnoHfBeYz1msa6uXm1TW++40Dc3Ndiubvz3tXWOSyMOLGq1fVCdwck0/x2WKVPGFAzNjNVhaEvm+cMJsun8ycuNXF0H+LW2rjGCdilXXRxIK20NFEvDtGHE8NZMGUiwC+PtmjVBwkGNmfMgmhsb7X1+ZPpucOJ+4+CA6zNiqOfO2BV+8KlpdngI1i0UH/Rzr0ahuEmWcGBDXaZu1NY5W+NAIE49oPDX5sYGGGJdy85e87VMklTaO+BoanCX3U4JiZkArM8H1Ko1hhVk6lSTde15W1Fj3VccPOI+6RnDa6PHHdda19Dveb9nzkp4dvFG+3lvabayY1B9o+e0rs4+FpYxm+tH7Rp/5knsiWhpaoRW67nqSaVVm6XOlV0jPIdbn3RWXv/zwYXQasW+YLsSpWzpGrcgXZcVLz54UAO0qeN3Ke8CfV+26npTI/QOUMxxZjveF5jabXw2zjpoVzj+B0/Dqq3dcP5hu8N3P3Gguldbmav7oKaMYGajfW+D+4CofXOqO/Mw4G1oHdSkdEr6Uv3K8Ei/oSw7rc1NUE/1E8XXtH1SC6faMPseZq69VYVVfaF6aOoDXMp5qn+sgT7rx9TGtFkDa34v+tmzheKYcetin3Xf9PS22IfaonOua+Jor+BnWDa1H7Uq6k4xZyoLPdNo8MHt8RdJtz94fRGsMzjeVG7vae/zH7X+pGus8I76WlcbRP1iM2t3PH0nuF34B2pq7XDKVut+4vso5eJyQPr19fQhrI3Qc0xgOxI29kPDlFNfMcYkU69xTIf75XHb2B7yceIPHjd75Zn4xedmwEV/mKPqwm3nTYePTNtFHXfltsx122SFo+E4EscPyAA4504isW3NjYH1LhuovUWNBXqucYwZtP9MfXE/y9Rf9VltDjJkUGOk/fnBNSawjqesNlw//5o6LaxWG/f2p/ttYxD1d0FQXcf2iUqgj90ILlqJDG0dVJRMAVQOqith4+xCk8scMsnziK3EgFkFDj/8cCVKOH78ePj4xz+uVvx5/H0uDAwMqH2hoQBP9KmnMqt2yLvvvqvEDzEMAcG/GJbAswqg5QUn/hiaQNvwfdA2tA98kPBYfBssA76nbaoFUiD2SzGir7KFwSeRFEPMU59ko1rsFp8JjmCj+E6e1ixqKkM/8RyuHB8HXazFib/yFySk2EU/7HSDPqn8sjUOoCBhUCpD32wFA9580vq21InZwoyUrcAjSOg+Jgn2YEYFEgajeqoGZoa6oOed9hNF42JOuprypX+ca5eH9kPb4/3hYpeZzzRBQlvVeMAeyBC4ys/rg196MHqP31Oxab+8PsdNzWVnK2CChJ0GobmkofsX5bpx4Ug9lSEJBvK2gouPOftwcokrzQG7bsZ73nnbhSs1/a5sBVaccY6ChC4hTu35xzSZpJ/xztrtsHDVtsy5Wr+hcyCFeQJXkZD31iuf81D4OeDrDegRZOV0p9SdJuFKnue6Qav3UdLU4rmTeOj4Yc7AUc/0ws85KT1CJxNAnaoftk4Jq6skYKWyFdjK/f7tDl4HsmVT/XPELoOzFej9H9Y5u4xWoK+dytCVrYALEsbvF3ShSVMqQ97O0LGpLCRi1tU7oDQPiLCMMvlIPUc4z37mvV/fFBWeUpK3QXRdggQJTeMeKkdcQUJ+ffUsKSZBS/s7q5w8IwyN/ZRXHmO4JWaEnoHU16GRjNdjb5YVd/YC7ikXBBrHD5k03L6+x+8z2t7/MMsjbqPVFqExwhbd432ElsowyWwFJGCL9YcEV6PsnwsZ8vd2VoCGOmi0tCuyFSTk40ieDcuTrUCrJ3pdI70Bun5xBAl5f2iCi1aiwbpYKQSpHFTPJJVhQsYBFPn74Q9/qCbpjzzyiEpf+JWvfEXF6F900UWxXfOff/55+OCDD9QkH98/++yz8PnPf15pG1x88cXKdf+ZZ55RooGYTQAn7ChGiKALPxoBvvCFL8Abb7yh0hN++9vfhssuu8xe1f/qV78K77//Plx11VVKQ+AXv/gF3H///SpNIoHHuPPOO1UqxLffflsJGqIwIh6v2sBO4qJjM25Nx+w1UikQ0zMdN82KrV6tBkmWccCQVi6zbXDnRvCB1ECC2Qp4oxmU1jGdZVpHffDvTFC8+3Amn8GPpyO0N5BIx6dca61Uhjyfuo7ewdAp0KADB5E8DzhXhbfT3djXgfaR1jpS930iZVssIzXqPBWOSZmbjkWTOvcExatC7jdBzGwPMG+544qJkCcMRzcW6BMcnjqIu08iNEDDgRgHPQbwc/yeBg+0UsMNLHFzvlM9wzJT1oUOWgrMI6Z7pacNpLrPB9h6KkNTuia7DqJxgH3PjU66YS7q884HEZkUZE7mCLofWWcrMKSB0rMVvLhkI/zmxYyewStLN8PNj2Q0cXb29EVKRYs5xaO0Wfr9WYWu0NYEkDyKyOBgEpTlkwNqK1zpJgPKQNuZUljyfsQeaCdkHbAVuq1JLh/00vnZ2QoaeLYC775c7aC2nVOHWcYawzl4Uo6lBlgqxUwZ6V5wg16Qgn2k66DdVzI0ZdLVeY0ZdGwqC0+1SUKuQWWxvU0sg0cuqdzCMwW5DfN4b/GZ+Nv8VZGfDd1IxNsYPTuOaX+6YVSlBcwylSFfFNANQV7jADeguvtFOj72L7+/6HB7ux+cexBc+5GpLBU1nwiSiKJlHNCyFWQz30LjN69/vH+ntIXKLd7qH3RFfqyXttidVZ/wOvhlpcklowwd26T2r9Pnc3/JsIbPjL6aHRf+M14+vLeu8VdAvUC6NGNfGLydHAgzDrDPixFOQFA70BtxEa5ayTqXBHbSJ510kvqHk2mcyOPkOk76P1zx/+IXvwhr1qxRxoCDDjpITfAx5gLBdIOYOQBTJKI3AWYZwMk9geEA//jHP9Tx0WjQ2tqqNAvQq4HANIb//Oc/lTEAwxV22203+M1vfqP2RWAIw4YNG+Daa69VAoaYFvHRRx/1iBRWCzSg22fsYDhqz5HKvRU7+6gWbYK25o0F72Bc2/qsRgemOwxp9E2TbJ4qzHV8tq+wtI5pltYRr09WngOG1Uu9wQ41DgRM4OOCk0Iq46I129UA2C+VoZ83gN05MM8B2l5PO2enltP26WccoM4EvRtokIweDvxeD9JElezBmj3w9OZD5ml4wiZXv3vJLTSHg6swz4EGq9PH6oXH4IP+7YYUTjhAw5zHn/sNii1lePo/TrQH3fR7GpTRtcL6G3dcYRvP6tBzoM7lPZJP9HReVAaOkyrKOSm6f47ngHt12rW6owZIzuCXe7XQ72nbqM/7glWZTBFU3/hKCZU/28kNrX65PAe0Z+CqB9801s8Vm7vg508vCU1HhhP6KG2Wfg6rtmaMA63McwANEjihwtAbTEd4yMThxlRmdM94mxHk8UVGAT5INq1IBaUSzAZq58goSoZXekZUHbIOhZM/Or6pD6K6Vmeoa9w4au/D6Dkw4LknUTwHuKE4m1SGutHHzgXOPAf4/fPzHEAPL3f2oeB0s453V/5SGepee5/65Su2V0yckEGe0pK3QdRWUZ9gqud624fGYq/3RNRUhub+LGzFmPppLCfeb15OXp2n7jIEFq/LeBthXXXaONb2Wf06T/uKn+H8ACddUdvDK07dR1335ajNZNUj3peiFgGvn7hv2zhAhndWd8hAY7vWJzAB5AZcMgZzrwUejjiypd4xCDJvBp6ClqcMzDUVrttzwDHkZb5zDOomo2O2aQzjeg7wz7nhp9DwlJyZ95LK0ETWd2jlypXwpz/9Sf1buHChmpzffvvtsfbx29/+NvD75uZmtc+g/U6cODFUafLEE0+E118PVti//PLL1T+Bu+NTTG0N4DwmrnGANueNPLrGmlYSwvKxmowIYS6IJs8BfcBt74vtFxv3KETdTl8xUn+tIpms2vr198Nxfc1tQIUr5teiMJTFRb+fY8cpU2fB0TsY6picFRq3EQbvbb0+cK41rwA6K7y6ccCKbRtI2zHItNrt6zlgr+R43c95/cLrFzZBRDYyMR3bc0AzDngmuWxQggNI/gzp7t8Eil+6j9sDu6MYGRsE8hhPda1x5SrmRInqjdtzoF/VSVqhzQem+uoJK2AT+1ieA9ZrLD53beerh3pYQdTneAtLv4guvfaKdp07hEGHDxpxIn345BGe+q171GReu69JsOEKFcfDiXKu+rNEq3UtTY7nwK2PLbbj0Ums1im3s8po8gQImtAbPQeozpuMAwnNJWniTYZE24Xauha8zmJ7EuStww3B+B9CW/E6Y39nuBx6G9tr9BywjAPM24evJuMu8DrGyePd5RNWhKF59NylDMaBVqte0ARXb9u4x1RQulm9jQ57bqLAQ9n4e24Y4CFE5KXlB78P1MZw7yQ6F7PngPs6KBf9LL0n3CEkwWGafOJse9TZ15wbGdzeHrQf9ewZctpTO82fTXqt0hym0kp4euMOf7HD4YPq4fKTM7pj27sz9WZIJiWRx3OAwPZFb/953eFu8UrDIYEs1dzATMcmI6ZJn2pYYx00TFpnX0M93IS8bjKeA17DWxx4G6LCCti4A89fN6T4jaHJSBo5rIAW+1JOf+jvOeC0Q36hy4WA+g4y8ukeekKG2HfoV7/6lTIIvPTS/2fvPeDsuKr78ft2V7uSVl2yJFuWLbn33sCYYoqxTGghwRAIAQIhhV+AfwgQeoBQQnOAQEJiSkIPphs3jHvBtixbluQiWZLVey/b/58zM997zz1z78yd997uvvd2zuejj/a1mTu3nvI933O3OuWUU6IUgF/84heRkV5Ka4g0qqHoFU4rSL7OIWc+zoHUpuXR+vjmmRc1Qnu5webbB7iSR4pIiIR+T0JN43b4I084oOFI8cn4OiAHAKWXrYCHHpGDrLFJRf0ZBJWEf13Cp3VaQQ5ygDzZIO6DsULPT2NLSozTKBsScD7WED6PSGEr4uiB0PhIo1Y6C3g/RMgBtoZkWgFEOik27j6knQOyljZJVu5y6DqHc4D6hfojVDkYvrSCdCQF6zmNHOB7gvmMow+0c4DVa8d7oet4zpTx0XjS/SLFWUf729geOVgVqakLkin7JEt2e+aSlJBn9UHAyRglJZ+EOwZkXnGUVsCMJs7PgPd8otNvLK6JdG4o9od6QYZlxEymFfD8botzwHF/ntqSlTaVlVom91gyrntSyIEkrYC1TaaY9RZ0DvjSiugaUO75M4N7Asgm/B+xnvP2B3IOYP3UkwyY843Q/XzOdPoWjQjd98WnzfUaOTy9BA48ej7MXWN0O5wD4qzm48XPqRAHLX8Oue/IecmdM5hacDLxtWmtO9o39b5EDrEhvSZwP+4IkOdRPF8G1TtfcIL66C+XRX3rmgWXnzpH/x7OAQk7nz7R5kKg/QV7QL/TOcAJh+uzR5gzhO9vg14danevUu/84SPqlefOS9pk9zf0NtpXTVraUJ2QA+YzG7U1GIYcCEwr4AgrHdjxzFs+RxDsGQ3Bdoi9veQccEthPMUnP/lJdfHFF0ccAIQYIJ6A0jHQWgJyGyi8PsU32DnAPIa+a6U4B3zKREb+lBTk4Y3jnAOejYAfIBShIEUka8ugSBl9L1Q4SVXUjizOAZ0LNbzIgRAo/YNrduWODT52GWa+MdNOEvE+vio3bFKUcKAgWkXP7+OwIOUK19K5lQ7iIvRfEUdPFnLAFwE3CqSfcwCyeU8M44ZsZK8RqeDXzTJUgjgH2tt05M9HNjfShIQuwx85/pga+A2fnyZKyPLeGSScVytAf+Wtd3qfPqfvcaNxgKV4GGfGUFWkpoZskSMHiiktRNqV9QsyfEP2LB8cncj6HlhLNdzTImce0mkMP0OgcwBpBS7OATZHKnXmHODkYNxwwlzlKJuI50NH4tLX4o4eyTlgIrEGfeDkHHAQh5m0AokccHMOVJNa4CMkjYyxtgzkQJJugv7bJZADtNe4HDk6as4M1XqTAfO1f9/TOzLPO54yGJKOVZxzYNC7F6IPkIJWE3JAzB9XUMXlxJAoAo4c4GetjBLbhIRt1mfPPmFWTHbISlfz6DE/Qw3vUQ5yoI05q3LSCny6ZFEx6C7zvNTvfh0q/s4tK7Y40TFYO7SekSZYbVoNP/tpy+Fnh4u3ByL1JrkPDhch4eg6B8zYkZScA3VyDhAR4ec+9zl19tmmpmoprSU6cg3nQBLBLsw5oJ0DZvHJXE4/csC93fLoaN4BCi94l4UcqORelzPH+4TIlm5ebuoI54lW/kOqFQRyDtSKHAiB0pMnWSpK+WkFRilOGW8eQkIcvPwAliIPFDqYNEt8xnwCVNiX90y/DXEIzWHQaR8hoTxoJHKgrwByAD/duNuMkSEkNNfVfVgDcoDGAwrBcJMS8ioJkHQ/OhRXkVbgRg5w54D53DU3uSMqpFJExC3gUYa005MhYIqQmqJ9lpJdMLXjzZcudD4D5KyjpwY5HHzIgTXbDwTNjYef2W3NT8m1kTVPXRBhl9Jp9k9VF0H+NvZUzEeZVoA5K9En1jOwPUx+zxhV2Yif7LSCBDmgK4y40wqqcw4MOI0x6g8XNDlFSKjTCmLkAJ9uLvQAxhl7NDn0600GjL5fsm6X+tvv+cv1cclCkplqBTbngOS4cRl60jnAz+7xncWi3VnkkynkgCOtRxISRt/j56JwAvBUG4wb9j0X4ok7Tgjt8eO/epY+I4no+uMvj/fcp7cd0L/lpMhcaF3y84J0UjirJHKAV4+JP69P7hHnVIKjksha8/hq8EzgiEJ7OPlfR42cNfwRuWM8j+/FR0g4oXBaQT4hocU5MIppBXBeldUK6uwcIK/5nXfeqd7whjdEPAMbNmyI3v+f//kfdddddxW9XCljLK0gGDngORxdzORFCAlDOAc4czw/kLjsOdhXKIrBDxYSzebvOLeGm3OA+pDIxH4b2HapKA0EOAf4huty6EhCQvSDL62AZHJS4x3CkQNSOeLjiYiMKxqJ6E2IQ+gfX3pKYUJCGmc8Cietiu9rooFcNu89rAlBSTYx5IAmJGyvA3JArHOkFgw3KSHm6/zpE/R763cdtMbE5HSyVBAof0l/auPfUaYrSpFlqQmyhGb0XXY/rHeqDOGrFCHXnK5WEHEOJPta8mxFSE15Wziyia8h+itLhSHHFuXtup4BlT7k+z7x5Yfvd5CTuoRSD/ieT2MYihyAcWLlSAvU1XCmFcA5YIxVOAeAVoo/14a9yznA9jBTclE6B9ylAb3Ogf6hNHIg+Z+nFcjSs0UrFsA5ICumxEiH9LpB+hlQDONFWgE3AlzBBRhK4xnioMi6CRGM0dd+v6ou6TemWkG7BzmQxTlgryFO+MtTuUICMXysczkHHHw7Ts4BnqrgcYBKMlbfeSQJYzWR8PhxESnqCbPj8+3p7dw5kHAOOCLL3GFF81GmufBUB9rjfXn21YrhszGOZ5lelSXjxbwYTkJCbu9mOWal44RXUAgRy2HEHJ8u4fv3JKHLjaTgaMKa4Y6UUowU7pWf/vSnEdP/hAkTIpI/qiJAsmfPHvUv//IvRS9XSgOKMU6Tjb+ttrQCfnAYY044A4YCkQMcol4FIWHFM+NdChrlHfqcikPJv4/9clnQ4SMJx9pDOAdy4E7IqyuCHCBnxnM+e6t63TfvU9+9d21VilIe5wCPmPkOJ0yJFCFhhvdZIgfIE++tfsH6VUdyOPM9ewb81pQStPMbEXVdJHJdaXykM8DlTML6oftLZd1VsQDK8bnHxAzwmxhyQOZ62oaKKiRoC9qMigWy1nm9Bf29LimRR/Kde9dG8xLONqMsuRxLfuQARwPg0I/JwtKKkzTsaPzvet/luqb2p199RvQajgFOOkZlLdF/PFKFtVGU1NQVHecGdh67M5ANeAaKzF1z9TnR/3//ohOt/ssTn0E5b1ogF8uU8VZaAY2hBW0dqh05oPeNOij+dI0VG/fquU+vU8gBVr4uun+G4cH3MDiipPMzquiQhRxIVStwIAeGMa1A7oGRA8zhzIBx251CDqRzx31knfx3hwMdUIXIgAsENXgKUbFqBem0ApcOI8fjEOccYFD4kEAMdzSkOAfEXmkTgipvVQW+TqkNg660gn67jGtq3xKpBugXgzKJn/O4I7qj/4lDCE6BvYfcyAGSaUnFgqjtUfUMtHnI6Th3nQ+1yKDjbPEFj1wiOQd0lJ6ICx0EvNU7B5TXOSLTTfh8pO89kXBMyWojxUoZtjU05wD27pKQcBg4B77xjW+ob37zm2rcOLOAL730UrV4cRhkq5QmcQ4AOeCpMJAng0OV6ksZjjBywKVAUHSCH94u2by3R3311pUqT6SCiya5FENXu11i8mLDxsWXy5klZPRwRYnXEsb8wDBwNl9+OPGDazCPkFDUpOYiFYYIOeBBtfB50tmeJiTk4837L6r1/GZT6xly7MxuJ0ogDzkQPSs7pKXSLyNZtC6oOgHJecdMi/7fyMYLh7udf+03VIAScdXyNrmz7SOKHFi1bb9z3vKcYle1AoyfQQ6kI3RWdIdVELBQLSKtQI4V3r5wwUw9dnCqbdsXR0Spuse1d63W7ZDoqqKkppKTBG2BUNlOV94uyRlHTbFI2uh3FJl7xTnz4lK0Dm6GLPE5gZ91/CztOMkS2i9IAeOGiZ3X7G4HRde1c8BCjKQdYtrorlHvx7h+977YUUprhF7vONAjkAMGSk4iuQS48D1MOqJ4ellWaoR0hHHOAcCTJ7rSCmpEDhzwIAd8aQXgJ6FKFnYpw37NRYBncLVFMvX7nPdSinDEFN3P4GjzCXfScN4TiRxwEhKmnAMD1lnrMuZrQQ4YksP0GSzZ86PriNKxrnKtxExvqubYjgC+NjTJnjCG4Ryg8xxOqG/fvSZae3sO9YYhByJnldE/aP+UKXeuaja1CNddcA8iSszjqwEfh49zAGTL1QTgTNuS+zFknJu3xx2Ewz74owfWRa9vf3K75az3icXBk0NIyCP0o8o5IPZuXtmhlBqcA0888YR67nOfm3p/6tSpavduUwe6lOYVHGCSkLAok6ohJMxPK5AeU1+eGG9C3j4KiBw34Fws+K77F4lOfOmWJ6NNNMsQkxHxShZyoD/xgOd4pYsgB0LIB10ye3KXl1wQXA4ybxp9rNERg+GEhBhTl3ImFYYsQsKinAMhkEBJtEjjk8qVd4yZjoKL3GsX7wDNOepGuu4Z86bqagWm3cnatIzI9DNLlMjf/3BJ9D8/8H1pBcNJSEhtpKi7S9B6mqc6KuRIBdHIAdavaU4LWzk0jOXcsHSvBllP3udU25/k36/beTC1rxUhOYzayJANEK5k0bwiB8Bv3vkc/d5fPmdhULpAVpQ7a/+XS5AUuj+75JjM34K/gkSnWoh57+t3e01mIweqTaXhkkV899Da3YJzQKQV6LQwF3LAtFE6EbgTKIsrBMYXcvlj54ANwdfIAYb0kbD1osgBGHDSCcXZ4V2EhGjLBJY3j7ZmpSXKagUUPS+ybkIk1OAi4zOvjKEsZWiMOoOOMRF5B+eAcN6gegFQJlgzIU4dfu77nOM6Wu3YR13pD/x7MeeAMbhdZKww+PI4B2zIeodef0DOfeHmJ6Pz6Qd/iI3TKQ4nJHcO0Jzi+yPpJdph0TY8yAGju5hno7f86Yjx9y9eOFMgB+L+ezpxkhM/h+8MDxWkLfHzQ/e/o/ILXxu1EIByzgG9T7c3OueA3b4SOVAn58DcuXPVypXpSCnxDRx33HFFL1fKKIvLoE0REtYxrSCUkNCPHOCH3GAgGzuPONnfgVLjUjKLRCfef91Sdeln/IaYZPfNgpSGcw6EIwdCyAe5zOzudEbC+bjAENZkW6xcHP8/i5AwlVbgqPfuTSuI6kznzydXJMeKluTka7qIyvC3HCPXmPHceLmGiLuCy5aEb2DO1C41L8nJJwcCDAAoQPwAdkXCQw586RyYNALOAZqHMrrJhR6B2rxjf6+3zJbkHPBVK+DKIYeEyjln3X/IlDqj+RXiVLtv9Q5tzGB8i5Acxs9gfgfhf2Ne8fQCOAV8JKuQohE0PAOPHtP9aa1dduIRzt/AmOQwWz7vs0ixIPZ3XJwD3Mkb/1+tbyCEMJIbYDKtIKtaAk8hM+20ERHc0ejmLRi0cn8posvh7LZzIAM5UNA5gLWf4hwgZv72dHslIaEsgUrGvkZ3OdqCPZlDrousmxDxVSiS8rXX5TsGaN4A+bTzQK9uE40rpm8RzgHMLzyPq7KOSyI0DnemiWoQ2jngcJ7rKj76M+4ccCMHaI/hKD2d3gZHAD+PJOcAIuUo3TeuXZ9PMr0USApyuGalFRDKgp+BHLmBFC+z71UXjZfi4lSicUc64lTh0JjWqdRXrj5bHZ2c43A2U9+RbvirR2Pd8DdLN6sv3vxU8ll1G5pJmzPv6bMlo8IXnXW1EIA60wq8yAGGhHOkjYyUyP2g5BxwS+Feedvb3qb+/u//Xt1///2Rp3Pjxo3qe9/7nvqHf/gH9dd//ddFL1fKKIovsggDRaYVVFutwE4rcF8ri0GXSyixFb8HRw5IpQLKl+t+FJ0IVUEoxxJEci5DTDsHBOTL9QhFOQdk7WSX00e2zScnz50c5Slf+xcXpmCPsp8wVpqQUD6jI0KrkQG+tAIRHebCDxT6HfWPj5AQB2L8vbZcQkLrt07nQFtqLvH7yz7hghy8CDkwkI0cgDF/5JQJasr4cdpgR8UCrQCxA02iUEIMH/oczOZpQsLhq1YQisaB0mxzDtgRbQ5zhmJslCTDB8HrdfNqBa61xx1tNOYhTjVi8H8yydXk7dUcFiIKK0kO8Qz8mXxErjwvGXDpPENJR3wDLWkYlHOmGOcoYOPdrOQl5JLjZqj/fetFKQWwg0dVec6zZ9/m6zOfc6A2yHCos3TtjpgsTeb7hxISSpQKH2cXsgoCIwHINhqTNHKgg5FjDuUiB7KQbRDs90ek0gqykQPdgnOAo7bgRM7iHIARS2MdSg4aKrxakU8IjXDJ8XGE1yc3LtsS6UfXLY5JuG9esUW98b/vT/WzYaUPTyvQefqCuySrWpIUF+kg2uIkJHSkG/FzlJw5Ls4BPt8Mv0DaKSgJCQ8ljqQJ49pyHa43PLY5NT8zkQMU1GIoh/j+teXxS+GBC322JNemOfmPLz05bueEcep/33KB+uh5A+qK0+ekUjyoi+XeAz2Akw9X0zbsNz7niOwLQi/UQgDKg30mZUrlIwcaIK0AUiIH3FJ4hN7//verwcFB9cIXvlAdPHgwSjHo6uqKnAPvfOc7i16ulFESeG7ltkkGLd7D4eGLzoYjB1gEzMOwj42FPo+94LESKb18/MzM2/NleoQryqaRA46L0aFWy7FCv6W70UH4gStPseH0GdG8WjkHaGzpnnzTn9Ed5qklhnzKU0Z0hLMpR+1lSgacRhoyC8NMPGN/QFqBhN26oqFTJpjtiuYmHYS+UoYa2su+YxEvseegt8l4AaTTNSZQem3ngCmlKPvEeq+dcQ4IpU86B2j9kcxJKEfENgABAABJREFUFOO5U7rUym396rrF66OoLZX68kVq0O5QpvxUVBqEhMOIHAhF4yCFxMo9184nWzHFs1Of8HxvGzlgnE5438V0z9cSra9QZwYI2KSTipTGI6dOUK/42t3R67dcukB98Kp05NOVTsOJnWBg0bohhYzaiXHKi4xirmTxuNCcoWel8YGBSaU7l8Z2kDb+4CSQTrshV5u1Ai2qFXicFPw7tiPPVvotp2KV0IHQccX61FH7cdlpBbIkrnREcVTBgCOyJ/sC5xP1B+YrDGl8hgg+jYNMMetJ+tF1JpBBTFF4bmxjTqXSCtqyOQfgZJcs53FaQbJHZ1Qr0AZ18h1qExECX/Spm9WOA32RkfXvf3Z+VWXHeO/Sr10zJg+N8MiOivrWvY+kfrstQTjxfs/i+EhVK0gcPpL1n6fVuMSVSkj9i/MJc8qFmsNnrpQ8q3JBlCqB+cp5VQY1h4FOIXLsWzydjjuSCEGQ55gjLh7ak0gXgUy1OAfMfMQz6fKKuL9ALtQq6BrrbHE4PaltFy+coa5fkfxOl33Mn7tPbd0fzZui89wVVHE5R+ScdBEiF9kvMSf4uemLxFsEuw2UVlByDril8AiRQv7BD35Qvfe9743SC/bv369OO+00NWnSJHXo0KGoikEpjS2hkEpsrtJLGir4Ot8sfJwD2FijAyvmgoru1ymVaKZI5XnX4S23OQfs7yD/zfVsBBvMUihCBIYYIovoU0lUZbc7zDng4hzwOX12Hgg7BI6b1W2zR6ecOOY1J2Pi/2vOAYcCLQkJ2yJDzxh1sqqDDzkApafTUaYwDd9Nz1853nS4GQKl9Lzasq/HYjHH89NvqKm4nBs5YNAyEjbInQNRPv7aOB+fDIHrH92knkkY/f/9tlXRPzw3JySUxm4RJm8LOZCsheF0DhAah5QkH3yykkQIj5nZ7YW8YmrwPqDxpKnAOQd4BQHuuOJoFWkYL5g5Ud+Dfh/qzCBDmreRC6/+cNS0Cc65rdMKHJEfGf0ko5Dmq0YO5KQVYP67jBWX0QjFbUZ3p57b2vhz1L+OokY63zeNfIirFTAF1TP2vvXJ65en57yqSkLHVSq/Jq0Ahr3ynk80LmjxkHj2DuYccKaWibSCCOKd/BaGNLUF40NO3Ng5kE4ryAoE0Ps8Gg9nMI09FxpLF9IBkW+Qrsn5Eco5gH7l34nHuKLbU209cjT3vVecrP73vrUpw5SIX7PQCNTG69a0ZeoAfAh1dRyXc0CMD/pb61oi2u4TzEf6He4TpW10udM17LQCWy/ycvGwdKAU54BOK3BwDmjkQHJ9QcAXqkzJc4zI/6y0Au4cYOgkgxxIBwVqEc4b5UrVwtyVaQxYy9Ans4T6VjpFQgTbjotzwIXCgmAvqXa/xJzgvCe+84g7jl2EkyMlch/hKMxSjFQ9Qp2dnZFTgITKGX7xi19Un/vc59TmzZurvWQpIyShkMqV2/ary046wpsKEExI6EAO+HLEuXHlY1+H5KWSIcrKjWxS6mjvwmaKWtEuBQ2bOSkmdI1QaL5LdiZ1n1OlDF2KYRI1kJD1PORAKOmgdHbw1zAMoFSAfEgetBwWq9MKhOHvKn0lkQMyrUCSGvo4B3CogU8i7WxS6TJzPEIi+p2es7vLP6+IxfeOJ7fZVRCQdtMeR3KpyS4FlisSKc6BxDkgjbRfP7op+icFY/3Eprj0GokkNivClcEV85GoVkD9Qwby2h3pnNIKi+Kt2nbAwTGC+aWcyAGpJHHllDuuMLce27g3ggnzvdDkzrdHewWIBTmiyjUvzz92hnePRHmuLH4Q7JUu6LxEpJABtkv1aUb4PKMJ61HOeZ/RiPHfsrcnUsh3HOhV3Z1xnvBHf7ksdX2CwjrTIhhXjeUc8BESinxn/X0BYSYxEfnqFP+QcSVBHjFSt0xagXLen59rD60lKC7mZfw/z+HOrHigCQkT465/UEfeNbN/pRKlFtB4ocqAjChTacDP3PC4NxAAZBtF6WnscB3aC+jeMOisagXJs9CzSuLEVFoBI411IQ8l5FoaxZLzoRrBGD37+JnqHc87XjsDH1m3W11795rc/fLBtbvU7t5wx0Q254BJdYxTRWzOAU3imRPtxu8mJGNE9+LIDDyzznN37KO6ig+7F78Gd+pFnAMOCLlMh4i+K9AEBjnQn0IAZIkcF14phQw6vu1FhIS6TTZyoV6cAwaV5h4nXWnFQw4ZyidQ1Lnv05tcSB/ZF0Q4nbUPwlnvIwCFvs6dkr5IfEejpBVI5ECZVuCUYJcJOQA+8IEPqAsuuEA9+9nPVj//+c+j97/1rW+phQsXqi996Uvq3e9+d+jlShlFCd18UHs2K60gK4/RVa3AkNq4nQPwuvu851wZy/OuS8I1l2cTylcWcoDImT728tOijbLabeQXD2+0Nm8coNnIgUDOgcQJEur0mS6iQrT5nzM/ZsYf74gQcoXTcg7oyJc4oDQ6wnE4schu9B28D+eAA16dhRzwEhLyskNADjjy111G231Pb1cuoQN0674E1sLGhzsJeM4fhJd0cnEOVFNikhwHkscCzxzClI9Id9T+pH2I/g0ncoDPLRmd5DnFxqGTNhgl5wD/Hnc+6Zx3Sg9iih1+9n8PrU/1OdXclvfwEaRBXnTqHL0WaYxlusLeZB/18YP4CAldVV74GtVpBbnIAZeSmO9IfHDNTjVlfHyvrXt71Dv+d3HkMJDy5Jb96q6V2738MrwGvGwHF1lj3byfdjxkEQKGSAhhJL83J6nkbeFOZVrHl3/hNv36Ld95UH3i1yucDtSY/T95BmdKm+AcIEJCTYpo9mYgC2B4oZ1wpD6+eV+hnGJeix4Gf9xe5hzQkeD+1DmKuQmhdeE7810RbhdhGgn4UWqN+PIynyfOmRwUWeZ7fogYKH/6eXFOUWlSEukcCA3EmIoqhvCRn4Epp4tIo7ORA26uD2oDd8xxR7xxDmQhB+x9B46mBbO6M88nGK3SIOVOBXKW8nLJUcqe0JskIWKtwg1wJ3Ig6UfuiInun3yHcyZkSVHnPm8bPwpcyAmX46IWAtBiyIHGSCuQ5yV3bJVShXPgIx/5iPr617+uFixYoNasWaP+5E/+RL397W+PnAKEGqD33ve+94VerpRRlNDNB1E0X1pBXqk0nVYgoNjO0juCkDAIOTDkzhtOpRUIqLeuw8uIZVxKJkcOeEmSpnRFm37e9oKIzM6kfnYWIWFRzgF4bUOdPh9edKr++88vOVbd9b7LteENJAVnHeekhBwW6yPbksabxRMhDFqtIAelFXQ40gpASOj21pMXW9e79xgf0e8Z+uJ79z/j7Dc5VBgftMVHfMXhfVJxoDJG1ZSYRE6mC2LNDR8p6NV3vegk3TY4c0aCkJD39b+//ryI/PKaq8+J/qd5CHivjjq7+Cowv9ghD8OScwvwXHudVpAgh/KE5jzu51v7RKxFcvpRU6w9Ts4tntfpIhKzno1D5zniil0fBiMRIUbfyznFXc6BIKLF3gG1blf8nU05qKlr71rtSCtoc0Z9vc4BK4XEhRxIc8cM5ZwBWZJFfPfaC+Zbc1U7B1jUnrcNDj7pPKF1yp1OPOKaVa0A83kCL2WYGMhwRJEQooPD02E0EpkpR6zlCZ0dHAnQ3RkjByCRM0MgBziqAHthKq2AV5Rxcg7YThA7jcgYoVkVTvKEr30uWaSS0lAtIjLdjgsc+dhrMaaY26Flow05peG9sZADcA4kOoIrN96UXHSvO+4coLnKyX+zCAmlo8MQEsbPOqmzI9fh+v4rT0npALxagXRKxKg8ON6SvsxIp6o5rcDhxMGYybFDn8IZlSXUn0XKdOq2sbOfX4skyzFLfVYLASjmBNcRfSh9tIeWXbeD2HakRJ6XZbUCtwT3yk9+8hP13e9+V/3f//2fuummm9TAwIDq7+9XjzzyiLr66qtVewJRKqXxJS+yCDl3/nTbm80U27xSacTsW4SQUEPdmFHq8ujLzS1r3/chB7AXkFEHBRw5dFxQTm3GpPhQok2SDJj/98ITotenzp2s7n7/C9VnXn2mChWKstEzZLFth3IOwCiFwhHs9GFRYyK+owOFwxQ58VkaOcBz+bPLEOIZXWXJDLrAV60gPTt5nhocI3mlDDkhYdYhydEXu0R5QZ/oUp/435MGwlmbZW72ht2HCiEGuMAZ5JpLOPC5gs8P/EuPn5VaGyNRypCvfYoyIopH/7uY+qWySoLthOaQjL5y55ObkLASweTzhC7DGZqx9l997lHR6xefOkddfsrs+F5RVM2PeOLOAR9yAD9xsf3LuYUxDa1W4FISQx2Jofm66FOXciqh7r5rejkHHMgB7hiqlneAjyvG78uvPTt6fc4x06x9QZYR5M5d6teP/TLbwbdm+4Hoe3Cu8rQCJ3JAVyswezCMH16xAs4DmVYAR6qLI8IldHZw8lk6B/jeQf2ja7sLmDgnqYx4WNg4cUJCVylDRK018oatd64jSCK/WqOqRXLSLzh2uprWORSEGqRn50gxKXgm7LXoc0lImIccwD4SlYp08O4Y5EDaeZ5FVsi/x2vXx8gBk8aYKmWYxTkgkAM0t3wGKeSV58xLvccj7zi3eHom9t10tYT6OAdcqDSLryHpE4ke4xU58uYQOaKqIt3MSCtwkfpCMI7YB+cnZRf/adEplrPeJ0ZHzCckRHvIORRaXnQ4pKxWUGfnwPr169X5558f/X3GGWdEFQoojcAFoy2lsSUUUglImjywQggNP/XbxxXOdheDta+UIY+o5CEH8lILfBF4bKB0wJi8+PTvdyVRl5kM/kxtO2veNP17eo2DDmRCWUIHKxkdWZBSH+JBCvLusTGHwMnp83OPiZ0+3BDkBzcEf3PlHu2lPjXROxhmyk1IyA5KyUtQYQqLZPrOTCsQpQV9aSp0CGH+uaDKUmkrku+H8TFpBe6e18oiqw8NSL2sVlBE4AzC8pLoF5qXzzspdgKQfOctF+oDv3fALmNI0q0NjZFxDnB0ihSdCuJw6PBult/D16NKFsln1C3YJ+it3sAopJwLNCdPnDMl+nvKhHGMcNVEkjhnCGRvwg2QFQHV7ePKHfub7wXYl4NLGTr202qgqyFipxUkiqMw7HylDHOrFXj4GKrlHeD3xVnx/JNnW84ezFUJ6edR56/e+lQuHw0ZXbTvY41y9n83cmAoVa4Q0uVEDvRbyBSanyrZ70POBDo7Dvb1WyVaEd2O28ucGUl7gVwB2gzCHRJxZNufRy/h7xwpxM+d2pADbjSar+KEFPreqxcM5upLWYajzzmA55K5+7lpBf08raDiLFvJ56uFHJDOASutQCIHsG8aJ7tMN4j6yFE9RxLi6bKXybPDIL3yjLnR6/OPna5TLlzGIyckNIgF5hzQVQEk50CdnAMMgeI6n3xVAVwVHyQaBTqmTMspjo4x77mQmyn9WRCAQlc5Z/70ICcFHEZcfD/DWI0m34C0R+LXpQ1bk3OAkAJEQgjp6OiIKhSU0pwCg1aWLCJPLhYxz6XmXuWwUmk9alvyFW40+8iJNBM5cw44kQNCkcqiHfAiBxIlhw5O43ke9EbD+KFkG83GWULEVaF7DBkdWYqhRg44yuJlIQdCnD4Sbo4DG7Awrtjh70O9ac8zL9MFfYIT9tgHt6McEIOYRf1AUTXB9J2VVqANcw9ygDshNAO0p2QTV9qKGE1QlrA+fASSnJgJ/Uc8FrUovTMmjtPwQ22oONbLtn0mSn7BsTP0vNPEWMzoHAlCwvjeaceEFBdywJBjme9JR6JVypAprJgf9L6rHJ9LXHMB0VQyXLjSxw3XvizkgCcC6iIk5H+70wrCqhW4jJVQ9FhR4U4S/C3nuC+Sxw0iVxTUKmXIpk61vAMQ7qCDAxIGuMx5N9UK4u9v2XtYfemWp4L3fV4LPMsJjnkvSwPGbUg7cMlQp/WPeY60gv4COcUw9jG/7LQC48yQpekmivxhbuBExqvHgcufPQ854CrdV3NagSOy6pOzZw6pr1x9thN6zYUHN1z8I1j/MJBw7mrkgMPozE0rcPRvql95OmbyNWdaAXfQ9Q/ZyAEHIaEuW+jYt+R8OZQ4n/i8ou9csGCG5Yzl57w8b3EfcsZFCEx2D40sqxNyIM2nZZBrOFt8UXlXnj+vsPCjtz9LTUzG5gt/enaki/PvVo+OSe+/IcgBiCRezZMUnxdLN5WC92lNSH6yUU0rKDkHnBLswqEB/Yu/+IsIMUBy+PBh9Y53vEN1d8clpyDXXXdd6CVLaQAHwRnzpqrnfPb30ev3vfRk9bbLjlMnfPC3Ttg0Du7Q6OrBftsbnskubxHIVVSvp+SVNICyFEMfsR/OMUT+o+s49IOdSVrBzCStAIIDlw52VymwEKMji20bCl5+KUPbScGdPrJNc1lNa64MAxoKeCM/uLVzwIEciCNJynqGIZlW4Mp5S5UyNNfl3+PKP28PXZu+B9SEj8CJOzFcME9XtQIYTcSKjFzhLIFSBsPNN14u0iTMqYM9/dHYbMlhTZfyZ5ccm+pn11m7ha1Vq0yVw3E20mkFWQoIJ7NLjamFHLC/Z+agXaKIOwdmT8l3ANE+5cr9xJqgdQNlh/a3CKmQlGiUc5ETEvqcQbpGtiO1IlWtQKQV5EE0ZcSXOxIpBaweQs6qnQf7nKUY+f6RFem3IbpDQZwDJDX6BvR+SEYJ1pR0OmrkQLL343tUl7zIvs+fpa0CngzlRw6IqLws4Yb9mmrHc2N6ygSDOMCZ8KGfP6a2J2eaPBP4GQAnIT8L+H1TaQXCgcEdzLRPh3AOwOFBL+n6NKe5Q8BX5SNEOA8JF1dkNUuuOH2OuvKseerUD98QPcs1rz1HXXXWkVpfiq7JyOrwPHy/wjwyyAHhHOionpCQ95FxDqRTDtAf+J2dVmA76DjqwnIOpMj/0pwDxik5aKMTxZyeNy2Gsq/bechCvXCBnoX5ct1imwCb2onP0CZ5/yLi0uvgtIhQFA6SY9u5yc8t47SI9vQ+CqBRe+PPn3XcTMNJUrAimI+PJ75fmnMhXWZR6EHJ/Tk6KUuyyL5lf/7kwXXR35v39kT8ZEeK/WekRJ6XJeeAW4J75U1vepOaPXu2mjp1avTvDW94gzrqqKP0a/wrpbmEK1YLZ02yDBQJl8bmFxpd7Wyzvcv8mukccZViwXd59KUzwFcz29roUpwDQA5w58BgJiEhFygyRCZXlGWeDkYyOrKcEtVyDkAA18PheNmJs6z8MX5YHPAgB+Icvvh7Dz+zy5TpYUa3VBYHZFqBwwHCSX2i7ybv0zDy77kOGTLAcECnCQndaQU+8iAf5wB9/xXnxHnlqfuL15JrwJcGwomZgL4BcoAO5w9ceYoKFYwpr4Psy10mQ5lY5iFc8eh1IgdsorvhEGoT7s0joFLahfJFv3OlFWjOkGT94jucyZorzvRWSI7h8bMnOeGGhh3eIAd0jXIPmZhdytDdtyaizCNwbU74JowxPFMucsADr4XRKJX1kPQoKX9y4XxvKUPJsxBWrYCjfOw9I/q7jmkFcA6gbCEJnI8pQsJkzmLNuSr4+PaACxdMt/Ylybfi5ByQ7P9izXQnaQeUVsDnFpADaB+N9b+80nDjvPbC+amcYqQTYX7h2nH70450nB1ZzgHKs85i4JdGbPS9ZB6EIgeyKibxe9SCHLD2r+Q5nnvSERaiIrqmcN7Ia+OZ4ICRyAFT/jMMOUDz0ZW2oXkFHM4BTf6cQ0goOQew5ijdct2ug05HAH+GFNIEaSiCjO7oJM8dIpEDWfxWcJBGZRfBg+C5f6j47ofSsZt2H86tBODiN4rSzxhyD/OI1ouJ8le3l/ESvj7Huev6kgfEVRElS3x8Xq7+xH4h+clAYD5SIs/LMq2gRuQAlSwspfWEHxqkXHBlR0ZEYdjk1YimpTZ3apeaOu5QKnLviyJY3tUMuKU8xzORA54IPDYH8o5mHSBgepbOAShsdFgU3crPmT/NguS70wpsz34IcoCUFg7noscynnRbgeEKAKJFnHNAes0//dvH1bfvWRN5eZGGYlcrUClId/S/i7RHGEFWWkEO5wB9jrlEZTbj1zlpBT7yIA9ygOT0eVO1A4IrqBRpmz9joiaqw/igSoEPJs8NXfQ9GSJAQVy8cGZkpH3kF8usslm0xv7ysoVROTQiJrv2Ly5SH7juUbVmx0FrTvtYt8kodUWToucdyEAO9Pan5lO9hK/7rLQCnQqSLHg+Xm0BnAN83Pl9+dpbdMZcdefK7Vrpw7iQsXj09InOdsEQIqUeCp1UkHvrhRxocyMHuCHF7++TLPg6GYe/XbpJ/eKRTeqoaRPUF/7kbPX1255Sdzy1Q4UKXf6co6elojAmrUAiB5RzflnVCjzKNYT/tFZ06l6Hc8BEY92EhEUJtahv+fNy56rrDJO5+BAYe660Ap6/jt/xfW3LfrO3HDV1QmreGPRYQmYokQMiBQ88B92d/rQCai8I8+QezR1+3IFP84C2ohDOAVeEV0YkXYaTXQJWBQtPuUJqAPZxYwC25TqhYQCjbdLBGI4caEsFXFz9yp2suKd2DjgccWgD+oxKYn7l9yujvwl9csNjW6K/6SxCH/iRA4lzIEkrkA4vIAdc3EIh/FZoq6lWYDtaikD1Q0q8Llm328kZZcP30yiCKP0sGV8+j6g/fBXBQoUT7kI4WaN+Pk2IGu+bPudV1tnMReqoMgqfN37UQvr8xafNHTEjXd4nr2T4WJUSTzHGhXubOQutK6ea53Tl5TF+8MpT1KBjw/AhB7gxp+FQGSWefK+5uAygqI0gJGRGsyt6A+TAzG6blwGKV5FtHHWNj5kRGx2a6d9x32DkAIN++SLn/Dkg/AAiCHlEyJWMB0VesqpQ3L1yhxknAVeWaQWuZzRs8vFrfchGhITmflKRQ9lM5NDf9/TO6DWxgEPp4tGjPitSnI6sSPge7z+09zknzEqV2ls406RRSa4B33hZpEksfxpM5Hc8uS06HCkPMbpee0Xf74rTY7ImajqhBVylHrG8pHNApv/kpRUgmkWXgbOo3sLXfSYhoYiGDXidA4kTIfke5he9zasZgCSQ1j7m1nFHTFJ/8/zj9bW+95cXq3defoLTKINAsSVDylSesOdBGjkQwjmQVu743y7OAf29POdABis+d/pSlDeeY+Yz35XfeukC9c03xgTFdFnufEkREjoMuzyyWZejwJrzrG9qzV11IwdsJ7ZMhclDa0ihSD4/q2zOFv85x1Pf+P0hPAJtQc01osrMt027D6WuzyWFHLAICdtSpQw1R0EKOdAWhBzgz83XG8beqlbgQA7kVUwyJZU9yAGBOgoROBI50aIkyuTj5SuZK+u8m2oF2M9ynAPaWWXSCtC/fDrpEpHCeWqlFTicxmg7PvvhA+t09SYu1y/dFPUzN7AMuaJ9fVfqIqoQ8Pc4ciCk5CrJoxv26DmNcakGORByP1prT27Z50U4xe87nJuMM2E/c0jTmsb7IHvMQsKEVuRwohuE05FXp4g4SzxoW5/4UnYhYfxkh63KQMMtPgRRKbaMLm1kKY2FHOgb0JtDZFRp5ED6wAIklUo4caZm5DG+8ORZ6rrb07mzUKqIyIk2PkDsOSRdKvxc5JkZQkiYQg4kLyNCQs8BQhsyqhVM77Zz4ELLQ8X3qKhvv/lidd/TO9Q1v3uKlfDzIwdMlYXsTYtDTEkB51AwfjhR+oN8Nn7Q8ZzgL9z0RKaX9zv3rGHKYvJZ8gwG0p2R8yZ5CVibrLQCtmFDCZTtIiXw50s2Rn//+tFN6v8e2qA/A9qD2inrLfM2IerDa7FzxAWH78sIrnGe2f9L0Qf/oHG+/eAPz2jl+h9/+qj60i1Pqrc/9zhdngz35RFAOrw1uZEj/1oqEbLmuosNnhudpKDRpWgYyGnEjYN6CVf4s5AxMurE9ykrrUCsX2kI0PjTeoKRFDkN2NrjfXL2/Gnq0fV7MpUjwzkwoKZOsOcQrvXQ2p3qBJaWEFKtgM9H3QftYc6BPEM1CznA90nsA3j99ssWql89uskbleXcFHAmWYSEyX1htGJuYbwkcpXnv9KYAV2gqxWwa3N9TpK+1cM5oJEDfZJzAGkFSq95WpO+FkyfOC4qjUrf4GcVJ65znQGmKkzMZSEJ5iCYp8s27FH3r96hv4P3uTOOj6MLtq4JBhNDzeIc4JV9kktivnQL5IBdrYAbr/Y9+ZnLnwtpBVmcA0UiknpPaPM5zVRh58CkLjNX7FQaG7GURg64nQNwMEqnKBe6FhlR5PRdlXBdcOQA9kh+zmnOgeS+vD0mrcCPHFBD+YYT9fNbnrMwHzngcQ7QGif0APg7kBJThN9qx/4e/TzpSgbhAxx6P+zpPjSiiwSQr/l9yd5JayXmqzH7DQU9spAwLuGIuXQ6WVrvoftGqXEijQQS6hygtlO/Y5/B/C3an0WqRNUq0hlQcg64pXQOjHHhG1qUB+UwqH2liGizIgb0Cz51S/T6NecdrT77mrOixdfX16cjUNikycj7p58t1XA0TkrCy1VlKbNSkcpKK9DIgYxShjL6zQ1qvCWrFUgFLUvoXmTo3fv0DmcNXhdiwVQryL4PKY1QuOOI5DjnRk/KaRZygNe3JrIYnwyJeubSKJUGDnR53rcy/5Pn3fLvcdheCKxQGl1ASxB8j5cSlH1AigopfLy/NLrBYezz3G/NNaD/b8/N+X562wFnXj85Oug5o+uy+coP6V4HdDJqp8fIyEIOuOCDdNB3d3ZEfSbzA+slnOsgK+IteSK8yAHJOZB8TTsH2iuKHoUTEuo5N2TvaUSwxuG6LgHkmgwj9Ocj63arj/9qmV5n//Szx9RXbl0Z7WsvOnWOBSH1IgcczgErCs/GSUZqc5EDORE0zcgvnAMXLZyp3nflqdogIa4ZzpfC5yYUfydygEHysU7dBnHaAKTxcyEH+N+1phU4kQOCy8SXVkD50mu2x9BqLmjdGy45NpoL9GgSOZB1zhmUXhyh5jnmEDpPKd2L5O5VO6J/JHQbVxWXjQw54IKtEzkqycTEcO3mnAMOjhk4h2T1Dz4/yTj1pX7x+YjUN+5k4w4BGgd6H20oEpGUJXYhWXxDPqF0NpIpLLptpXi1VzRiKQu2Lcu5SeSAHB8f8TGdG/gNrs1vKcsV8nXnQjrJiiF7D+WfA9SmDbsOpZ4F3f3Yhj3q3lXbneWSIfOmG+cARw6E8lvR2oXjpqMG5EDo/WYlhML8/PBxGsEAp/ZgrmAeoS/QVprnPiQMBeO4g4A7i3Yl+o6VViCceS7kgB0c5M6BAgGwduMckGsstD+Hq7RukHOgTCtwSukcGOMiSwe58t2z2IZ51Hn2lC5r4WnnQHtbZvSX3n/dRceYOsEZ5CwpsqGMfDL9LN5Shm0GWiiuA/ZY8rA+uGaXpRRLUqgswVmsy+AI5IDLuQEIdB7nAHUFRZBpXO5btUNdddZR5kBkY0U5z1yxkpwDcA6AbT1EaIxMBNZ+VjhcXA4QWXNacw4kLNVx35jUj1BYoU/o4MSMdNVz7u7siJQKDls1rPgO5wCbS5KTA5U4pABBQQfoH9a44XO817ldyuG2cfm8NKpEj4NYnpy/gD8z2iKfB6SEkXNgmCoWhOY0Si4Bi3OAfc/MaRs5YFJboGwjehgr7/guV45oHUjiOSmaHb43Tsch+frtq1Lfw772+T85y3q/EHLAYWi7lOvwUoaDYcgBtm9SeyR6Rl+XHDyJEQTD0qpWIEoZ0nrB3669XSLFgC5wVSuoDDMhIe5Fz0UINzhOZFrBlAmd6utvOEX9w08etZxAQNABfUNt5N1v884oP3KgrRLdMwYxG6eV7zwFV87KxNDiZzZH+Llg65pgMNlz+DyLx9o+l32RYL5ncfh9Kq1A1lhPnAP4nuSqIAcNnHP8WfL2f29aQQ6ixiUYY27cu4gygViSRiJee9MKHKUMs8b6d49vVefMn5qPHBD7o+04YAauhS4bCi61i5SU+NkrUZt/kaD6fvvY5ugfRBISSt4BzjmQx28FOWn2ZI2ckemwRcY35H4034k7Kr52eFoB535CWgFQNllbuETC0DV8ziJUEPHt+/gb+4idVmwQXkXy8KOzPFE1pMoaxk8WO51HDzlQOgdcUuIpxrj0yrQCh/KelQfHybzkQYI9mdZeXvT3N0s36cM1EzkgnQMZZbHw+xRyAGkFVBrPYaTTxvv6/7pfK8yEcCCoF3IYybiwIq7i3vw1riuZ/LWB4jh7QzgHkIOP8ft/P1xitZFv+tQEXr7QQg6Qc4DlqoaKs1qBqLXrcoBo5IBMKyCItyOfvla4GfXDso17MpEDac4Bg2KRwsfdkEhVtEPJlSMIcr3V2/dbKA2f8CnBFQpaXzLPXfI2cKHUHS6u3FK5NmDMcEOnnmIqFeQ4B8SeY547Rsvo74m9gjuYSDRc00IOmHnL+4SMnTzkAAwmGoteDwqABFf97A1PWO/7SrKZSgxpp4+cd6m0gpxT3EUMardpwCI2xXPlcZ5wJwqV0ks7N8A5kBjWrN1Ohn7xnjF20vuCRB3VItgbUUKN9tDX/ue92lFC+/8TW/bb1QrA8zE4FEXz3prAqp99/EzNF0LvYwwNuiuWB1bvtNIh5DMYEjMTbcQeHUKadsOyzSmSOiutwNFnspQh5w5Y8swuVanYBqYpZZidVuArz8eNWFrHstqHXCuIbNL4fOLXy1RoRDKvlGER4xH6Do9u83NCOiX5mcOfp9vnHEj6CuMWMtZEFih/A8E+hr620goSFJxNSGgjB0IR11T+F3L3qu2RM8PHW3PHE9tS7x05zUSOt+8/bDlL8/itSIbYnE5VKyhASJh1PwiVHgRK0Eei6uNM0ZwDyfmK8XksSWcLQcL4uDaQSggdMIRzwCYkN2dzETJiWyeSKbz540efj2Tef1mtIExK58AYF3l4uQxTX1oBSRZkFl8nr2EeBBAKGkXyTQmWgFKGnoPdIlb01GIlw0gaF9h4JYmfJDmCAkQb26yEwR9CntDP/vFZus9IMYOCohnOM5ADeZwDIURMUhEDfwJ/Vih4UPKINJG8vL6tspLk0EbPwUtxCc4BTB2X8iWNICutQKQc1AtuBrg3HYySHwGQWA6p42U1pXCjluYV9fUNy2Lm5kfW70k5kvh19rCSdlki70qkXjCyMK7OtAKxFiRywKpW4HACRp8nX6G8+VqJ3nBNTq6EuZaPHLAVG17NxFkJQnIOCCXdwB6VSCsw436wAHKAxEXQxWXIMQYuYjUSl2PM5hwwf08smFaQVf0lRfzG0WMBeaf4DgxL3uZxDuQAxE3CJ5ADgoxSOuuyIu9F5iQ4WQg5gL3Vt3aorKt97/h97CvENUFIC4mMIlLKl33lLn09cj7/0Vfvyj3X6OyVaUYhaCqcpxhbSgfjsH7p6Kf7rdwWG5l09l3/6Cb1yd+s0J+/5TsPqq/9fpXVNiANujNLGfo5B7gBSMaIQQwOOtcKpaeY89lOlZNCV6KzjMpH6iBFau/wn8E+Qa74ZC/ngJ33zuc5X2eTRCoGvo95tXwTQfF3RFxFeWON9eVKwcI+BjQiXyuuUoZ8P6T5MskR5ZdC/XzinMn69dduXZXpzPjEb5ZbbaQx/a87VuvX/33XGusMBb8V6VVcoupBSRlEGkPMaew7WfteFumf734o9Utlbt1lAjnPQHqtRXwUutqSXbkBlbHyZPOeQ7nOIvo8SslycT4xzoG4ben5WSSlQJ4TLmdS1vjJVImRELkPhDjBx6KUaQVjXPgmxmuv2sgBf1rB/h7OxC0UjqH8GsVSYuSAHw6WSisIUHh9nAPESM2jakVIjsjju+eQUhcumKG++5aZ6spr7owO/G/++YURRIpyyt73U9NGbMIGOaAyShn6kQOhbfzuWy6yPuOkhLYyMKTJdSZ2dah/eMlJkfJF1+H3wHb66vOOVv991+qYkDC3WkH6cPalFfBqBdw5EAorzJI5U7qsZ+fpE4h6uZADLucAn0sPrt4ZlXmU7ZI5gsiBBFw3T+ThTBFXUsRpTnOyxDwjaWsWckA4ByRM8V9vfFL9733P5BIhZYkL+jgzIYrMQw7IKKJGDgiHmVQAJUIHqA3Nps+RA6RQDoq0ghzkAE8p4lDaPCEYMTlSfciBwTzOARE9LpJWkJXCJOc+9UEouoN/B04f7N28/XAa07pDGoLTOSDOF40cYFF067mSixVJK3DNSTheyDmap3hfe/dq9VfPOz61t7mcO7zvNzlg8FsZvwtdhw8rrwzEncQ09kXQVBhL2pO4cKNA9skvH9kY/ZMCg2Z9UuNecxRI5IDFOdCWUb7Y7jNZVUauFeJpyRsfGZH0Vf+I7ot1USCyjFxxnlZgVSvA2edIjeTrQO7xgIr/9KH10eubl2+N/vGIfJ5I5AA1RXMYgHNgMI9zwHYU8D1D6gSQD191qsV6v42VzHQJIuDkRMtLN8UZSv9I75L8J6/697vVul2HojNb8vHwPH5yAOB3lJ9PDoos0j/6/4WnzFEnfui30et3vejEyOH2rbvXxKTZDpJjL4qAIRqwP2rkQDIPpOHsE3Lc5TmL0L+Yi652uZEDA4XKGLp0Ih+5n2/8RiNqL9XqEjngltI5MMZF5hwZQsJ0BKgvN60gXc9a5nLmCYdeBXEOhCAHhEEBHYGXkAG5SyjJETZXemZsLtMmdur8XM7aSs9hjOLkORncVNb8zorchbbx4Wd2W+/vYpEWqYTvPNCjI5Lw8koFGjm0upa2g3PAVCvwOwdS6RUqTUgoDSS6r8thESKk+JMDRyrhcAAg6sUVUR+MWc6l/7zz6SBHEubY7KnjoznnMxAhUxN0hkQOUPqHK4rqM/5COAeoPaEKWhHxXROElnl9IJUvzvjMRUIntYMKcxB7V3K/uJShMs4BQUiYFz0hhYsMHloHofm4JLMnd0UKIc9D5oqSMQZZHzhKwLrTCnKQA4wQ0yUcNUPR2dBSqrxdiCK7eBJwLsR7e5KL7SxTa78HmLAvzUcil/LkxmVb1Dt/+EhqTsKwue3JrbmKN9V4jxRvtn/ztqccNRlN4x9Rn3OnDy9/Jh1DRdBUGEtORhi9L5ByRfbV5Rv3Ru3TnAMiCs6fIyq15ylfLPcyk7445NQnCM0Uwj9DlWo+9aozoj2L73netIICzqX9jrQCF0+IK2pt9lzTJ5Dt+3uc47CbpQPmCeYxP0clGa+LkNBm3OdpBQbNRyVff/bwBmf/f+I3K9SiM4udD7TvFQnGII1R8p9w0j203VR+iD/7+m2rctPkXGcdnxcLZ3VrnYpuKTlxssoaWms5aa8kJLxkoZvXBVJJdLAZk2yUalb/uuYgHGHaOSCCg0UqFTiRAxlHURZ/zUiKdBKWnANuKfEUY1wsWFGfJ63AU787nVbgRg4cd0R3Llwdh63F4uwq5yMMyLzyXOTVlPlT+G1MuGUOyCJlV6Cgk4EAJambRVD4hoPatfG92zLrdHOuBJdyHtpG6b3naQVSCQc8GgcGHY6UM/tHZx8VvV50xlydQ8sN5zTngLINM0e5Rukk0fnyVlpBGCyN5tSiM+dm9gPNPa6syjxmQktIxRXP4+YcaLcMhRBHEvqJDNcT50xyfp/fSR7OaD8nCeTOJ1daAd0LnANZ9azpGfP4QABTDJWQPFlShrOuKR2ELlI6blDAgJT1nvF9XqKVExLyaGYI5wCPlIZEMOEY5alHv350YwSbpRSUv//hkuh/OFmtyHsljJBQKjtSTMm2YsiBkAhSl0gr4G0xpQyN0o7Hc5eptd/TfBNi78wj4nQJXeKT16dRPlxuWR6nB+UJ7cHSIYezSlY4eXzz3qBrEgcBFx5t5ONA/Q00Vdaoo5QrxlYadSDHC4nESzlMxKqrdzrPPem86sogJEwhB0SUW+oTsjSrTz501alOA8+bVlAN50CXp1qB5BzwGF/ybF++aW/VyDg4uLFuOdLGpHQkqAK2P0pUAU8/wG8wRjTnPnxVnDvuMqwJTVhEyMFVJBiTv7cZPh4814bEIRbCn+M662SKBUdGYm+jt2S1prSTxaCA2lOcA+25ey1HwsydEs7+n8050JYab12utQbnQDNE4dPVCkoz2CVlr4xxkYQkLkgpGHRdyAF40vF7LtD/yKDKIyW5/JTZerP3IQdoc8ZZj0PP5/U3To70ZmWqFbRrI5U29iJlV0CuRdFcVwSFH/50aMnIEldU+DNkIR5w7xDhpZZIdrNyhlIZgpHLc5lpA10wc2L09xGTTRUKHsUzlQZE1Bb5k8yrL+8NRd9KK/BAc7nDgsi+rrn6HE369aZnLXA+P+CYR0webxn5EqYOqD/ny8BYuXK5i0LuyJDQEbHBIV0WU6JpyPHxlkvjZ5GKI+YaR+lY1QqYscsjTjDKpneP80ax8mCKIQqalJCcaIpKZV1TR2aScdJcCx4FH2gb7aASETw8r2SJt5EDA7rsXhY5p4zcZ+1rLz51tkYOQN71wyWp/kEr7npqu3k2zjnA5p3kHMhTyLTzKEEpSeG53RHRYg7nictZBscVHx8oXYcEciBuS0hagXAMifa4nI8+WbW3klmmlWSfKC/qE9qDOVdK1HaPQzE08ptC+WCfdSAHQkjT/vySY/W8p/57cG3MlcDz/2upBEP7GtJqpLOKHAIQ4mjA1E1VKxCIELnmJXIAOd95MneqYb7nU8MXMaymWgFn1HelArnyvbnxJedJERSSlOecOMvqX81v1NbGSsImyAGG3INeR1/HPLYcBSyo0aYqERTfJbL35kzuynRckWOLnA1FgjE+4cgBk1bQFs/5NfGcDxV51tkpFgbZyNMK+FrlJJ8u5AD1N36XrlZg9F5+Vsjc/BDHIPrXVa0Ac0NzDljOq4HqOAcs51jjm5Ry7ZXIAbc0/kiWMqzCD2xOeGYTElYyOAfy0wpo8eWRkhx/xCRt6Pg8+vy1iRjmIAccxpxVyhCH+NBQ7sZbYRsvmJzpmQ1rs21cQxehA9fkFJvPXQqM7RxItz20jSfONgRB+cgBU7aRi84BdXieLeRAKq0g7dWHSNJCK60gA87PYWmvOGeeJv2SZJMkl504S31g0SmpdsbPYudlgjWaO7Z8BGjVOAdiD75ReqE0fPzlp6vXXjg/+vt5J82KHB2nHjnFeQ846izkgBVhtttNUOEXf/H2VMSNyK0geF7Xmg5V0HykTvVQ+oxSa49XmnPAVsJh/GKNS0JCK60gqlbAkQP9QdETaQx96GWneve1o5ISXRTJxX2zTJGv3PqUc/5xBUw6LvIJCbOJAC3kQF+c+lAYOQAHgJOQ0JAVoqnOUoYSOSBSSuS+IJ2TWbI3EJ1NTsVKDn8Jz5XFvY1j0+4zcGzkifwer87Bxx797TtPSZ5zwkxtMFJ+NaFUfpVwCBgkwaGaKsHQvnbIgRygvedfWYWO133zfvXFm5+K782ilNEzCkexDgokbZTBhuNmTQo2jCB8bshlonOyCyEHsjkH0siBIWdOd9FzhF+TyzsvP0GdPHeKjRxwcA5gLel5StxO7elzkRu1cCyRPLV1X7Aj6X1XxmevT8BOXyQY4xOzvw9EZH3gxKCzzlctIU+wLrguFjtKzD35nmoCDunURP53TLbdZhMSsr0cZ9v333aJfu9NzzpWozZxbzgG8/qXO05kW3CGcMSkDgxmoObykQOq4cVX0rQUW5pgKEsZTrEPL4oaDaUJCTPSCvYFIAew6SH6e/wR3dHr97z4JL3xcaPRRfYSX28oFbHKg8pKAzvKlezr1wpSJVHVqR+yNl4O7aLvYXMlpZiIklzETLpmMfM6QxHikGH+DNxb7XIOhJaGkYgKMPbH7RlMQbxdRo8sJ8fbygkJ4fjAY8h8bychYfIdF3IgDybNRZJN8pJkuA/3yqMtmFu6lKHDOeBEDrD7kYc/xJHE7437kpJ/4uxJmquCxhVjL8cdEEDuiHNxDlD/IYfYlfLwlVtXagZorI+p4zurUtBQSpND48EwXQ+lTxr9/moFthIux06XMmRpBUgzitIKmMFyiCEHeNk9KTJy//yTjkj2sTnR61ecfZTe10D2OWX8OOdcdUWQXYiKJ7fsSzFNBxMSstu60Fh8397fM5BCZ2UJzgko4h3OUoYmQgw0gbOUoThfAHn1VitwIGZ8MiWQ9ubNl8YlCX09+sFFp8boE5Gv7uMcOO2ouAZ9npyV1E13pRVwByiflzhPyRka3Tv52gmzJ+tx2bbfjQxatnGvWrP9gKpGkNoAZyUQc9h7JFoClRMk7wF3gET/A9WQPLsMNtCelYeYkGXR+NnjQw4M1ljK0EIOJPfIqlZAkdlqGNLnTE7v1c85YZZ2GGnkgHakmvQFWfkjSitwOA1tg9g47PcwPS9Prjh9buS4IgSBlDPmTdGGbpFgjE/Q9x/71XJ196rY+U1Eun/7vcWqWsG5xHUC6hdOGmsjB2w0Yupvtn9hXqDqBde5MB48CHD09ImpMw+OQamvkSycNVH3rws5gL/xW6n/V5NWwL/fDMiBdFpB6RxwSeOPZCnDKtzwswkJA9MKOOeAOMy1c0AwWB87s1sbVxIlwBldpeHPfQXYkIogB2DQrNl+UB8iX77lKStnFBuv3CBl2RUo6D0MOdDtNa55VDz+jO+hrrQCGfEuWhpGjpWvWgEniZNGhySIittnDkhZzkumBZhyjexZhfHWljhnqLkY3yKeXFcEhsbel89Kz0KHPLrAhRzwQYRJ+Lz4QBIhyXLScEWCxoQ7ACRRF8ZMGmVwRGGt8bz56DWD1oeWOcI9FwbwgUgFLa+U5q4DPbkRPiJZzFL6jIMwLj8pDQn9PaEAyZrmOu2ApRVwxIuFHOgbCEMOOBA2dE2KbJLMmBQ7e1DCjmTKhI5UPnpW5Ir6+Pn/eps1bnC+SKUwz87g+680pOP+Na/R3mo5B1ylGBEx5Q7FEORAXw5yoEgpw+OnDKm5U/Lhzn93+QneiDwJeFgk3wHOD6loZqVm8E/kt3hZNl7GUnJhUJ+cmzgWsOUj9SBPfvCHZ6Ic5qKqMdLNsB89vmlvtJ/k7T0rt+4Xedn2uEr+EBlsIGdBFmIChikXPjekcyCvike2c2Ccc31Jpny7VBwcj2S0V1IOx7w92DXPaaw1sjOFHDDOODiD8agpRJ1O37J1EVwrFAGDa9M43f3+y/X+/LKzYr0Jul+RQEfWXEbJaTigqiFy9J11HFFFf3M+G96i+1Ztj+Y1T8nAuUJnF3duas6BZB5xFBjmzt4EnULCr8mF+pe4oEjOOGqKeveLTor+ntHd5S3zG/0NQkLhUOLrjfMqFUYONIGdLYM+vgoLY13KXhnjwkvQxDWuHc6BDmPcFOMcsA99SZYEozT+LjvQPHA/fojjmr6okWb8T57DZ9AgsrcxgaRh4z1n/lQN60J+O2dsH+/kHLCRA3gO2uAN2V4lpajwyIWrWoRLEDXCoXvVmYY0kD+/PERdDhUQEsqIqCutgOeJajLBIRmVsBUk/nwaQaH7wfQBnwOh4orA0DyUpeG4g4vPKxh6LuSAywvOI4NkBH7t9fn1e3kUSefOR0q/2zkgxx7ljqCMSwIdtOmZnQeDyxzhnjSPiyhoeQzTYK8GeZVvJM+YNzVT6eNRLRovHknNQg5oBxNKGYqUKJpbes4NmfGQyIEszgFfzj/eh6HMFT1CDkAhyxNyXtJetXmv2/ly2+PbrPfbakAOyD2bK6YhyAGd8pI4SO1qBYlzIHG4xAaJyihTa7fFRDvdfBPSOZkl9NMPJalGPsE8x976p+cfHb1/5jyT7qP3NnHvPAcGpSvg3OP7hNxD9bOz6/E9zpUPTNFFLuRAeGLzPpUnxMHwuouOif4O2XGnJVVUaFgu/cyt2lj92+8/rC759C25ew+tQY6KwbjKuvQ4uyRyAHMV4zMj4VKhUnryOxDOsSG3m7wqHi7Zl5RuptKkWZwDrtRI7niU5xavqOPbgwnVI4X2KX2OyBQsmjsiVYOfv3w9SYRW/LcxbM+cNzXX4QvhSJA5CYEexkWW8w0JdPiE2kYOp3qI66yzUBT9Rj9ZuWW/uuxzv9ef/dX/Lo4ct/uYQ0LypWgUkOBhsdMK4s/2HjI6tQutqz9Lrk0VDE5KiI75HHfNb/w9PjmrqJ1YI4ZzoGBagYOQs5FForuaoc2jIWUpwzEuFnKAVSuwCAmFEROKHNAwc6HQQ0mifEj9XRZZ93IOOCD3/QHIgRBWZlKm6Hu4N6Cwzz3pCGf5FVPKcFArxvLg45A+HCw4OP1pBe50CJdQW2NugU1qagJNl9dxERLKPtNpBV7kQDqqziMP0L/SlQjSkRlptPO0gjzOgXDkgCn5By8xj0Tz/gbJFScklA4MCDmYPvizx/TrN137QKQwkXI6vbvLW7+Xe/D7XciBpH99qTDIAQTcEAofBMuLKydZQu3k68NXvpKIKD/2R6epqRM6I14BejYa4xACw+ndnc5rEhyXom8LZpkIkkt4lN0i9PRAAjGmJrrj4xzgUV9yDgzVzDmANnCHIQSKHqW6ULRxBysp6pLZkzujiK7P+UJ3ImKwro6K6ukPWy8W54BQNuWejvZSF4WsQxircJDyqIysFEH9lEVIKB2aulqBRivZY2IciypIrjh9TjQn3/fTpalI4/zpEyxDhJ79ggUz1I8fWq8dyHxOoCly3kkHBrYQWmf/+pqz1Ju+9YA6aup49YU/PSfaJ079yA3RGMhjjO8TNiFhel4ePd0Q8MXfaU89n08WzJroXKeufW3n/h71tz942GmQ7cyZ1xDOc8BZ9Ulk2T1p6HP9IuL0SUy6i48z5zM5FLhjj/drKiUpp4qHSxAM4YS/HC2i0woclQCy0gqoqs7rLpqv/ulnj1mOfJQQfslpc9X+njRUnuYD0k6wlvk5qtN4ElZ9nlZAa5W6JEJQJWsNCCsIHDQ0f30lheXrB9bsVBctjDmB6AyhqgFIYZGOVRJad1SukJd2lWeoS+j7eSVxQwX9zPcAWbkBust1D29I/Z4ct7wPqJ87hK5FZ5p8pgmdDHWSfMbXrkwB5aIrL0Wohvg9XpnLhdLSnAPMyUjvka43VqsVhBDvjkUpnQNjXCRhjity7SqFBkHuFEocZXEOSOfATgfUnRTAEOQANiRfviA3skNYmemQoe/BEQBl18VMzpW0iJCwx4McYHByXeoKcHq2QfFHkIiHPIFxy/PUcE+w4tNhYxESigMHB+wEwZmgc0A5864FnxWGmUBHuKKEuLVJK0j6IIL6F3cOuDZ2eh6T0mIrnhG0nyls4ImwkAMOiLCvHjgpBRQ5IwWbiBKz2tjP7h0Rjcm0gkQZkSSLGjlw2I0cQH+7chBdQsoXDLau5FpcQXvnD2LOgj+76JgIBcDXDqpA5AkpedQfLzp1jjrpQ7+N5jjBHy8/dbb6t9+tzFVArAoTEfLGjargZI+uUqfaQEVaQcJBQcKV4nQpw6xqBfY6wb0m5CEHMq4J+ZPz56uv3bYq1/kyqatdO7Ty1gv/WEaouVOMt9dVAtYlcg67kAOQOFdfec8SaaQBseTlHCiAHIDQPKfc93/+9Qrr/fkz7Og7yewpMUR3w65Dqai9vDeHcrvbaPqeylrinOHIKS4DBZAD86RzoKNNzfHA7lPPOHl81BZa+xd/6ha1/UCv+sQrTlevv/jY1Ly6YWnMV1KLcJ4RWZ5UkudpIsu2StS/ktEfexgZnNTWAcd3+JzylTSmr1D0lP7PMlDpO0gryCckTNIeBcGfIUI2hnn0/UqMWJk1qUu95hv3RqiIr73+fN0GECG60wpsiLiNOrEDBrKiEJ0lPA2PowRlpRGfE3nqxHHRc0IXJBLKIxNjmwg8SdbuPOjUMXi/uYIwWRJKqIn5A6G2vfLco9TXb3s6ek3PRM4XEiLWxfjLYEsWcaX8hOYwPTn/Tcy5IpwDuWkF/ntCL4tSJUU6He7nQw5wXYGejeYQd16NJedAM7R5NKR0DowhoY1BHn6pUoaO6KVkDueyn21kPs4BDhEmmZGUc3NB3em2muwpVfqIbbQ5yAGTP9VWFXu6dg54DK4JjrSCFOcAixhryLxQJOiZuHJbBDkQ3TNxSIAU0VwnviZ57sk5QMgBUgxIQfL1GSowmPbbyhqeBc82lByJaL9MC3AhQCQhIYfVymoHIeIiY4tZlo0xyJ8lip4whQ2RDBfnQCiUnr5Fn5OC7TpoOPRd584TckDAQXsHkiiNh5AQypfL6CI5ctqESPGRUQwuyKn82u9XOg92UtBOmTtF3bVyu/rS72I+jmpyOWEE0DPzqIZ2fuU4B2QpUM51wUUqQLgXvib3rqgaipVWwJEDlFZg0i184ku/0WkFyT5IbdqW7ClrdxzQz/zXzzte/c99a531t/MQFfY9w5wD1O/Ya6QBnkYOGOdAiEgnD4/uy0h/VFoNyIEAzgGNHPBC9lVh54DrPq7SoiSAROP7NvGWMSyt1AexNrEXDjHyS8uY9ESvtROR0o86spEDR06dEO2Z6AYiLbx4Qb6hxfOrIyRY0vZzj5nunFOrttcG4abn5jwjKV4YnfplIwdobCgFUTqyNEdLR1vkEDnAnHsQU70k3R7+jNcv3aQ+KRyhMHBfePIs3R602S5lmNaVXAEOzjlAwg0y9L0h07WNZc43w6cKOY4xL3GOcCe7tY86Uveonb2OkrEQ7GV4HhnlpxSoL9/ypNNpTs50Ql5GbUNaQaADO0RCiW+Ja2T97nhcX3/RfPWJV56pblq2WX9OKRM3L9+ccnrwNCDqWyAsQ8SdVmCnckiCUejJewsiBzgfAndOGr0jzYXA9xGz3uz5GSqd7bxKV+Nnqqd1iMZv82hI2StjRHzs4jw3MXIOOIj8jGfa5Cc50wqEomnSCir5aQWOXDipxPFDL69GMc/froY9HYeirEDgSitwlTKUbP+aQZj1hTaMOecA2p3wPOQJ7ulDDqBmLl0XTgxfn6WqLQiYJ/+tRUgoDLOsvEsJ9zflyFjKQaB3gOb0on+7M/U+cShIhAKv95zHOSAdGHnIE0RzXSzz0b1ZP1hEYylCQrfhrAkJgRxIwauT/hqKcyazBDmVWaU+500PWy8uqQijg89LiogY6GK2khjBhpPH4pwdHDVB7+08ECtsT2+Lyc4keqXDlVbA0mG4Mkxt5dG9opwD2mHYO6D3W6QRfPDnj0XEbSSnHTVF/dklca43yb//2Xn6b0Ta8sQqmxqwXnxGqNyzAWkNLbUmv2dVK0iVncwpZSgU4bwylqZagSokmIOhzgEIV5p1yhRytQfyHRhQzLnBJqseRN9lJJG01i1CQse6oTEgYkH9nXFtajyDK/tEkr0Zx6V7PiG9olqZPnGcs5IA7ifT2IACwNhIVABH2enzWDgQjLPQ77Ql+bvvP+wlWL1x2ZboNVADdCmeQuiqHJNXrQDtltfAHgKdAoJ7U1/wKgBL1u/SaxvIMz4XLQRWpIck7dQOGWNAUluln40TGPJ+I8fFy846Sv3wAX8KFMnitbus9+vpHKAzxuUsk8J11LlTJ0Tt5/veLSu2OPmoePCK9iKOCMsTU8HA3CdOxWwrhhzI4BwwSBFChJh76Otl6F98H9FOhiqrFTQdISHbC0LT58ailM6BMSBZ7OK/fcx4UMnr7iQkZH/LzYoTEsaR0cE0ckDsGJSPLAkJeVqBl3OAGY+SEEqKMX7ac0vmRN9rt6MaOAh8hxlPKzigv+shJGQGKd+YpIIZfddRLSJLQIwklQmeVgAlBKkFPuQASGqyECOcyV+yhRvDLH7tGqMUIaFKExKGbNaY01v2pr35ROT2+Oa9NjGdhp9T9MdAoKHwZyEHqkGe+NIzABOMlH7hHPCRUaZI3zzRSeo/QD9dStPVF83XOZUo7eeOEFd3WFYcRgdHtJDhqdERAQqIk8gxeY8UdjK+b39ye/T6Bw+si16jKodRfpPxZYSEgBfHpSXN3OS5nlnIAfkZ2oT3t+w97NxvQf764JqdOhWJ5JS5xBsSy8ULZwZVj5iekLHxZ80S356aQg4k+/m4qpEDpi0phAvnHAhADmjYrKeMZTVpBZKFPMs5QMYsfwY7rUA5K7WkOQfMHskj3RAXaStPe6K1bqUVeIyhedNMagEp/nxdTxbpbmCfl2RvZo257wHEX55I4sVZkzqdc0rus5oIbtCOZBJsnYSjAjgKhq7LnfVcXIg9iJUy4HgOvPep3z4ejR+MTDpzLQQgmyMmjS0dtdVoxqQfePoYjEYgAek5+FqFc4Duy1MEiffmw794zNrj+Fy0nKwMfm64EQy60YUMNc+VnhMhTnOedlok9S1E6NnOPtouAQrho72bEfxhTvF976u3rszko4p+1xdD70PFEDyasaC9QO6JlnNAIwe4Tp2BHEicQfS/5NrxlZLW7Wln6bsCqTOW0gpcFalKiaV0DrS4hLCL29UK0hBKvqHxzYquDcOYXwOCPUnmSOcREno5B3TUOc1SLsWUhYsPyLz6yEfPMPVkqS2aTTYnrYAUlkMoZZjk/6dJEw3sy8VsPFQD5wAcEhKizEvmTZ0Qf+cXSzZGOXVE2Oe8lqNEW9x+7nk2MEhJOJgqU+hKK2DjLNETsqKDT0IIJn+3YqtupyQk5BEyHIR2tQIbIlwN8sRtmA1q51lnRyUFB/WllAB6CEec/BwvMcdI6b84cXQRjPKS4+K/T5ljjNAs5EAoqz6v9e1jmIZDA3BJKO8h0Qk9/6xSoBX1yI6KeucPH3E6O9cl+eHaQSXKfJFSzA07rhDzSFE1yAGsxY0ZaR0kP1+yUe09ZO4FRA8n/iKpZDhfuCMyCDngcQ6kOAfqiRxIpRUQ54B/35aKMF77OQdU4Tr1PmJdSpeRfUOKNl/TzrSCwTzOATbXwCnC2b0dpK0SisyNSJ/TipMS0nfozMW9X3VezIVCzu9/eeUZqTZA8Ay+s+f0I+OqDSrHcXXfB14YVfi55upzov+/85aLUpWR4ue0HX6GkHDQQnho5ACbq3zd0hyE00SmFUiHNZcQQyZGhfWoVXsrpoyhpypRfM24Ha5yzEi7RFvttYI9xIwvJzbF+U6oONmPuxKy4R37elJzMTJIWaUec8ba943L7Jo+lUasy18U6jTn0u1BYlYrxyZlNeWY0FlEznDf2uf7HvHr5AmdLdCjQkSinqQDDML1y3EO5EBWtQKtN1jVsMznLj3aqmQhuCrQJ6F7f9a+2MjCz8tmaO9oSekcaHEJIePjGwci0F7kAGNw5Yq/yzkgSeGkc4DnCHLD0nWwknCvtyvi4to4sdH5SuZQdEjmEHIlxIccgMFGBziioynkgIZJupn4XYohFAiCOJMhn8ekbJAD7nzMrXt7tPLwrzc+EaWTfPmWdC65yxGSVa0gjkrI6Jn9XFmKr3YgwDkQEUKFIQdC5jSUKd0Wzv/giN5b1QqEop+HPIFSzJEnXPghDadNDBe2HRM+5wAMAkRhvMRsbK4cShTrS084QkOOuZLQm6EInMCcCFnyT6w03B+fNy9V7lOmFdDtEdkPcg4w5IqGylaUum4N8V2khb9XAWrJYVAaRIutfKGih8zVzeccqFgOw7w1SwgFODEspn+qn50Qk+WV9+JGYoiC43Om+koZhjI4yyhTJnKAp4M5ov0DXuSAQZVxkcilUHExnP8oQZ4QIokLT/OwqhV4HKN+zgFWtYHD0PU5ppzoPF7+zJdWQHIUQw6sSlJssLYJyUJy7vxp6txjp3sjknlpBR0Za5Y7rui+BDsnQlL6H3NVRqYlcsCU3RPIgcQ5wNNBOPqD+odzAHEZykorKEBus7fPnClcV5BOMAyVm3PAdoxaTqLk+/QZpsdBnpLFqg35hBBzPLVK8x8wPUTnpou0gjjlzbQ1jYJMj32o03y4kAO83978nAX6vf984/nRWeRCFWAMilY5oLEfYhqAz3EL0RwOwrEpz27XPs4RbEFpBVG6r3JwDqT1aCvlRCBDq65W0GSlDPlULvkG/FISEra4FPXuuqKTfEPjhzK+S5sDkdPRRmZB/zRywN4wqAwQGGQJIkeESq76uymCKmZYZkWgonY64PmukjnkDHnrdx60DCtuaPuUMY4c8HIO8BJ2DueAjKyTYvqB65ZGf5PxQIY8SJF89X4nJmiFFHIgef77Vu9I/QYRkNQzpdIKbIIo3lY6eNoSC8xwDthGtY5W8t8LWGOFVysQ+ZD1mNNa8WSODg5T1tF7CzlgH+hAnvjKOLnyd7nwEl0auktw4YRXIsU54CEk9FYr0PNIOdNiuGME4iubSHLFaXPUh39uSjZKqSSG6klzTCSRFGbX80tk0bYkuhWGHGCKa9J2mru7e/MVkCe27FPPOemIlEFJxrdFEsc6TVdwyGmbZNyW1QpChCuAcLLy/ssr78X3mpC0AvSlhOCnnAMJpJXSsUJEOpfaA5EDzrSCVCnDxDmgHWoymul+pjzx1UZHjjlHv3AHDScPk3wHvnKLhlOF8Y1YTgbzuQ85wDkHXGkFdG587/5n9Gsi1vvvu1brvWlzknpF6XzYB11GBydBdAnG9ohJndHvOTmpqxQcBPtZyjnAHKXxfZPv6WoFEjlgfs9L7tEzwchKkyLb543reUJkyjhzbkrElBs5YJ/tTs4BR8SV9icyzOk853rIoxt257aR9kjaLySKRaMDGIJRf2alvBleFjpz9hzK7is4zX0EuJWk4gdP/asn5wBvF09fe97JtO+nywZyA7ioc4DWBMbyTc86Vt20fIsVoKD5z19r1JOnXKebcwBpBX1haQUMceiqVoBl7EIOUHvMuoQzrg6cA01gbFtnVDOQJIySNP5IllKTFPXuwsjkC54OLFPOkDkHkIM3vkMb0VZawaBbSaTrgXcAUF6+aflQAQaSbhwIuciBFAS7YkU1DPSfRV2TQ5kOSJ/ibWqaD3o5B7hB6iLb44ohcugR5ZcKq4xouZADnCwS+YdZIp9Mlm0cl1mtgCn6Q25UQLuHbIt/xpEDRpGr35wmJYjahdSPxzbs1XOUkwJmcQ6QhERzixi543i1AsE5IA0uKJOIiqUiso7cazis4lJXaUU1i3yIKlz4oIXcGcKVfSACpEiiTOMcyFYS4yoe8d8Prd2l+hKugv5AQ3CPJm9MR6+xBGm+udig80oO8nUSX6+4c4CPBfgHZHRT7lV8PlptCIiAamfqQGC1gkAFsasIIWF7m1Nh9XMOgHDLjShyGdYh/f7QWjdxKK5CKUsYH29agUDrYO/KKrfocv65iCIxJ+lSNG5WtQKxbnBucGcTzg2gh7YkRgsh9kyqjsjNZ2R0srqQbmvybMRN848vPTn6m8qTUuqACzUEkfBlL3IA+5QHOcADDyZtLl5/hgPIvofJxU63i36Xt3Lo8yOndqnjpwxZ+o7VLy7OARG8oP59ZueB6O+tSYSf7+N83miSYYbMxL6ZJ+RIlM5tzJ/YiEza7EAO6D5lVUVc7dPPnZGuqc+Jl51urdu6OweSgcW+FTvT0mkbEF0ZiO17hB7NmwekZ2EunXPMtGi+H39EXFnmH15ykvrd//c86/t83Pka6AhKK2CcA5nIgQSdECFClINzIEEOsGvwwEgKOaCrFdTAOdAEtrYrnaeUtJTOgRaXEDI+NyGVVOwqqbQCXfO3q4MRuzHkQPK/C6Iqyxly54CXc4BFASSsU4qvZrwUl5MBHntfpQKunFOkAs4EyTmgSzN5yPbwNx1UebwQXGHlgsOWPuMG7jM74rrCWSKvlq62YCLeECiVcbUCJcrI2Q4Ql5MHl8L48WtIx0EtcxplJdftOhjBhZ/aGitmX7rlSfWma/+g72OcXub+rhQQElJ+SSng+bRZSjGER2644qYdE6wkkTutIFtRcxlJNnIgbRhmcQ6QgrHAUfddOkO4su4rcZhyDiTloLKMTzD9w+B5/3VL1RduejJ+nkDFZUaSLpSGedtwdJfylRc5sSoFeAz2zLnZ1e505BRRVLhSGRKsCUUOGKdqpUrkgDsdDW0oRkiIvN00HN9Op1HBQpFVGM0ukZVHeMUCO61AuflWhBWqC4mwtAJ+HrqqFfBysfH325zIgVA+IaQV0Jmrz3FPX2ciB3DmDlBZxvj7x87qTjmupBjj1K52hHFFf1jnJTNWdVoBRw6IvRJOE28pQ0/7eN/6DNwPXnlKNN77vGkF6TPdoOYG9X526+Pbovd+/ND66DVnv3cZ0Bw5EIpyIGeWdNK7uFtwOV5RyVVJR9/fMyfynOaLzjpSHTHJpOZMGFdfsDL2G5wVROgIA9mJHEj0Uz6XXnP+0bn34emItMbp2jO74+c67ohJqSoPJq3A6EuuNrkJCXlagX+vwhrknFa1cA5UXa3AUX2lkcVV7rGUtJRpBS0ueZBoqVgAuiw3iHgjGbDTChh7LzYd7rmH0uZagGDbhnOA55sbltV0dCPPgQDx1YyXYtITBlPKuoykuwy2iHNApxX4OAeMUWilFSSb1NINu4NL5fHax/KeZIjp/HRGahMq8nmNIunhHGDwbBJ5QLkcONIBgN6g38oazNXMach5x05Xdz61Xd28PC5DxQUERORA4l5ymtvj29q9zgG8J8cgT9CPfG2Q46UzeV46lKkPeflNLjJamCpl6ICwHtSlONutclX6WQVzNhdSZtfuTDuX5k8fr2577+W6X/jzIF+f2sCh8HIeughP5b1pXIc8TktaS9M6h9Se3kom6d/p86Z62eMNEaidVhCMHGCGuSvilycXLZihHl2/J805UEBRGV8UOVBx75cucr5iyAE3/4L8O2pnhDYKL2Woy4F51qOpBBCOHChaecTmHEinFdCtaR7xfdHHOWBy+tNwcu4skbn/Ps6BUD4hXJnQetoZ6ulreT8uHAkGB0vWGWmuZ/qE1hv6UY4rPy95kMGFHJCcQqZagbuUoW+NRPNxQKlPvvIM9bXfr0xBxemceeHJs9T1a+1giKtfrGdJ/n9swx6nA0dC8e19JM0jNMVRTUNKJXGc//rRjdY1eYRYlnrlKWeaD6edeC7E2s3YY/JSoCi1gPgQhietwOZK4WPjyidHWgHf96i0LDky3vWjJdaZRumvOHfo++gC9B2vNpRKiRKBBoyFXFt8/aDPXShGl+A8pxQb7QRzGL5cj+ZrTqJm65FW0AyR+KzUt1KMlD0zBiTLu3vO/FiJhuzrASGVyzlgezLhSCCYnUYOODgHXMoGvK5wDrhq88qNkTsb8ggJfTXjpbhqweaVMeTKCBlF0E3l9/Xmyz32DkVix/6+qhVbugYOGJ53V5Rx1klIyCIOEG4465JwcA4IzgCcU6u2HdDkil5CwgLVCrLmNGSWKKflkj2H+yylB4qDjNzVKlDAuOJKikBXQkiocz4dpc6cpfO8aQXmPSiWE3I4B+S9YJy7cjLX7Tqsbl5uSp9yBZ4iN4iQEVfG3/9wSfT/F292k1+65mdIFYplm/apVy1IcmPFZ/y1hnE60oqsPPDB+iEH+O8+88dnRcolFzBqUzSal/hycQ7kia8NPunwOFwxhvIaoWW75Di2ZaUVcOSAw6BPccwIxu/UvE9uXcQ5ULTyiIUcYFF7vm9Q83gVF39awWBYWoGINvLv8zYU5ROi8oVYD3Q72yHBHJee+WRK75oUpzDngGmzi79GIiRoHnAjzRASDng5hXS1ArFv4R4cbs0F937OCbPUHe99gX7/tRfOT6HCgIKS69rlEMOee+PyLUGVojjiRiMH+B7B/vatdlofNGcksS/vV5lWoFMfB021AnovXREn32HvS4EijgrIik17cwlbiwj6DVwpHL3pQsDg3ONnF537NM7PPi52+p84e1KECnz7847T34kdK+ZZed/RNXkAha8nXjqQ/xYyvpMb1uk9Nws5oNMK2Lha+28mcsA4gMDfUR/OgcZ3DnD9suQc8EvpHBgjAkj06y6My7s896RZ0WsY6RBfuTTATLmhuD9xJJDSi2gANhjyZA4mx1hHBnIA5QztSgRJrpQnrYAWtytayiUrMsrFBeuE4hPiHOC5nqnIuwdOLjcp1HGuVrFFbWSeowhOhyyRh4AXOeCtVmAbpXx8yFD8rztXR6/JMUCGIhmOGxOWI01ICENt0EaPhEga5n+x/mz9bsam5BEakyXrduk29CRoE1lusVYBdwOHkUacA6z/o1JSjlJnLhIyHyEhT4vA/KcolOQcoO+5nGchxjlPb+HODsqjJaeCjGRKokz9TA7OgZBIKEUsuzuU+srVZzudnag+out4O1IwsO6oD1z7R17OpQ0FNdcnAwSfPfv4meptz42VSyorSXP0by8/PnpNEUgeucK8KJRW4CDHyxJjhNrvox3S4AktpZrJOSCU3YjE1JHiAsFY4Jq6WoGH7I9H5UOFIppZzyYrj8xihs3OAz1OB2bs2FTe+SadA660Aj4NOS9J/Nzms4ef2eXkQwgROhO4MswNGm60+4lVjaMDhrpMeXKJXe2InSWSrA3nJUMOUF8hku5KK8BY6moFggDVBbfmwtND+DSaPrEz1Q8+5ADfj2UVAB/5rxQLOeCoQIR99LUXzE/te0C3pMkxbSOW+h5ntITe02/wOxovV0pQNUJ6wL1PG46Pv/7eYmdVkHohBziSsiOQkFBXMEjmFBFOkoMjUQfMWSGi8xw5IM8RH3LA1v+Eo9BhqGZyDrAqR5JoMu4bs15lu+IgnEnjsTgHAslom9U54EL6lJKW0jkwhoQWAsqUTZsQH34SVovDLFW/GuRp7Pv6sCRCQlFnmHsrXR7RGYlTYofgHGjL4hxwpBW4lHt6j3LNAd/L8lTr67BNmEddfSKVInIkSCXdhRywCAmTS5w8Z3JNpfLgLefRBf48Pjn7aIMaoUNKGp0uZmtcl9fR1tUKkv+f2rovMhSlYUhjATg1boU7RoSEAnkQInbEYpYel1ClbOu+Hn1AS+RAvZh3cQDxMluccwAKho9EU6YVpMvz2Q4ufh8X5wBfw7wNIcY5z8fm0T0i5SwSD3IhB0IjoVRW7IrT50SOodcntawvOzF2dkKxwTJzlZZDf3EDnRu543OrFfCofXofwBhgHyHYKs1RKK7bE94FCBA/IYiZatMK9BxIIQcGregsJI+rJahageh72k+yShnC4JOl71yOVRKNXCoQiaT2zZvuNqpl5REyYP484SchueGxLdqw4cMepUQh2p/iHDDGP4dtu5wHEG7c0b0+8ZsV+rPXffN+3YYifELUd+QA4mSDFpcMy//3Rdl1asrAYCHkAEf6cUdzynBi5yX2Ftr7NCrAIiS0HS06rYBFhPNKGfJ7cuQaD3xwMaUMA5ADBSOSfN2ALwfpjfw8ozGXvDe/eedl1jNgLhmD1BiBxgEff/9Qsvcs37RX9x2tWxeRc1EBCk2WWc4jWa6Fc4A7brI4B/jej78x57An8rlKf8t0Q46m9ZFt+hxgmLN8rclzPb5OBudAck+esmRzDviRn3G1pKT9/bWVMuxyIKEaWfi88JGvllI6B8accG8niS9XKp1WkD7codRGhISC9Z1f1wXdAWEYlTL0RaSlgcs3Zx8hIaDNv1uxNXr9f4tj8h/fQeS6zqEChIQQF8qAR96115l7LRkpH1h/8xRWl3Qn7eRl49CfVH9eKjNo6ylHmlJ0rgiQi9naXa1gyPr/5kAopUwrMBUdVNWilZpAe4Gib7qcYfKcUrmqVQzngIkQI/ddk1IODBqobCqtQDrqsuHVUCppetGzGUeaTXxIwpXAovnYMr+3iLgUkNBIKJUVI6G+IzIoMLHTa0n86Yo245G5gshzevOQA3xfSPFDJL8lhRh8CyAwwzNL5wDGq4gCbjsowp0DUtfs9TgHuMJXLXLABU020HQ/cgB7ax7ngMuwDhEgrYAycZFtwrDhZdi4YXPr4/H5gvvntZHz4PB+cfUHDALad+le4POQbaAUnzy2eI4aoD2H7x020awN8XcJR4ph7Ycym3MItnlOt+FEz2+Y09sY2SA36Gw9BXskDBxIFn+M7H+OpACCEkKXWbczRqPRnODj5eIRKnp2WMSmDkJC7piQEH6+F5CuIUsZuqomkbOB9KLHt+yLXn/5lqfUX/3PQ/H3CXKelNmNr+NPy/BJCFmmj2S5iECHQv9YaQUuzoF+R1qBJim0HQdc16V5a/L6VT7ngC+tgK39NFLTlVaQgRxg7UPb3ZwDfJ2blCVZjUqnFQSggXwO4mYgJCyRA2FSOgfGmEDpwyHt80x2ssOBw5QfXb9bbzbwrkecAyKtgF/X6RxIGGxdhIR5yAH6GPso3/ig0MnoZ5an2uTiDqUJCQPSCiAuR4I2rpnha8HK2OaNHHpEDYqUynMhBzC+Z86bqt7z4pOiv8+ZPy2KNLz8nKOi11MY67Kz/Q5max0hsxT95LPkayFR+7VJNQWe/+2q6FBUoKyydH6vkNIUwYwxd4EcgBe+Xs6BZB5gbfD1wMsZegkJc5QIw9o+ZDu3ksgEDGSMIzeKuXOgaD62LBumakQOhFahoLJiELlXSGImF8wbii5XEDmsPg85kJXvjz2DxgAGBrgGMI4gxITACKiWc6CtJuTAgJPwrNpShjbZk92u2PEb/+0yCrDu0Id51QpcXBshgnX+lded66w8EmLYfPq3jwvOAROR48LHBvfllSA4yZ/uh+RaxFqeZ1wREZyPT+g05vxFdSDeh3ZaQXpvksLRekUICbkRT3sGpZn9YskGtXr7fuuexplukAOkV2jDn63X0GoFWaUM5TPxYARHvd24bIv6+OJ2tXTj3uj1129fZQUc3JwDFX02VwojB9LOfo7SlMKdTXTGaF1DEFryUoZ0/ko9CboY9SG/ZjXcO3kotCGBQqtW8IxYPnD8+fZTWTY4Czkg01hkgAdnZ+yQGXQa9XLv4ugAea67qnr59HNe6pe3lc9zs+c7kAOMkLB3oH5pBU1BSFhyDgRJWa1gjCMHfJ7JzsS6ogOQlBBs9P9y/ePqW3eviSIW2pvdVTytYFpimK7ZHpPVmdrODDkgNkarooHgJchT6CpMmbI8hxU/03t2tYJ85AD32GtvviPKgEOHFFNi2P/e/c+oK06fq/7i2Qss1l+faM4BptD0sSg0qjlT/XqKNPz84Q3x8yVM9tQ2lyPEpEU4kAPtjmoFBbR0zB2dVlCQkNAnOLB5uTK6mqtlR0+fEP+RtP+hZ3apk+dO9sKYq5UU2RtbD7QeCaJLh7uLsMxZOcSbVuBOi9EOMKQVaDIvg/7gxrlk0uZC0Vakt0gIb63IgZAqFM8+foZqq2zy1nI2kULlNtaYU4srf7w8WV40lNpOl6BpI+cI9gHaB2VddDyzrElfFXJgXJXIARFl9yEHQgkJU9UK2rOQA205hIQ2rBXOAn9U3t5/QgWOU1of5x87oyrDhtaIcuxdPl4EPt/GBVYryMoM48aVjy3+Hf/7UAQXB7KGJEIPJHu+nVbgRgxaz8KdAwGpd1ywp139n/emnGMbEn4YQ4A7qDkNKIrZ5UQOFKtW4DtTeHSVO0tgjJP+884fPuKsNkD7FDlm+JgjnQD7wrOPn6VuWb4lt1KUq+rJIZZWYByNaX4iblS6kAPc6TIYUPeTUu0oFUr2UREpikKrVuS4dnPOAdYvpKMSCazL8MffmDswkq20gn6T9gi9x0IOeAJZMq3AhRDJ0pP1XiCqAJ3FUkLRBtkfrtRbi3OA6af8GrUQEjYDcsBF2lhKWkrnwFhPK/AcFnTg+MqK4WA879hpLK1AIAeSTY32Knm40HU/9PPH4mvt7YnI6nDAhSAH6DCWEaginmpeis7lXQ2pVkC/I4UHiib3WEPsQxmQ+bRjgg8BDiTa/ENL5nV3pp0DWtlriw0ZJ9Stjcie2qNyPS5HiKmNHiuvtKnyMcB1dbWCAkr6/sN90bUMNNgo+bUhB9qsMXzNefPU3at2WHODDNxdB6lSQVsUAdqeREw+/PPH1L//fqWOQtQLcpZibefIAbYe4ahLExJmIwekgZFyDog57nNChBjn5LQypQzDnQPkPOTKvS8yDQQNd0iS0Dyl5zph9iSlmG0hnw3LGOgAV5463sJeRf3A4ah5yAEQD1J7UuzTVlqBTWDmczogPau9Ws6BAF1O8k7kcQ6EIgdS1QoyojI8FSmLkBDzFmeTZLWHyP0nVIwS3F4Xg4XWnYtTJmpjW/q+NudAckb0xxF1uve2fXYqQ5agrYCa+8YGzoH4/rFzQOZUR59l7HnakU6EhP3hhIT4DYl0DJDc8eR2i8dhzY6D6uF1u+PrM+QAOSPpjKD1J/cwE5zwBxScz8T2D5tzoF8EHCregAM58WUfwWFwzIyJzv2MkB3HzuhW963ekWrfRAdyQDoauVB/QBfh5Hg0lvQ39ILHN+8N2mOoL3haRTUGVFEUWrUi2+ZDDhw5bbzat2W/3u84ckA6DHycA7IMM4+8+9JzjdPNdtRkEUBzofvKAJ0sscrb3BaMHGizkA/8GoWRA03MOVCWMvRL2TNjTDT5WrIhgCFdGsK0gPKglY9tiKMSk8aPY5wDNnJAbt5wOEglAYbRI+t3m2igp1oBfYxFje9U66l2RW5CCAmlYuTkHNBpBQaSZuUnOiClmogpEK5ppRX0OmCXHQY+ptm/WWoAFBHXs3IlFlGVzGoFyR8E0c47Iq57eKN6/hfuUE/vSyvYtXifDXJgQNe7J7jwq8+bF71+0amz1Uf/6PTo75Xb9jtTUFCTuW7OAXEA8X7VaQWk2AmoLEQq4BJ+KLkfTFpBPLYSiSOjbiElIjG/CX0CKZJW8NwTj7BeZykgqEJx+Snxb/70gqPVK5JUGEkgJJ9NOuFSjPms0okx1sjYZ2kFAWsP/SGvr1nT+5hzQCAHpNSKHAhB2nQME3JAOph4f6TnvXH8uhyJ2J8AEUdeOUcrucsEqkKinUKe8ShqsGRxDvBXOBtdaQXv/9lSXQL0k4yAME+y2sp5I7hzQEfoHWiFbOSASiMHAtYKfX9fUmrOJ++/bqm65pa47OmSdbvVZ5K0jUN9/dqpRlMGc0TvlR3ZhITYD3xLhCNq7EpM/cEBh42sMo7kT0DK4J3/+AJtuH3t9edF+9vCIybq3/G5bZADpnqOjwzRxQmFc5TaRs7vpYme9rXfr1L/dVdcQShPeNComvM4L0Usj2Q5VGTbJlmcA8w5MHWC4BfwIwdcqFqabzJFxXbsy7QC27Fp5kUG54Cjnym1yJUqK7lQejKRA/Fn5FhzIQfwnHn7YiumFZScA34pnQNjPa1g0B35fnLLvtyDEZsJRcYMrM9GJHBlI6RU2o8fWKcPUYkc4Iq/hORX66l2eVcPCuPKJ9yIyE4r4LBTvjGplKJs8r7Cl6aONHDOAQZhNR5u28Cn9ycmh2lW+/EMPlJIXa0geY6Xnx0bcnlCB9yN6xMnT8Q5ULv3GYokz+OOqnRQxDkygjpT6SpcCtoZQSIPTG5Q8fXoM9rp+7xLpNGFy2NsJGeGKakZpgSkS0Reot52WVyWj0c1JXLg6gvnp0qGYQo958RZ1vt5pEc0ZsfO7I7+njWpy4vmSCMH3JBaCH1dVisAgka3LWDtoW9le3i1Aij04DPwOR3g1CuiqHDnCueB8Ylmmh+sL3JAjqPFBO1CDnjaEYYcqDjvVTitIKfMbahho9sdVSvIdmBE93U4/3YnhLySdDBPQowrPoa8tK2EE0d/D4ZwDpjrYX8NcaSRkZ2H7qDnJwSblNXbD6rbnzDkjzD+JcpqvLeUYVhaQVTKjyMHDvcHBxw4caDkHNBzmEo7J5e/7KRZMSGclV7CAg2CQ2g/Sy+QZRQhLoj7/Q7nhqwc4JOJ7D7VGHxAoZHIX4eQLIdKOq3LjRw4alq8Xt3IgcRhIDgHOHkm5xyAfsK5HOR+plF6AvVkVSuQaQWO/YiqeYXsbjqtwNIvjYOKhDeRcw5E7WdOpdZPKzB/l5wDfimdA2NMzCGSRPiTQ1YeOqGl4EjW7TyoFUGNHBC5VqGl0gju/UxCVpdCDrDIsjask/eq9VS7cmCR65eVViCj7d1OQj8TsXc6B4RxXS1yAGPHD37uAJCVJpCfTbc3DPcDqf7myqDO/2Xw03S1gvi7Z82fFkWfZ7Mos0v43QYYbK+W80UTbiaHJfpbE1b1D6gnt8REWHny5OYE1lCjpAzaHEJCabQQbJQf2KlqBRWBHEiMdsxfmZevSyZmKAGSERtIAspH9TkHCFXAp9C/vOoMbXTOnWI75bJqzbui8L7osVSADGmUz5HC0wqSSG5Hm7XWQ9Ye2ibbY+qt9xsocJInLEtSQmDQhHJtEPrqL7/7gH79rh89kls73EW8ytcJPTOfDzy6XQg54IiKm9e8ckZa5YUhpasVDAxFhr+PcZ6TmRYRzoRfD8OGmu1ro+UcEJwDUcndnfFZlyXVGlfc+ER1IHkuQXSZxYC0AhLM7ZC1UmteOSd/xJ6TIiTUyAHb8atT1XzOAbZ3cmcJ5aeHBhy4Y81Azu15fjBJHQJRLG+7bB93MJIA4k/X9BluPADAn6MaoXsg0s6fqaj4UGghJMvVIweMHgauJauMb39cdYCTW9J7pHvgXKQxoz7kDgQrNTS5Z1dGtQLDhWU73bgDYIJEBDr6ORQVZaoV+Pd8jgYhbgxeapsjKYpWK+hi7M/NhhxohvaOlpTOgbHqHEAUWefM24d8nmHH5VPXr1A/enCdk/GdL75QJeFAYpx7OQcYAzuHSVXjqYbtYHEO9AWmFTBl30nox6IHLuXRVae7KuRAMnacYZkz3/NDgD/rF256Uq3ZHiunD63dlTIwLKIjkVYQIwdUihQSCjEd/Lf+f88PaH1Fk0C6yj0WlVQkM+ljKI9EdLVbEML5JPR7eSKhunxNmPU4YKWCSOFKuLyecdK4OTPMPDQKUnTvQOg43w/4GoaiDsjy8oTNG3L09Ik6Kn7UNKNsBkfnGckYd0pxkXNbRgpT1Qo44mXIOBAmFEYO2CkbMhp0qHdQK/U6rcCjdGG/C4li+NKy8mqH+0oI8v2Gcy2EIwfS6WhZ856T2knB/EQ/cYh0/Hs3v0ERW4gUfBjCWfM/xLDhhqWXc4C9lNVKyFkOpvAs4VF/2YYssTgHkupAfD/gUOgiaQUWOinAOVBrXjkFFHTwIdEv0oSESVqjcFjiTMlLK4gIGtlco+ufPX9qUMABqLT4enE7tH6S9CtIjqm9MBB9jjSJBDROxg5vSUGOHHgmwOGUJSfNmWTtBbUYUC4UGqqC1EN8nAO0D/75tffr93/y0Hr9Ny8bjHXJjWO8x9dHRFg5UKRagRv1xNsbUsowVFyEhFJHtvdS0gsruj/48xfRC5oROWCjd0sT2CclIeEYEx6pjP73IAfOX5DPXO4i1Vq5dZ+X/ThUSZiWeOIl/Jsbj66SWFDoPvar5RabNClT5BhwHUhQOIcY6Z5OKyjAOeAmJHQgBxz5TjzyVRtywJ1WAA86DqxNew45WdM5AzP1lYvZmhPayFJihvwpadf4jugAyqrVCyEFaPX2A6k+KiryYMNhxQmrZLlIn8yaZCvldatW4EgrIKXXR0hoHFF9mdFJk1YA51Ye50D4HMPa3cpyHTFX50wZH5XBWiacA5SCAKWDG1lxmkT+GPOygLJeNETCdw36xIb3utIKIOSMKYocQPQvBWtN3t99qFc7YLE+5XUp4khrEFHFPORAtRVZeDt9aQU0D6m/Ae2unnPAH5WJU3zMs3hLGQI5MGhHtKiayPNOOkI/W1sGcoCze8+c2KH3KA4VzqtK4asCoO9PzzKQRBoZj0t+KcO2Qs7yD191qpo7dYKzDcHOgaSUIV9D3KDpK5hWUAQ5QO0NPQd8QvOxb4CqutjIAUNIWFu1Ato3ZPSX9jcQtJoVlg44QPfhcx7Dg2pMM7pjnYbvM3ztuDgHsI8DxckrqkgxhqpNJpinZ3EHOPYjcuTy9V+rweciy6yXSF2Bglw+Im3Ibx7dlOIckPNGOgfwHp9L2mEVoTU8aQVFqhXUAHF3cQ7ISlx87485B4wDi6fYFXVS8H2mGQgJQUpM3eEqH1lKLKVzYIwJh0JxBUE6B0hBy2Mud8lDa3d7laWQUmkzuzvVyXPiMjo+qFZMhmegmVKhe9bxs9TZH78pev2dN1+onnOiUSil8M2MnA9kSodUKwjhHOC5nS5CQledbsMYW5xzYD9TUjjsEnckxZj666mtbli9y8CQzNYc3m0isIja2oYZydTx43Q1gCwhBetHD8ToE07wVFRkdBbKGlce56GEYY6cMz+uxlGrdASkFfCUEKdzgD2XhB9K7gqdViCg7ynkQIE5NjthR96+vyeaQzQ3kP87d0qXWrGJKo/Yxs66XSaCNWX8uGiPIaMidG5r50DfgHZw+Yxek1cp0gocOeByKyCCNp6rGgKr1Ckb4mJoM0+/0NUKxHOT84mUcRiseQZftRVZ+LVluVHOUM0jWaFzg5QrlHVMR67S814SyXLBmYG1Sk7My79wm/78Ld9+IDo/4Oj1cQ642L2ndbarcQu2qMtOnmOeMUAJzjJs+P7n5xxQXs6BUGc5OQaqMa7488lqBam0Am0chCEH4BgMQQ5QHy6c1R2czuUSWju0R+K+pi+T/d1R7rBotQIZ/SUjm+bZV64+W33gp0vUPuZL5wGHXyyJSwPDkKb597Xfr4xeP7B2V0Q0SXoNSTfbZ1wlLUmwF+FM4MgBn3DkQJ7TC0LEiDev2KK+fc8adcnCGerFp89Rn/j1ijgVsUlI5lzVYj5w3dJMffWzNzxuOQMoxVYiB6I0v4QQFQJUiill2K7XjnQkpIIpDrSIJOXlZLt8Tw3Rv+E047a55NNCWqGrWkE1iFV+H/oHvaAZhNo5ONA87R0NKTEVY72UYbJhyMg3bRw+aGWWkCJPyqkrrSAL+g9586UL9MEkFUh+0POySlIAxyPF4bks0uQS1CXm9wslW+Kfdzs4BzgrNPQOu1qBfV9+ABVDDiSRBlcpQ0or6DCHQARlFQehz8CQz8Db6uIc4GkFkDlT89JT0uNHpQez8qezxFWez4KoR+WwzOdyZvDXodHTPEmXdEsjBwAtj95z3JcrEtKzL500kpBQQlyhWHM281A0Dw3xzcs3R2MNRZyMF5cA3kpzkJ4TubmhhifGjNajr/oJV4DISEynFaSRJDISFlcr4KUM89feeF+1guR9EDcSSkXzXog1PZNBvfmzDEftcBfxqnQU8faFQktRRs011+kzHpmhvpJEsk5CwqQdKzbtS7Fy8/QJoE/4IyFqKJ0ou3tVVK/+hsc26/dqjRpx524I5wD2dvQROcvzlPFaGN35WBAqC23UezozFmTJNZe4ooLjO8PmCaGLfEK515WcPgBLv0YOJIYb9ugJSTt81Qp8S4tzlsi1sfdw7A244vQ56s0nDWiHnoTG8z1g2cY90fyT5IpELIf7uM4Xvq8Z5EB8jX1JO1xlDOW16IyXZe5cQvPukuNnqtOPmqL3M+gonMSY91EjimwbITXyeK1oT8lHDgzoil4QzC0MN4fl+wgJ5bllVStwVAiDwBEUekS70grSnAOmjXQrQ1Q8WHWlAgjOgEaeK1x8aYelGCmdA2OccwAeT+kcQN4zzxnrClSmSDn1KRs+hwMUD4r6+yCw2KtpYUtCQi6A4VG0Mg++bCEHBiWhWzawhhsU7lKAlVROmuUcEEZd7cgBxjnAqxUwZbCogSGZrflzSM4BDAV/xhndeYqKe3wo8pfHwF6k7jqiwWTQYl5dstAQ7UHoNa5Rrxq48jp8TeBefOxcBzRHDuSR8slSnOPE54eTzylqTZDXvH4mg+v5nzcR3Hf87+KIn2Ln/h4n2SDSNtbvPGTtLVDwg5EDnHMAsOcUcsA4Erm92Z5ZrcC+T1S1g3MOBCAHJiTPsGN/j9WHaDOcA1yhdyEHuORBMmupHe5KYZL7jeUcKLD/WGSZnvFBGzAegwGcAy4ZYvtDJXnFOU/81XDi+37hpid0m0NSW7LE8CdQmTMVzDnAFemT55h8dZdUy+hOa/Y/73hav/7b78drlt7X5xJPK9CcHv6+d7UjxIlN48Ir6Zjfxve66szYyK5k9AFKjcIhKQkJ4Tz1VSvwjbXlHBBIRes8HazotUUoDjtv2fz9s8UbMqO8Ow7EyKu47e5rdEvkANIKApADNMf40vL16alHTo7uib2ZUpugE9Ia5oSkjVwLXs7J0GoMXLekdB/pVIrSCkQQRaYIoM95tQJMM5e+JNsrUTd8PsCRTpf59z87TyNPIPI1xo53h6nEkeY/iBy3aH//kE55yioxnCVGZ2oOY1uXlqxTAKgVpeyZMSY8Ny3Ks0s2DHnw8GgQoJVHzzB1ebOEDlBfDiZ3OFy0YLpGC8DbHaECPMzanC1Wkq24PP5TRHkul/D24Vrw2BfjHHA5B4xR7sp9lEYdyeEqkAP6gGcHI7gkYoigcVIUNTAkszWgaRHngIb1+qM005Nc19ecN8+CtuYJRy8UEXm4yagtJ7dbMGtiNA+fm5TZe92F86PXFQeqpBZJQ+HTyAEogPRV15rhUFEOP4x/A4Mrfq3TYpLf8Lz8CHL96+XR6ye27Isgr1lM975ILEVwtyQG8FyBDjlj3lQLOdCdKLtYj6GGpyb3I7LKAOQAj0Z7CQlZGVQIzfGJbP/LU5CoT65PItArNtt9CIVva5JiwaHAtBb52FKJRtezDEftcIkegaBqTYwcYPOygNLEuSskwRN3zuSVMkTbtoj0FB+6CZwpSCsISbtAuke1ETIuGK5eBj+WhhQp4ZhucA5wyLYPdUNy7vxpVRG3Yc3KikNAXcDotZAD2Ncz9jzk6nLJSyugttDaWPzMbnOd5H8Y+rRf+BCKV54xN+oD49wdcFZc0YSzCRs9xKS6udvHEYiutALI4YGMc55dPI/Els5RnGtWrjZHDgAJ2DsQnak6rSATOWDOeOyV1HeyT6dM6LAIYuFAPtjXb0gpO2zkQCOTzMk9c15SsrCIRIR8Ih0l5gByIyyxh3H+LugUnC+F60s4s7kDIIuQkAJbkBefNkd96U/P0a+/+rpzrddoL29bdD2hX0qdnBNm51VwyRPM5UaeK1x08KBJ2jsaUjoHxpjwA4kOUmwcVgkYj4FyRgJByxLa/Eg5NWkF7ilG14ezgSKPhjk8JsEj8UG18pADe5MDGvXFs4Q/56An8uoT/rkLZYDNl5fN4ZuRi0G8GuQAFBYencFBwKsV0CEGcigVaGDwAyT+3zhoZLUFTRjJDig4BOZMHa8+tOhUnaMeItWUwJJKf6qUIUMOIFcOHARHTpugc+fqSa6TYthnbQS036TCuMedO4t8tdR5WUo+P/F9graSceAjopQOgjwCPMgRwsg9O+Fq2JKMH+Yn1iMpMiGIBVMWkBw6du6m7Au6Fo+KG86BtlznAEXJ4Egh4Uayz/CSESr04ZNbYkJWVGmQJGJ8Xc/sLuYcqLYiC5+DWcgBrqwWSanJQg5Y8OSIc8Dt+OV7TFbak912G7FUZL+oNkLGBf3MjQiXQxHzTZYy5NfgcurcydH/odwoRdfspoTThZe8M+dF9rjz9vJa6UUci7JtVGoVAYOLF8YBA4iGvQtOAVlxha9ZDhmX5ed8z0PoD6lvcOQAlrvrnC/qRNaovLbstAISimgbQsIs5EC77hesrRPnTI769I/Pmxe9ftGps9Xfv/DE6G+c3d1AKfQYdBad+b6Uh0YTOa7EL5XlQCWRQQrSz2RaAa8e5HUOOEoZ4pw2yIEha47w9sL57epnOHFcju/T501NpWVp5IAD0YLvSgc7T0WpRu+ERKi95NqU1lEN4nOkBf3ULGkQoyGlc2CMCTeeOLs9TyuISOwchtGCWdkQSBKqj0sLri8gh5HXMeeGpYFDDURGBBH+0P+AQdKelpW7WgQ5wPcGbOShhIRcwXQTEhqon76fY/Pmj1AVcgClj3rdaQVQoOj56J5zPOgBl4GRQg4w4i1eyiv+334ujhzYeaBP510ef0T+PKq2BJY83Ewpw2QsHFFoUw4v7QCph8Tl85STUNCkFSQRXI+ybRlgHl4FrAWZFoNo7oZdhzKNBpnKkReJhWxL0gsgZybIAcxragcZCnev3BG93rT3cC5iIf4dd+i4kUgcFcHXkR85kGYuJyXdSivwGI4hhtfPHjbkZC6Fnq/rWZNFWkHAfKu2drgvYu/lHKgyrcBHGBlUyjDZY6TTxCdwfuFaRfaLapRgKTgjeQUElyGFdzhsG+KKtCHXuRrOkxD0BFBlOKOjvx0cQS7hayfrjMpO8bAF+yHNnXOOsZ0DuAcimrJaAfqIt4UbeuFpBWlUzT7mHOgZDEMOhAjmqZ1WYMaaHCFoLhH1wjkwqWuct6/3JzrP45v3msoTifP7uOS8jY3ipK+TG2DfI91Bz09BSNjIBpSs/kTPk8drBWcJ3wMPy1KGrHpQ6p5Cb6D1hD5HCcggzoFUWkFbKq1AGu9R2/pNCghvLwkfKkn+KvUartvhHCjqNAUyCKTT37xzde653ggidb9S0lJWKxhjwo0PHv3iyAEfURnBsEkWzpqoVm8/mMqBIuMPRhjgVFkHC3cOcA8/NrWntx+MjAgIIo/xd/zw1L2H8j3tEFIaEC0mI5fnj01M8hyrRg6g1A3b2F2cAzDqyDjVebeFkAMmH5OuQZs+L4uH81PyS5CyQCXosko+WhUXIhK6eM4s3bBHjU/miXYOOAgJUcJp14FetS0Zj5PnTlZPbz+QWbWiWiIuL3KAERJqRRgMwm3mkOdIlHpGTOheulyQg3NAIwc8486VX1mtAC8HPc4tg/4YKsR0HxqJpTmBkpf0P6/7jc9dpaVk6Uw/IWG/pWTx2hc6Es3KhVoKkCOtQNoJNB583lA5Vle5uBDDa9dBG5UhGcb5upZpBXmlDENL7LnEF7H3VSsoojT54NHyOrTOdDuEU5eg4Bjj047MRqhVkr3qiISzAftPXjWcSrLn0TlVj7QCGCY8N9k1hvF7Q8Glv7YnqQ/VGGVF0BMWciDQIUHj1xPgHAh1LMrnPEakLmK9wGhJcQ4kKXNI2eFEqUFpBQw5MJCRVtCThRywnOHj1O6Dfd5zjdYYzjU+D6TDiL5H+hm14eltMRpp18HeFCO8rMxBxhnWMb6HPkQqKf+Mcw7otIIooGA79RpVOGqDuG5In4MDVVYswRklzyfaA0EWar3nQTC1p5ADJuAANIAkcDYGeVZaAUMOMMRZVGqQrdVYz5P7eLocbqpagaicwFNRqqlW4CsZmXeuN4KUyIF8KZ0DY0zALk2bzQEfcsCzQRw7szv6f82Og9r4/uQrzlCzp4yPFtmf/se9+mDWBGIZygaMayJIM15NpR5Ys8OpyIIBmGqt+0pz2WkF+ciB+J6xUkFt4A6TvLQCzmrujijYeZLxe9w5oKzn5IdRMc4B892DfQNqcoTcMIYoDgxSDmIlPP7sa687N8ohyTIwkCtHyI13/WiJhkv/fz9+JFKESDAEuloBV5YSCN/Og726P4m52lc/ulYiLun5RlvQn9xLrr3HiYLJnTPyOWoVbtTyNQFnHdaiD2mDiIT8PW8nmp6uVlCpyrgIjcR++ZanrEjJm679g/U5MaX7ou2ydCaX8cx5yHOibedAoviKtALoSC7yRnmf3Qd71Tv+9yH9+sO/WKb+/bZVKUdZNWku0jlgIQcEIWERJRw8MKHii9ibiFGbxWtRL+SABUMntBFz5nDhzeoe79/7OLrppmVbor8x7Ei7iPcV92x7wyXHqmt+91RdkAN4lp485IB4y8rndgw5zrlqqikUQU8UrVYg98Ss9Jsia4Wv0fnThXMgmZO4F85SOHh5sIOMLUoFsJEDoWkFdmlHkv09xtHXM5AY0w6dgI/nG591rPrK7+Iyhi655Dhzxmall5ATgnSRP/mPe9T2/fGOR6V+73hym96XfMYZkGMrk5LFPK0Q/YE5qSsj9BkYPc0BHuFu5Dxy7lzjOqzLgfrp365Qj67fk+LiiAkJRSQ+CiK4nQO4pYHlU1BpyOYcSF6bdYVABHMOiEof/DPOL0G6HE+1IkeGbBs+5wgZjkyN+MVEwM4gJoeMkziQcyAPRZd1rjeClJwD+VJiKsagyGilNDB90OaFiXMAytjxR3Srl519VKSk4pAxsL9kU8xYfFz5N0Z+RV1715rM9lO5IGyCtRISkmh4/OCQjrrShpanKPHNvTsjomClFTg2bxzY/HtFlFcaL2xyNKacuZ0+40oIjQv6rHNcezR2rzhnXoqBWSpuX/7dU6lIEKKkxNjOn4Mf2DOStIIIOZBExI6Y3KXrR09zcBSChKoakUYN+oUrspj3hpjH5N5x46meBwfvW3daQX+mUWYhB6TBK7gf4ODCmswiGcsyLvII8CAyWo5xhvgiMBKx4HUeMnKoFGydcw4MpvtEEuTR2zK6u3TDXq2AZ/EwVJPmUk/OgVrEjxwwESMeySpCSGiV2fSMj6lw4kYOcGUXc33axHG6hKYrfcKUMjTXQtSQw3Kja3WqaL85e36c8lIP5IBGZGnF3G1IyfnG12+W4VXNfAghrdSRZKtagR1VDGlTFhlhkbXC16gPOcAJB0kQSeVnG/Z4GMc2csDjHNB7p733p5ADSVdNdFQM4H1CFXBo/s2ebK9t7MWnMd6m7Lz+uC2+fen6Rzfmpm38bsWW6JkM/H1QrzuZVhClJiRnEDkGeICokQ0o3jZZcQsOVOg3COYgeAShfkmXMjRnjq88Muami5AQawvvu9jxZQCIO2S6Ozv0PkHGO98fqW2ptAJdyjDdTs1b4Emn5ISMoft+CIquWlLpkRAXkqMUW0rnwBgUmedMm4VlfCSRVCn3Pb3DUjqWrNuj84vk4c1z031i6vkazoFlG/bo3HSfHOobVM/sPJCBHEApwzBgDE9R0JUKxsUQtSzhfeZCGZi0ggF3WoFQ2HFA0QZdxFtP7cTBSDmKPAIS1yzmh4SBpIUc+iEK6obdhyxCOP6TaXAOHOyznAOoH/3R8wbUaUdO1vWuQaRUrUinCpRCjvLYn4xx+pC0iX/qaaxZiiD7G+9DEfXBem3SN/czDqY4B4AciL9Pj5NlNMhUjiwCvCwJyTMOiTRy4wOKq6zUwMs1DQZXK8hvj4uHIcTwwtyGSIZxRELp2cBKrts2jEq4qzJK3GfKXa2go05pBYJ0TRMjpsrUDqXGneb5/3fFSdHfZ86bkqovr5FXwtFAn/9D8juSz7zq9Gifof2GIyXqR0iYvZ/Kt62IccYZU00JuRDSSpD82dUKTNQ48/qsvVnIulDHouw3YtHn/aU5BzpEtQJHXXaTesCcA4M5nAPMuSijsZxzAIBCF3KAt5/6n+bfLe95nn7vO2++UJdr5GkJXDfia5/aQqkJLsGIfegXj+WmbRAChYwzXnJPpv7x9kBvIv2PpxU0YuTX1W/SOSAFUXEgc4Dqov4+KEptcueA3Kdl5J2nomK+8vKqfI7wnly1db8djOApB53tev1HaQUW50C6kgIn69bXE3NK8vZge9mw62DEVVGEc6BoSexGEzy7DB6UYqTsmTEo8A5iQ6RNiStLLgOFHAB/8z1/fhE5DvjBnFXK0FXHHJskwc9DBMZUrYSEUkEIrVQgvazk1JCRB01IyHIgLc+uNuri17UwxkJpoag4jwjR2FrIgX7jQQ459KVHPas8kyutAMzAlC+Jg4IbUPRVIFLI6VNrlQAf5wC1SUP49bxvS/MqMIW5fbiQAxmcA53VVCtIfiKrFeA3UBJ8aTaVjFQOHwGejOjWKq5Io8s54CO8G5ClDD2RgZhzIGxcZfQjxPB6z4uNUeoqEYu1TU4DqYgNZ4RO5p+mkUo250C1aQXSoE0hBxztkK9NCtBglAsNh6FEN0ERdhwBVnlBQrjhZ3jmenIOELM5b08+csDtTDlKrLFq50MeaeX8JDrPDQyQE+Y5JCy29QxDImStuK5J40KkxnJuYbwe27gnSnFDCU4XcsDFOeDzeWAMeWS1Fs4BzHdKucT7pxw5RcPWfegcPta03+TxwxDBb4jQmYvzJk4rSOdco48RUSeHXrNUK7Cg+I7UTi7ob1f1BzgMuN4Dp1+3GPPsagXGoKe+psAJyabdh9X1j25Sr/za3Vb6Gifv431O+hzmUiqtgFIePGg8P3LAIGOoz+ien7n+8ej18k371LV3x2jdHQds1J9PipbEbjQp0wrypXQOjEHRBkliRNBhwBVVaaCEsHR/5danrDrDJpqSzznA65iHbibIZXexXmvnQCjnAINly6irT6LN9bfx5krypm89kGJpNaUMjaOEGybYl+DNhyHOc39DRSMHevutg4PGlm+ABCHT5G4BkCpZ+ixLCeG5vxCCBqNvAT+Xpe9AWgiphUA2Va2AtQWRAyh9+KzTigAw8sg6lTIk4WPAlYAuuRa9zgG/sibTCgwhYYc1zuQMIeNAOr7ymO5RZuzDV52qjZi/et5xwc9OEZoiiAUIKbDoHyh0Lg4Bkn4PciWFsmgr7vTh0Y88w2uR6EOJHIDhS04DmbMdSkhYjcgUJhKucMpqBUXy3bmhLbd7iZLxERJycjxeDkzXeHdEBTXXhuMM4E5NrC3LOVAHlmoMl+Qw8X0vL62AQ86j69XQRqxZQltcc/U5FupCRyQFiiS+ZyXcOZBzRmatFXuN2vecP2OCNRfoTP3xg+ui179bsTUiKb531c5UX3LS2dC0Al7ik1dvkKUMs6sVcA6JJEJcqWjjk4xuBGL4731OonpGW0mfMoSExkDkUwu6w+5Dvc6AQrMgB1yOGzdyoC/lHJDlffnYyzHHLbXThekNeu8inXlxu7r1ie3R6/9bvF79zfcXq60i5Y6nr9nlLCmtoM1LSOirpFDJRA4YZCHdc7d4ZpIH1uwKqjQQgqKrllR6JKRMK8iXkpBwDIqMVkbIgQxIaUh+0Za98aZHZzFtXDiEspRMzTnA0grOO3ZaxEK9TeTacSHD/YSkPM9AVloBqxUbCrk1yIGOmllaTSnDhMdAKCg6rUBwDlSDHJjoSCvgpcNAQskN4BCvaVZeqVRCTDlKe4zJCw4Fnfoa5Q2lo6ce8Oos5wC1hYxMk1sJeCA89Cb67Msfrlb4IcSVyVS1Ah8hoYUckAavQaCQY06nxoBzQM/vwWhe3rhss/rZwxvVy88+Sr3uomNyme5J6PNLEgI86qepgY43kpeeMVf99KH1kcIwFIhYgJAjg9aFhGe6yjXBr2NF8qpMK+AiHZZZ1QJ4CpGrYkoniwYtXrvL+mw4qyqZ9Is0cgAlz7ixVy/kAOfX4MgBSUioUUcVc2+aZ5nOAThXHXoyZx/n3Dq8OkO9+hSlAX1zWO4jvrSC046aqm5ZsVW/rjWq5SOtNLnMrFqBIE7zCTeykQaWJb618uzP/E7rDLLfjp5unAM/f3hDRMQnhxjGEiH2KKecRKc2FihlyJEsA4CRdyaVAnqqQA6w+U/BCUoPIGPUpVfwx6a94DknHhFdKzRAQqg84vLxue+Jd4P6+rYntmonFp0P8b25IdquKEsTBnKcitgczgEbOZDjHEjW/L7EOUC6DSoYSB4CjhqRY66DCkAORHqVTUhIsjsABMvJ+665+lyRVpCcFQNp5IDkHJBtk39HyLpkMezY758zKpBIkJO/VnOuj7b4qhmVYqREDoxBSTOkE3KAGSxCQSjqySbPfUiteFOqbMAi0Pt/L7ShuVIuXDBDE+a4nAPY/ItUK8C1DgnDSkoIigJ5yjAIAXNsz4n4ItqVxQLtE0DqyDCUNaBt6DwpQWEQUpSozBPaYEkJMQp+xWv8E0O7VJaRelCPiL1U+vm10K+Y9yatIDFGMozQWoX3tZVWgOhAjnJupf04DF4SajsZP1gSplqBiUCQQJE5Z/40LxGlS7CeaH0dJ8pBZcmFC6ZnRtuzyCelc8rHht9vOXaYsu5IKwiN0GdFPyTZFUehtHsUVnIq3rUyjiSt23lIve6b94trDt9xbFKY0sgBKLm8IkaRyLqFHKhkOcUM50CKkJCV2dKlNwk5gPxgB3+Mj9yQhLOPk8MU4spVr1Z0FRhdorStcFoB7y9ZwnG4oloarswcNDgz8vY93qbQijqutcLLePK9kdbIDY/FVShIfuhwDHD5yUPr9Z5t0hQdaQWe4eYcGNiD4by20woqXuQA38/52kdwgiDrcNgi/Y+ek1dI4chD2m+ydADsS1QpCq9d8vJzjkqIlWHEmj1SOgdIjHOASru6HR6NJvw5XGOTlVZAuoJOqUh0RpdDUeqCPOBCQl2q+aKsfaVY+tqTW/ZZz6KRA4M2coDSVH2VFPjyRZluiRzISllRBYgE81B0jVrGkM+bknPAL6PaM5/+9KfVhRdeqCZPnqxmz56tXvnKV6onnnjC+s7hw4fV3/7t36qZM2eqSZMmqT/+4z9WW7aYw4PkmWeeUVdddZWaOHFidJ33vve9qr/fziG67bbb1Hnnnae6urrUCSecoL797W+n2vO1r31NLViwQI0fP15dfPHF6g9/sEtytYpgA0M+Z+wc8Ne4Lpo3xDevLGgkNl3uoaeD6PJTZ2cawAtndXvZt3n+WDDngDYwBlNM77WwtPrI0+RrePNriWpBMbp75Xb1wJqdKUWOM9OGOG707wLaMnNSZ3Qt6OhSGebGvyRsiz5PUg8gtXibpdLPhwA5slD6MIe4gS7L/dRLXHmprvb6jBaeaiLXFIeMczg1kWpG3xd53tUaSHAOkPINZZdE9pR8TZGXLJhzlkjngFxT3JjRzNAWtFL2lRsR4nuGotEPUsh4m4EcANqIGy5SRgQ5wNJmZG1r7oBasm63c291CfYrGgsZoZURSOkQhRiHZUXPb/oKDBbJ3UCCYcH+yQWpNSS8ZG89CQlNidhsfh3+Nv1tfY/9iTx6yHBFtXT5T44cCK1WYCEHqkdfWM6BZD/EGuH6QJ5QqhoMGVnukEQS8GUhB7A/otKFRUg4GIYc4H9P7hpn0goYlxGe01eJ4Oblm6MAiEv4vrToLLdxhrl97vxp0f+ckBBDbjsH4mfC3tRUyAF2lnYHphXAOUD9gr6RaQX4ToSokg5qwTnA9xsqi1ut8DZMGNdhcSH15RASQuQ8tzk1/GePlNCAYLXn+mgKnT3YI9bvOhh8zo01GVXnwO233x4Z/vfdd5+6+eabVV9fn3rJS16iDhyImehJ3v3ud6tf/epX6ic/+Un0/Y0bN6pXv/rV+vOBgYHIMdDb26vuuece9Z3vfCcy/D/ykY/o76xevTr6zgte8AK1ZMkS9a53vUv95V/+pbrxxhv1d370ox+p97znPeqjH/2oWrx4sTr77LPVFVdcobZuNTC/1uMcMGkF3FPNy9gUyS/qSrzNnGAwpJQhVwZIb3EpRRR9fP3Fx+aWxCJFERAxCen1CTeuwDngU3yKsLSmo5b2d0y1AlUTcoBHJH/84Hr1nh8/Ev3Nu4Yz64ZUkjC/i79z9YXzU1wBQBV0J4eyj+gQFQtI5DVcyIFacq+l0s+NQ8w3RBJl3lnE5uwox1gP4XPalVagX1dDSFgxijCU0Ki8pSBcxPggClHUOcCjt6g8sWDmRGfk4DXnx1BfkvU74wPYF23PEsmPkHKwsb6AwuQjZSIh41Xe9iWnzalr9IOP1aSucZloI6ttavgEz7xq24GI0A0oE8wD2kM++stl+vt/4eBQ8QnmkbMUqpj3skILhKc68fmNvFgXE7lJp8nhHGDIAThE6kJIiLQCcMp494y0k5aE+vb/HlyvX/+/Hy6x5kAtnANZotMKOOdA0v9Z5zUJd6yFIgdcYiMHKsFrJOtMhgPVLmWowjgHGOx6esKB4yIk7HYYoHw/9yMHkrO9oz0IeXjSHDcyS+5LMM7ed8XJ0esFsyaq84+d5mTV52kFNueAIEZtIucAX3O51Qo0f02ffg3HJlJRcTk4huJS0Gn0GQnvo4Mg4vZwAYQIoSohq7bt1ySahPCxkAOEzA3gHCCxkAMF2lasFGnxc320hPZcOtfW7DgYvf7W3WuCz7mxJqPKOXDDDTdYr8mop8j/Qw89pJ773OeqPXv2qP/+7/9W3//+99Xll18efedb3/qWOvXUUyOHwiWXXKJuuukmtXz5cnXLLbeoOXPmqHPOOUd94hOfUO973/vUxz72MdXZ2am+8Y1vqIULF6ovfOEL0TXo93fddZf60pe+FDkASL74xS+qt73tberNb35z9Jp+85vf/EZde+216v3vf79qJekSyAE6ILMICUPzi97306Wqp78vUjpDIrBQ/DmEK4ouOX7DPfb0uTR4IKQYQOkpmlZAbT6UU62gCEurPFRSueLJx2nOgXCly8d/AKcLfU4KhM51Ji90QCUJqficMHuSeuOzjlVX/dtdURTvP//8gkjB+NP/uE+330f+xJEBbuSAdA6oOlYrMH/D6WJqZPtLEtX7gLNRHAw5IOaEl5DQSiuQ88g4ylzVNmTUuNroKV2HYPI0r7Ym+cKkrH7vLy+xcoopD/affrZU/+6zNz6hvnvf2miPKGpsSyeddIzwvtC1ntnYuRQ7OT9PnjtZff0N5zs5BKoRjjoih0oe2ggiI4n1EtoDvnnn6uhvcgzQP3LmvuGSY/UeGsKh4hPMI5dTl8M2aex8iK9+K63A/AaRODfnAJwDKietoH+Y0gpUYeQA1rdv3x4aCeQA2+8gmqcmxyHRUS/nwGSz51O/ha6RrDMZyDBXWoHPb4M5RPOvLemPaRM6jS6RvKedAznQ9aXrd0fIRnom6B8xciCeg09v2x+EPJSlDP/f5SeoZx0/y7kv0esLktSniiJHi3lfEu66KgpJNAQ5iJrGOdAW7hzAmufIAUlSSGNGEXxTWtjuCxJsTzFSKg7CIB11qkBBhkgl+d2/3mhQ0x/6+WMM8WdzDtD89nEOpNK6eNod4wEjXdfnKmhkIsFaJJQrrJQGJCQkZwDJjBnxxCQnAaEJXvSiF+nvnHLKKeqYY45R9957b+QcoP/PPPPMyDEAIYP/r//6r9WyZcvUueeeG32HXwPfIQQBCaEO6F4f+MAH9OdtbW3Rb+i3Lunp6Yn+QfbujeuEUnvpXyML9KJ9h3vNBjLYrzc6+lw+wwtPnqW+cvXZ6pPXP642J4YBydypXeqDV54Sfa6Z1w/3qJ6+eLNsqwx5+2Ncxc6BJhns71dDjo2PNt8+wC6HBtVQYuhEkCt2/R1JFCHKtavYn/kEW39vX7/alzD2ju+oOH977tGT1dwpXRGZkmtzrSR9Qt9bv+uQfZ+K3a+VRHHp6++P3j+QjAfl+4W0mzb7j/1yWQ65zDL1/BONN/fg4V6DKBgcyL1PezJGNJ6He1AiskNdcMyUCHqMdtB1cPgMDsTPA5nKiCFnThynP8P/k7vEiTYUNm7O9ip77gwOmGdMReWT+1SGjNHckzwj9Vc917GNJDZrAv2r2+9YeyQd/HtD9rgNDQ7o6Ne+gz2aLAzfGUpKrdHw9PT0asKuNtaOUCE0DjkHNu+J53ZXe1s03jQflJqibly2Rb3zh494D2DaQ6jefKhIBwaeFe0eZHsFzW25zmj8rd8PDKgBkXJG/cCfIf5dPy2PqoQ7cia0D6lNuw0SLkuiPa7OZ0fWeEAZJWi2L5JZcewhUpCeTAaHbD+f39T3GL9+ti5JsLdEvpxBMz7kaCKZ4NoTk3VL54L87FByPZK9NC/a4zkBJZ5sglr7Ggbn4eSs861dbpiSYn64pzd33yYZqmEfzBKa7yS9VK4tuT79HX+WfU8+A8gHVm37ZnCy4MHB4DUihdBrdNZSO+CTO9jTa86YRGfge66rL6LvJQfj5PGMVO7A4WgNo1pBZ5t9HVpf//wbU7Xo3T9+RH32hsfVhxadoro7E8j6wR5NyEt/h4gkNn3jxfOjyj++falL63R9aiaq/wzGY9mmBljJveTHyZkNXYdLRQ2qypC5STXnxEjJIOsMmlJZ7cRjan4f0hGTPY2jTSPnQLJ/RBVWxLZHOmpfsvfQ59Sv+xPnwvzpxVJwEWyTziDezntWbtP6NMmh3j5vWgHpxbwPsGfTnoNrENpv5dYDqUAf5INXnlzT+deIkqUrh55zwy1SL67lGi3lHBgcHIyM9UsvvVSdcUZMtLJ58+Yo8j9tWgyTgpAjgD7Dd7hjAJ/js6zvkEF/6NAhtWvXrig9wfWdxx83G7/kS/j4xz+eep+QDMR90MiycxudJG1qzXqC0rSpg/v3qd/+9reqo9Ku+oYqatuWTer66zc4f/u+05Ratbei9vYpNWWcUsdPOaAG1j6krl+r1EAvHaoV9fs77lIrd8b32LBunbqePnRIXKrXnoI33XSjivUU+/0t23eq8Yd3RNdc/fTTqn37qsgU3L1nr7r++uv19zZFaKEONb5tMHqmEDl4IG73Pffdr57cQxtDm9q8wd/uRXMr6tq9MAD4RhJ7Y6+cc1DdeMNv1c4e+zn6enqstj6zNu6jp55apa7vfUot3kzXale7tm+1vueTp/ZU1Oa92ZGMTXt61Fd/dIPqPUz3qqjb774vugfJrbfcEh2omb/fGLdx+YrHVc8GeroO1Xf4UNS+tfvj5ztw4GD0+nBP3I9333WnWsWWwNZ18XORLHtipfp171OWsfzg3berimpXQ0lfLl++TF2/4zFVjWyNbFbzUHfecbtakZzXe5I5CXns0UfV+E2PqMd2xe3btmOXuu2OO6Lf9/f1Bo1BqOzbE/cNyconH1fX71uhxxB9E7V/80Z1/fUGagxZudc81z133ameZv2LOX/ocI+69c67or8Hew/r9h/sN7/99fW/VVt3xG15dMliNbi2IAyyL/7t0pW0NtrUrh1mrpIuQ+Wbklid9bP4vSH1oeuWqL41A8HokL1izOjZp3aqKA0N98Sz3XH3PcnY9ek2xTq5mQ/33HOXmtZpv7dq5ZPq+kM2100t0nPQjPXtv7tZPb3XHmOf7GV9WQ8JGQ96PyvncojtISdOdX9v9Yb4+Qb7Tb9Dtm0x43frLTerx5P5vm37TnsvTPaSvt4edWOEKIzHZ2dUd7uiHnnwPrVTHMWrk/1z1aqn1fXXr7Q+W7/J3Hfl6nXqohPiOfPU0/H7a1enf1NU9uyOx/mJlU9H1zx8MN4HpfQcNvNhoK836su8fZvkrsXL1exdJtWjXrJ6fTwGT69Zq66/PkaUrNsQ98uTj69Q1+9Z7v3t/n3mWdbUsG6e2WrWxI9uulvNjABlRZAI8dy9bNah6Kwl2bQ+OaueWKmuP/xk9N5jydx8bPVGdc0PNqjjpwxZe88anMGrnk5g3G1q8/pn1LhKJdKFfnXDzZGeMzgUz8e7b7tVIbvqkR0Vde2TaT1g897D6u9+uESdM5MMuHb16BNPq97++HubVi4Pes59Wzfo700dN6TuuS3e73yyI4qJdETOh+0qXjNLHl6sBtYO6TPx4OEe9fTqNYkOtUpdf31cfnrHZnuPXfLQQ2rzxPisJ9mw3q8LjbZwHeuJZUvV9Vse9X4X+xRky6YN6vBBeq+SpBpUlOqlw7SituygQGVFDfT1qM2bNlj9Q/sTHH5tQ/F62LSNeC8qatWTT6iOSpvqH4LpbeuHsbDUk3FDqm8IZ7T7UPzu3U+rE6cM6TY89fSa5Nxri5xVvYPmd5HutNPoTv39cftuu/0OtTF61nZV6dmn3nzSkLpuTZva3Wvf89I5A1qfbyXJ05VDzrmREug21cjBg3G6REs5B4h74LHHHovg/s0ghDIgjgIIORrmz58fcSZMmWKzDjea3HLgUfXIzs2qe9pMpXbvUjNnTFOLFl2sPrLkVrXnUL9acMzRatGi2EFTRL6y8m61Y9sBdf6Fl6hdK7YotXGdOn7hArXoylOc36cI5j89+DvrvZctujKCTb3vAfv9Cd2T1fxjpiu1eZ066cQT1CULZ6ivr3hQTeyepBYtulR/7yEqD/bIA2rmlIlq0aLLgtr9H2vuVRsP7lMXXHih2v/Etqjdp510vFr0ohOd319EJReXbUmhKAiORSgKREa37D2sPr6YjM1YuidOUIsWPVe/fuS3T6jbN69VC487Ti264iS1+e41Sq1+Ui04ep5atOjM3Hb/6tFNSi038G2fHHf6OWr6jtVqy6H96qxzz1dqxZLo/Stf+pLc2sD3/XK5um/renXcCSeqc46ZptSyxWrGtClq0aJnqWUb96ovLr1PdY0frxYtel40f1R/v3r+856njjuiW0dW7n6YFNzYa33Hlnb15KGuKLJy+Ukzoo3wipe8WE179K4ogkly9plnqkUXHK2qEYJkfmqJ6fMXXv4CNW9aXBrrpn2Pqsd2xQ5DkgvOO1ctOnOumrxyu/rm44tV9+Qp6tmXnq7Uo/epiRPiZ6qXfG/TA2r1vrh03VlnnK4WXXxM9PfiZ3arry43xKfHHTtfLVp0eur3Dz+zW31lWfy9mSeco64460jt4V65db/6zCP3qI5xners885QatnDatb0eIxICNL6gQdujf5+8UuuUP+55n6lDuxXz774IvWcE9KlzrLkfzb+QW1au1u1dU9Xaucea67ev3qn2n3fgxm/rkTlnY447RJ1cSBs8eb9j6qlbMwuf/7z1EP33K5e/OIXq3Hj4gjZe+6/KQr6nX/hxUote0iN7+pSixY9P/qMIizv/cMt+veXPeeyGO304G36vTNOO1UtunSBqpf8YPMDau3+XREz+cuueklkfP/fF+7woo0gF552nFr0kuxKLUUkZDxChfYQIkBzyZZ71qpfPfOEmjDe9Dvk9weXqsU74nzOK196hZq0crv61pOPqKnTp6tFiy7S33uYUEhL/6AmdU9UV111mXrvAzfHJXEjJVupl1z+vAiuzWX5TU+pWzeuVgsWLlSLroxzrvk8VXtiZNPUWbQfb4rmzJ2/flKpLRvUGaecpBY97zhVi9A9Vu/brebNP4YsUzVlsn0WQT634g61uzdGtE3unqCOO/3EoH17zrxjnHtBrbLujtXq+nVPqSPnmXP+17uXKLVjqzrrzDPUoovme3/73+vuU+sOxCjJc88y+1gRoTPh+kfISI73+x8+3a7mTO5U0yYMRVHbENWc4PP0vXe84rnq+OSsefyWp9Rtm1aro45ZoBYtOiW6z+8Xx2fP6n1t6qvLVYT6o7MHZ/SKm+M5dOyCBTGCcuNadeLxx6mlezeqHQd61YXPukzNmNCu1P2xXvqKl10Z7bu0pj/9BTpnejytU+rpA+Tx6FddU2crtTXmBHrna1+ifn3NXbnIwysuOV7d/vPYSXPMEVPVFS+9ODOiufNAr/rnh29TfYMVNXHyZPLiqIsuvEC94OQj1Ibdh9Snltyphtra1fxj5kU61IknnqAWvfAErYfcs9VYg8+65KKI8+Bji2+PXh+34Fi1aNGpqhGF0JkfX3xn9PcRC05WVzxnobeftt27Vv3yGePMOmHhsap30161/sAeHZiYP2emWv/0TjXYQWPXqyZ3T1THLZgZ6UCQq64iDTCWjz/6e3X4QJ/qnDhJqf0H1JlnnK5+t2VllLoweZxS+1ggl/TDD1xxspoxqVNt3dejZk/uiubRm75tqla45EB/RbVPovM23s/mHHW0GiLvwNZNatKETrUzjrJFcuYZ9vr9l8duV/v7etSzLn2OeoKqIaxcpubOPkJ94I3nq38cHFJf/f0q9dXbyLkZyysuPVstOvco1WpSRFf2nXPDLRT1J32Y6zZFBQj2lnEO/N3f/Z369a9/re644w519NHGKJg7d24E+d+9e7eFHqBqBfQZviOrCqCaAf+OrHBAr8mInzBhgmpvb4/+ub6Da0ihqgf0TwoNarUDO1IyflyHRdzT2d4etTnOde9XXeM6qnoG1PDtj4Fp8bXHxdd2SUdHh05lIKG/CSmi2tKQqR7KkQIRTEe76kyegb7Jr3+wH4zDncHPgJyywaGKeiZJBdh5sF+1tXd4D5qXnXO0uvKseZl5yhO6BlPkabxNHeAWqMTvx97muB9D2n7kNFtZzvoejQNnXSYZ39WZW42A5gIJjefAUJvONY3nefLZUDwGIMPt7IzXAOV4uSDNpBjR+wQxJ6HvRjWbE+cAXbfaNTRxvN3nXUlbSCaInMSupJ/Hd44zML42MK+31XUdc5LPLrZHTOyy+RZca4/6kXIQIf/w08fUF25ZqXP46RmRX4soAuVf4jrjK+belfZ2ncYzsav4XkXriufHT2T32RGHP3KFvhd630mCN4TmrNxnSamnZ8KeQ/B2/VmHPfuor7rGdab2w3qONfVr3Pb4uvTqYy8/3cnZYrWtzu0IHY/QPcTXtvHJvk9j8OAze619EPtO9L2uzmju8z0DUknWXcSUPm5ctP76WErItEnjU/fvwJpK9k8uVLYNcggs7LTHouxdFXNfCvLzB5I1F/ElOK5pc2C0Be/bM7q7hkWXwHjxMQB4hD7Luue4djOe3ePDz1iI70zYus/UXnfxGg0xDpJr/+JC9ZZv/yEaV96G7mTd0Tz83RPbM88e5Bfj/CPjEI4omlfgNnnwmT3qshNmaM4a7D8PrtphBQakDLGqSVsS8taIh2Bil3cvwCx5+dlHqc/dFEf1SZZu3Kte8MU7Mzlbpk0yezzuSzoS9c3EriQVi9YE06HQb3KPndDVqSYy3Zb0lEbUaWkufeQXBlnz+ZtXqu/9Yb23n+RZS3oWdGF5voEkm0guoQPpdFXWF6Q7k5MLe0y0hyf7wl+fOqD+48nxas/hfvXpV5+h/vSCY1L65C+WuBG6UkB4KNNwKbjDnQMYc7lHtVE7Ez2A1jDOpT8652jLOTBxfOPbL9VIEV15tJ9/XA02ZD3bPqrVCog5lRwDP/vZz9Stt94akQZyOf/886OH/d3vTBSZSh1S6cJnPSuOitH/S5cutaoKkPeFDP/TTjtNf4dfA9/BNcggpXvx71CaA73Gd1qyWgEICZODEOQsRWpcu/KDexiRjyRPyyr7BfIUFxETXRNliehzXWFAQGLBOgum4BCB8vaPP31U3f5k7OH/0QPrcllM81haUyXnKr769NVVK8irIsHJZdCnnMU7a2z0MzCyRln6zFR5iL8LYkJ6ziz2abz3qd8+rn87s9soI7VUCpA56vxasl9BlqZLGTLCproTEgpiNsg4kdAoyY/yyl7x+UmEfI+u32M56uS9JUt9UUEFEFQr4KRkRcg6Q0WSnrlJ7+L3ehPHIB9zXuuZhP5kvpJhYYXn8wyVAXw1ofl8dZVYrEVC+5ny4H13ruQQVNH8+8JNMYSbor6v++Z91r7J+5bv2zKVQZe+FRVEZFk4JyHhYE61AlbWsNpKHS7Bs5iyvT5CQts5ELJvk5w0Z7IaDkEf97F+w995Ne3t/bQYIWHemUBXprz6OVPSlUP+5VVnaHI2Omt13jibX2gPIaVCKgKgggrahjn5P/c+EzkRSD72q+Xqtd/8Q4poNLRqERCE+D3tR1n14d/+3IXqP+9YncpBd+33XCiwg3MMJfEwluijiBvIUe6VHLxcaB7zc2m4iDFrEZyLFIEP7SepG3BCQgjKWPKyjlwflrqJLgue7DG0l/L+gh1/yXGznDpF6B7N78tLGXYL5Ke8RbujVCdvB1W34K+r1f0bXUIrrrUiEWNTIgcolYAqEfziF79QkydP1hwBU6dOjSL69P9b3/rWCL5PJIVk8L/zne+MDHYiIyQhGD85Ad74xjeqz33uc9E1PvShD0XXRmT/He94h/rqV7+q/vEf/1G95S1viRwRP/7xj6NqBBC6x5ve9CZ1wQUXqIsuukh9+ctfjkoqonpBazoHUMqwzWLJr1ZxwkZLm1douTxyDmBjhRLFD3ViByYnBrFPc6Zdvulx4ayzoQIyGkSu68ViKpnS0yzDNqOyrlYQqHTxKhI+QZ12KAioxkBdHWKMGGbrIdWTHJhQwgxbuKhW0KZy2aeR40X8FbKcYS2GuZy7VuktgZLA3OTPqOdt3Z0D3EDwH8Zc2Q1Rpt9/3VLt5KH5843bV1lzmoQ/Ci+LVM06n5IoT2autqUOYFo3fshssQNYVg1xjUusBBsGZ5eChHGNnAVSwaujQkRK6e8f3xb9TQYGGcvUJ4hmvfi0uRba6Lv3rla/fWzLsMy5vPGAnDp3slq6YW9mJRrXmgxhfwbhF/1Ha9FXylA65SyFPKo13uYt2+WsVtDnrlaAPaxopQ6XYP/r0dUK2oKcA1nVf7jIksL1Eux3cODzv/POa/6IvnK/Pgk5E8go/t5bz4vmCUfkEXv8P/3ssXj/iowjw7wOwblJ9wipCEDtwV5A82/trgOp0sokcMxyF1oRByf0Cu5ccO0F5x87XT3vX3+fQ5q2PPqdaz0SUonSC8DGj7Hi+7yrogulP3Gh88SuVtBYBmPIuejqJ3necYcKRAaVqMoT7wvZFZh/qEZBZ5GuyEJVDHJKY4fs0eSw4PsfOT7RJnk+ZpUydOnk1AfHzpyont52oJDu2WwSWnGtkStzjLSM6qr/+te/HlUoeP7zn6+OPPJI/e9HP/qR/g6VG3zZy16m/viP/zgqb0gw/+uuu05/TukAlJJA/5PT4A1veIP68z//c/XP//zP+juESCBHAKEFzj777Kik4X/913/pMoYkr33ta9XnP/959ZGPfCQqh7hkyZKo1KIkKWwFgRPA1ESPlWcoCFv3Hs4kqfIJjC9SwBCJyFtssuQa6pBCgG6gA5tHpv3IgWLOAXrOdTvdJB4yylBUZBQm5RwQxrVGDhRQChGFINZmKSfPmaSdGjgYAX8LNURMTexBVmqxze0cSHRNej80skLEliSUh1ePCKo87LNKb+EzPCMv9TScpQz5vJAKC0pOFlGmt+1Pw1upkgSiJ6Qw4Bl59KgaA0muK+5wwQEc3VP8rtoDOF3KsM0fwXUovrJ2e2SkCgUqzyAKFRjLvM66jGZJtNEEBlmtN3IgZDxI5s/s9kYyfY7REGQQfY5nwpzPK2UIpZePCRkvUumNnk/sP17kAC9lWEfkAOYR5p1vGslqBSS+6DFFzuV36y16T2fwZPztK6Xq2rtCEW6Q0DNh+4GeFCKP6wmIjEftZeOIcxPGcUh7KNWPhHSfh9bGOd0+ofti3oZEInndepJuEeWVewHxJYU6NVwiy31K5ABfF3wPTJUy7LCj342GHAgLPKT7yY0caM8836I0J+4cSCEH7PKZUbnW5PukXmO++EpjZ+3RkKvOnGulEljIAVFaU7aPl+k25cXtfjgh4ewgWbl1X1W6bjNIFmKnLGPYYMgBSivIk/Hjx6uvfe1r0T+fHHvssbksz+SAePjhhzO/QykO9K/VRSMHEm8necbJIMeG+/MlGyMyq6J1yRFFPNzP0gpylA2u/JOS54pEkVC0YH1ixLdnIAegGISmFdABwvNTsw4aOsCLiKvGuvVaKMo6qlXQe0tjRGRdV3z5zig68efPWhBFkOdOjYn4+AEPwyXUQIOC0cfTCjRyQFnt186btkpwZIWYoEm4c6OWtAIyImh+oy6whRxIpRXAOYBnHJm0Ags5IBQWvl6KQFddwqMnUWlGUhBYzeQ4X7K6tAKfwwUHMN2bK3B0ABfdT1zOAdewYG4b5IAfsUN/y+lVj7SCaqNZHHlRy7z3SdZ4POu4meq6hzdESrMrkumqqV5UQd+eOK5wHZ1KJc5+o7jazgSSyR5HL5rm0mUPedIKDHKg9ggZ7m9SIsKQAxBXn5Px9uZvPzCsEVu9p1tpBWFOY76fFkUO1JJ2RPsk7Zu0h3HnAHcGYy8iAyf0PuS4Ay+AdOpJIV0DekBIJPJdLzrJ4orxGYhF93vf94hnxn2+mTGDEcuHmSMaMD+ic5TK9A0M1t1pWatU209Sr6J9TwYTpjLnnJ53LMUijToTjmZCDiTvHRrgDpj2wns06Ss0XifPnaIeXhenC8I5gCtz5zKJHCrujHWhIslhfc8qqgIWyyd+vUL9152rqzqrm0GKnnNjWRqCkLCUkRV4UKGfoV59rZB6KFykgIXCs/mBSZtelrvo0Q17tLJl8t3daQU+hbLeB3KWIN/Zl2IhI+/kVKk2ogsiHTL8CCYmFVH8jchBCN8AbzM5e6BYSM4BDIFOK6hUAiHmXVEpTJlWUOs+3ZXUHs7LkUWfGOdAbDzzZ6uX8OvxcekSBjp3FhSBrrqEO7UAvae5qJ0DNaQVZEUP63kA8/2B9hJXBBlzVI+5RA6IyE8q+lOHCG2RaBZ3MnIjdbgUFIwHkbgRp8qfnH+0+swfn6X+/fcrU+s51AEauh9iv5FcAum0Ats45QaNjIhCYLS4OAfgBJAwcaQA1COVxHAOZDsU+dvSWS77/OFn4oomMHIvP2X2sKGYeFpBX6Azny+VopwDtaYdUYSbHAO7Dxr+Fd7e5Rtjpu5kG/AKv8+yjXssWHiReZ/nCH3WcbMs50B3TmWgWjlbJnucA9zQx3rkc0pyDmDt0f/kV2s05EC1/STXvItzwIUc4L+TjhJ5hkZ8DYludSjxNVH/5a0r15n5gz+sVb98ZFO0NnsT3RD8WxgT6XTwIgcGB1OcAyFpYa3oIChyzo1laaxkolJGREIUo2og9Z2Jh3XJul2a0CdPseEKRh6QBMZpFAlluYJOQkIR4fTJcJCoceEHq/Q6t9cJOYB8QxI6AOKavbaCDfglOAcApwxPK0gTEhpCxaEIBYTxo8cKgTRT2Ud0j+UcqFEZsaKxVpS2PTOyQocwHBwdw5lWwNZfFnIglLgsRJnl5GlQEmohJMwzEPLIOkPFIiz1zFmDbonXj/Qf8HvTZyni0DpEaKuPZrnnar2Frn3Rwpk6ak+vTZpQ8f0mGBmUKNvYb/iewQUGtuQB4XubFIyzdBBHDjDL8CWnX/x3LY4xKXgWXNM3P3muehaPACnrb/8fU9bsszc8kUuKW41gj3GlFeSl2PA5WtQ5UGvaEQwhkPVxBCGNOZEI54m8j0SPFZ33ZDzd9b7L1Q/edom65upzov/pNb0v520ecqBW0jQJMXfx3BB3kzQiU5wDcJqLIECjSLX9JB0BLuSARJzKtIIsx3P82swpZLfkjbvvzERlkH6xn8WcG4NO50AlEzlgHLChaWGtmmJQSr6UzoExKKGKUV6OGxdSYH71SKzE/GbpZvXQMzEaIaqtmiFFoYkuQkLawIgV/GeL16vlm+JIALHYhmxsdIBkRerzDuQ8sclscqoV9BfnHIBMHEd5ufHfKG3D741DENDJUOOXG17SmNCROyqhx8I1i5/ZlcnQjhwv1JquZ7UCF5kZRPariVKaZ4SSXG8opaWoZZAkceMhJB8xT9ZsP2jdHzwjrntXxTlQMO+4NuSA+14YY8xPOX+kcieHth7Eb9U6GUcCOQABomjtjoM159+HKui4Zx7ngEGapfOkJVw6zTlgvw8npvVe8pZ0cNaTkFBG7ZycA54xRhQPVUBCWeprq1aQRg7kVivgaQWBRk+98n5hCCGtgDu/v3rrU2onQxT4hJzQ/D7oi2kTqJRzXgpkXGki1BFK/3PUizTe6+08kSUJrXQWVkkq/ow9l0wr0MgBe802ilTbT0WqFZjvCEJCcUO5d1IqEOYlkAPV6Lg2N8ig6ksq8ZAQ+gP61oRA5EDEKcaQA9XyNpQydqRMKxiDUlQZzIuK+eBJJN//w3r13JNmew/9rFwsn/CSWLRJcr4EyL/ftkr97OENublTdJ1Tj5yslrCcriIHcjEiOrlx29wbtSAHyJid1Nmh9vX0q10HYiWJH2qylGHo83DyKtM+IAeUhqw9719v079523cfymRoB8S8r6/PeSg/tWWfekENcFref9xQTDPf24YInZ06gln3tAI2FsJY5aknEuLuha5O6YqiQHsO9mWm4nz5lifVyXMn6XkIgs/4XnVIK6hD7nbtyAGDisjjHKDPZGqCz2AbCcg0d64Mt3NgwcyYeGrtjgOWoVCNoRzK/rwmcURgjHylDKG4GsOk4oVLQ3R1G4Ec4JUKkKfeMwzIAUmE6dszfJwDtfJV1BU5oAkhw5ED1Ro91aYdgThvt3YOtGn940u3PBV07w9ddaqlDxgHt1Inzp6kHktSE1xywbHTC/c/IRiR1iLzw11SC2fLJIkccFTFcZ3/3SLdAd/F/42GHKi2n+Q+R45ZiZpKOQci5IB9fmQiB9oMIeGh/krVOi4fP15hKK+UoQ8VJzkHhjOdtpTWkNI5MAalqFGQFRXLUmwgWYoNVzDoY9LzfNeCEUUGn47a9A96PaCbAnOn5k2bGDkHSAkl47pWEjUuPBKTIiQU5Fy1IAdICMYYOQeSCEpWWkEolFqXvYqqFaB98ZiZ1A6lNie1nH15a1k5Xjcu26L++TeP69efvfEJ9d371lbd974cQX8pQ/Odos6TUOFjIY1cau+hQdRJDs/hv3n5ZvWOjDKWfP1hrA719dfEhh6aVlAv4df3GV/cUehCffDfYQnSW7BP60FIWG2pJAs5MAyEhFyOSaL4REBLBotGDlT5/CEK+n/d+XT0Ho+mugkJbQObj5mPcwDdJa+FNUzPhfJuhzVyoI5pBcIp5eUcaMtGqVTLV1GtGKODlzKEcya7X/gZVgtqqJq8X4kcoPGF/hEqnKRXIlmmJ6ltZCBy0kO6LyGuTp47WVXjTN2YjG0ecqBW54lcJy6nFBxn3EE6MeVUaLPmSSM6B6rpJ+kIoCCHdBhM6nJwDgg0XzbngClliD2n2jMSOhonETbOAXcVBPno2Hv6LeRA27Cn05bS/FI6B8aghCpGvmhXEcVG5Sg249nmRpC/Hft7vbWfKTdu7+H+SCkrokfnRV2g5F198Xz1zTtWR/f//tsujnJ0az0YuQEmryXzb2tBDnDlwDgHMtIKgjkHDFmfrG2flbURGvF6ZEdFfeveR+pKioP2SWNSHtJoEzeO4KAZVkJC4Zih9Yhx8eW+upRp6pd3v+jEzKgZDIvZk7vs8qUdMSN1rWkFEpZZb5lYIK3AIAfsz/lchwFOvxl01EofzWjWcLOC09hRVZAdB3oj9IBEAg2Hgi5LE+YhB3S1ggDOAUNKq5zOAXouMsh2HjBpBVCy61mtAE4W355qG2np74x0FE9ydPC/8xBTVmnYYUYNeZ0D7HwL0T8grvRA7qCHg+TjLz9dHTG5S73xv++P5taFx05Ttz+1o6oIMN8vi6RhVOM8kYYtHyvsM67zTZYyRE465gSVeo6CMg3oJCjST1LvJeJivv/S39LhRc68zFKGsnRyVMowccQne07VyAGkzhJywHIODGRwDgQgB9pDCaOrT6ctpfmldA6MQXE5B4pEu+qp2HDkAB2kn3zlGSnlGogBU2ZOqaXr02kA1UZdsAnvTxhkKDr6rONnqXqIZZik0gqg3NYHOYCoLkXK0tUKEDmuMq0gQg7Y1QoeXb+7pr6n8bxuTVvd4bQ4sKWxlTr4RR60RdhY5zJiVt1oiRxg4100orlglqlRHCJwDpBiVI2MNHKAK9S+OZBXrYCPJZS7WIkKq+0+nNGsEGREPeWYGRMi58CPH1ynVmyOIdQbdh2qSfnPUtDR9bSuiBcGxKMp54A2sJHqw2DPOWkFkpAQ0VHq2+7E8OlJyooZ50Ad0CIVO63AzzngdwySjHQUj5PMptMKcpADcKh2tI14iTuw6iOtgNpQxGHi0mV49QzMSZobl54wSx01bYJav+uQWpXwtkjivqL7ZXdOtYJaRSITXBVyNDKOp9uJPfzWFVvVJ35jdLBr716jfvvY5qYvb5dKKxhnowJov5BOwzitgDtwVbZzgNIKki8VJSSUgr1QphXQa4xjt5hT/moFxvmFVMZqkG6ljB0pnQNjUKQBcuUZc6NyhtXUJa9VsbHSCtoqTuX6I79Yqp7aekAd1GQ6FW0Ah0qWEoENFVBCH4y1GuHKYAo5AOdAsu/XjBxIohRgc+b1eXHQQHEuTkhoDiQcoDsO2ORZRfv+wbW71O7eSt3htIiESph2CjnAopn0VbIx4ACpf7UC7qgRyAEHwiNUQtcfKokcTNJmqiXhoz6k/QNGViNwDsD4702UnxSngCNnlA9vPZ0DRaNZXGEdbkWMcrMf3xwTxH7nnrX6/e/cu1bdtHxL3ZV/ut/nb3xSE8S+7pv3qSMmdWVzDjjY4/2cA8pZylA7Wce16b388HAQEiKdJYenxJprbE+GjHQUr8PBOWBKGWbPQeyp1fIN1CJEumudb+2V4P3v3S86yTm3OXoPBI1Yh3AO0L/o/lUY95yjpdoIcrWOW8s5kMw7k1Zgf4/GkwIH9Pbffr81y9ulDf/2FHIgXT2ICAnTyDPfeu6wCAmxVqrTJ2VAh4vmschJKzBpM1TG2NZtauG3KKX1pXQOjEGRUcNT5k5RX339eVXVJc9TbFQO278VGWSQX65cT0gOZQSI6PPZUwy7fYhkKRHYLLVzILAMYoi4IM2QNpEzq3P6q4T5TpZpBcwxAWX7UFLPOZxzANC2NHKgVscQGQzDAaf1ESnJfsW4kzFJ/UMGLxwgvihgteIqK6XbyxSSooZqqGERQ04PawdbLXXeCeGzfX/PiFQrCIms432NHBBfswgJk+by8Q1NsRkOsdIKhpFzIIs0tgg/S63325bMGw6TJRmQaQVtIaUMPciBBB1DjitEmymtgPYw+BHqU8ow/h81yH1oozxCwpGO4kkCT+4oyNt/0IbRcA4AQWKqFbQF6R9E3vp3l5+Qk9dtkAPog3nTbH6C6tIKzNytNoIcKhJhw/dLud/LuUSoAzJCfX04HMSYIy2ptIKIc6DdOmvouajfeLlfH4dR9HlSbpCf7ZhTh2pFDiTXOZjobFzAOSDnZCZyQOyxtfBblNL6MryaXSkNKWkSlUrVdclDyq1lKTZcyfBCb4XHl4zsCxaERVFCShFiwx8O5ABXclNwZyi3knOgymgs2g0F2OYcqFTJOWAOF81unhiEeWOQ1/fIg683nBb9l0X+5isvCOdA/asVpFEcEK58FM1/Dy3rZJxDhnOgWuEK70imFfgcWto54KlWwJ1k+Kw9B+o9UjISaQUhpLGqjrWtQ+5HYzXggrW3hacVeDkHtJO1XTO4k3MAzs26VysoghzwGN+1lPirulqB1f/ZvAnymYfbKRhESNjRlrv/0b+Pvfx0r26B4aAzGONokAP2WFSXVmCQA93DnFaQIiR0pBXoz8QeGWLANnt5Oxj+/Ny10wraUg5b6jervHAecqC9TSMSgVYC4qWouCoMyWksx036l11pM+mqWdXp/qW0tpTOgTEoLuhULQLFZo5QbEje9cLjMxWbkJxiSZhF3ysCC82LumCzBFxR1gseNkJCwdzN4bDViIywudIKTE598bQCKNdw1mRFn0MiXlQaalrnUG6t9KJwWszvNHLAXcqQBAoAYJc44OslFv9DBuNxNXD/EMMCfcEJCauVyQwqO+zOgZBShppzIEF9eLg9bM6BbKj3SMlIEBKGkrbVS/kPvR+/j86H1RVEwtMKfKUMaR/tBufAoHEe1YqckcgF7ZRqC+AcyNhXaJ3e9b7L1Q/edom65upzov/pdb3hvbJaAfWfcXCEIQeGe91nOQd2C8LdWhwr7RZywHaQUBUj6/6B1Qa4TJkwcsgB6RywDGGx38u52l3AcdHM5e2sNAJRrQBzmqd1Rs6BDEJCicKlPsf5XitywKQV9FvpH1y6czkHDCEhr1ZQSil5UqYVjEFJIQfqsFkAnvScz9yqNrGyds8+Ljv3VnIOuERGfGmT5JsgbfA8KgQ5MjB3qj2FHKjfIW5Dmt3IAXh1oaDVihyAuNIKDhfMqedpBdJZw88hIhrjPBAheWvUN69eMKi+9WR7XeG0OPDlQSmdLtwBoKGADsKmYUcOcELCGsrKZbPGwznQX4e0Ao4cGF5Fg9oPjgN/KUPjwMqrVqDTCvh4NAhyYLhKGRZV5mtV/oNJatk5gcg1FGvuQMtLK5BIB6B/IkJCzTlQsQgr61K+UtzfNz/5uyGw/XqUK8wSnAtwyPD+ywsUYE8dbkPXJcj556UMa4VHa+QAq1aA/UAiB6riHBhJ5IBYJ21ZaQVirymSMtHM5e3oLDkAUt6OmD9H6g3cYRATEvp1uHHOagXJeTRU21rBPARygNpCjgu03zVuKcJNVh0mb58qpRQupXNgDIo8KKolJ5NCG9Nxs7st50AeTDEEVisNENqg+SZ40pxJaumGver1F89Xx8+apGZM6lJzp4TnTuE7+xJ62bqmFbC+dsG5SGIiPLPhV805IJEDrO87cxjdQyCoA0M2ISG/xqdfdab6q/99KEoVuObqc4P7/uyZQ+orV5+tPvXbJ+pGioMDP6+UoQ0xHN60gsxqBTz9o4a1mGVY1BM5wBXekShnRg7EyDngMaxSnAMeBckmJPQrziMpHBVVb7RKtcp8rcp/6O9nsbQiGdXiSvek3GoFyokcoH0Kv+VpBfUgI4zb6keouNo5HOSX1QiQMnDI8PSCPKcJHpEq+1D1iZHMT4YhpNPmxDhW41jRyIEBE1k1yIHaOQe6mUNg1bb9wwrbzkIOpNMKlNPxQe+TPtKq5e1i3cWkpUjOAbwPkZwDcnm4Am3SwVZtWkHKoU+lFsX98tIKsPf4OAdKKcUnpXNgDEoqraCOm8WRU+0DNS8qxw9cX+QshRyoVKzv7jwQb/YvPnWuesEpswu3WRqCsl5wLZLFdIuX5NEF30BdkQMZRHehSionrwJ61xWZR0rEzEldhRW0K06fo648a17dSHF8nAP0zCiLyZ/NVc2h3geozW/gRw4Ml/FgyI3q4BxIoLKkNI1EOTNyDlC00J83LODdHmgl/6xxCAmHHzkA0rY8qH+9lP8QkjiS846Zrv/mNbj5/1nOAR71dSMH2jRygJwDcB7Vg2/Amd/rcw601S+Frx7CU8XilAJz9mQ5RYlk8kcPrIv+fmrr/qj6RCg6rx4Ccknp0K1FNO9PhBywUXVHCudAUc4B6q+P/mqZfv3RXy5T37h91bD1V4pzgDulctIKoIcRAnDH/t6WLW/HnbGkx9jVCtrdnAPcOZCqhJNO0ZU6b62lDHFm071kJavunLQCGzkQxitSSikko+/GLqUBCAnrNw2OEnl/eRFYvnH6/AgpODilFSTl53hJvakTqzPq5UFZ12oF3DDxRJqIcwDGNR0u1R6+Kc4Bdm85xoWRAxHngE1IyC/BFfJqpJ6kOJjfrvnEPe92HWgbOVBvBag9g3TQdg4Mz8GN5wHnRC3RUxhc1L8UPayVwC5PsEeEVitoyyxlaP8/2soSXy/DpXSDtC3k6vVQ/kNIMqXAQHWVMsxDDgjfgN5LyamEFLHDDDlQL6SINBSaBjnA5nuUi8xKGvrah+oTHNLMS9zR58MtMgJbj750sbnjzKZ5N9UqRRiuF6C/ZMnl4eyvItUK5B6J31LpxZEixhwNQT/Q41P/WGkFmpCQcw5ULMeKLJPr0qXlPlB9WoGN9pPODPpY8nGlHOM6LdSs82Z27pQycjL6J1UpIy5djvIr9RLpbc9TvIOqFQilABsgNk9Ee6exg7w25ED9oNK8bzsyqhXUWqnAjRxIG7++tuRyDgwOptpIByXOIn6AjbagDa5ILOYSzTWbKKxtWJ0DvL/ltevBOZAn9eIcIKX2h39Yp9cdRQ+f89lbh9U4wB7hc2Ia1ng4B9yf03BjzC2DbRQ5ByzkwDAqbSBto0ivS46ss/LvI4njpLUgYo3+Fmgevl581Qr8nAODKc6BCDmQzA+pUA93WoFrnxlN4euIDOK+JKJIzXQ9Q1b1iaE6VrnIE0kIWE/nAJ3BMq2AhK+XxzbuCXrG0eqvKLLscX53CtJV2XVYE1QGdOqETnX7e18w7MSYoyHGAdAWrUuLkNCBHKCzOYtUOp1WQGWRhXOg6rQCcA6YtIIsVIOTb0cjB0x1mJJzoJQQKdMKxqCkqxXUT2GRymcRzgEfi6oLOWAUfHPATpvYWVWbpbe1nmkFWcgBvCZIY62VCmTZpHQpw+qQA85qBTzaWamo/qEh5hwYeaKq0GoFfL7JA9IQNg4v5wApDpUMxuPhMh7qwTngq12PaNhwRZZCkQPGOeAeW/4+LgUU0mgJVyQf37RXXbhg+HK4OWnb5j2HoqhmUX6Wau+HdKFzj5mmTvnwDdHnAyxibQyzNut/UoZ9cxXNlWkFPc60AkNIWC8HnFzHIaUMR5PfwtVOWjOIKPqcZHnVJ3iVi+EkU5SR+/o4B5RBDgj0Cu13q7cf0N9983cWB6VRjGZ/Ee9Qz/7eaM7x+ZmFHKDn/NWSjdHfG/ccttJFCMnXSgL9BP3hKmUonfUW54BEDjiqFUgndjVcFdG1krMBehedFVy/onvLPUfuSS5kTFmtoJQQKWfJGBSXt3O0OAesUoaeZriqFfD/IRwCWBNyoJ5pBRmcAzigSTerB3JAEhJapfpSrLpthYwXUqx15I21Ec9QD7h6vQRtJo+7hL0jcpB2DtgolHobjDqX2rEeai1lOBKcA6MZPdTIAS/nQJudVuCJ6PK38Z3RjKKQUv7iL96hX3/sV8uHHYWB9J1XnXe0eutlx6lXnTu8ta1luhBXpjlyAIaZ2dvNuvSlrrT70gpYtQKgqSitAPOjXg5MuYX6lO5G4bdwnQUcbuxrW3D1iWEucSdz/uvBHeEq9UZ7JRyhsgpSSFrAaPYXnGHynElHmCsNky4ykoL9B7n7fC8I4RyQS1zOQdq/JIdXtWU/5RhGyAEWmKH1Ss4Am3BXXsOgq0rkQClFZPQ1+VJGXGgDs/Ot64gcEOV/8jaiiUFpBe6oN/8+lVerVsFtG9a0An9OsSbUGhzSCm0tkFeZVsChhB1VpxXYJf7StdmV9flo1L/mQsrMV29dGf29eW9PCvYO6GCK0V6kFdQfOYCIaPq6I5FWkEIOFLxPkWhYvQXzjZTp+1fvTLHTcwdWloJkIwcqoxrJhVK+mVV2aWWlHMK5YrjBbwyzSvTs37lnbfR6f8+AN3UFUTKJHOB7EaJ2vYP1JyRMcw64v8fnYyOkFcQpVfHflFKAtALfnhdafWK4S9wNJyEhdw7QW7U4Qkezv6ADSCPWVdmhUdJFRiutgL/meqbFORClFfA8fzcqLf47Ntalk7CaEpi4HpeolKHFhxDfJ6t9tvNreMiWS2lNGf2TqpRREa4U1zOaQWXOuJGayznQWZxzAAc6/361KQXDXa0gK9dcIweIc6AOUa0UIWEd0gpclSxsUhzb6BxN5AAMrr1JSUqXwQUFQCrpnalqBfV9DlyNDBkZCeVjM1yEhJiHh1hZpCIyWtEwGrO7V22P/l6ybo96w7UPqo8vblc3LtvirVaQdvy4nAP2ZyMpY1Ep9xlkEESviQWf1ur+JM82y2mCMeQIBLuUYZuFHOipe7UCtyKe9b1GcA7wFAKOHPC1DdUnfCuF3j9yBErcDSchIc0hoFce27CnJkfoaPYX5nsq6iz6iqbkaDp8R0ugn2AP4P0CPZM7DCJCwkDOAXwmz5Tq0wrS6A+7bemAgy8AFZWiLpEDpRSQxjipShlx4ZtaHvS/Ft6BvI3IR6Dj+w4JmssjN9OqrFTguq+PHbvWDd5HYBVxDtTI9k/S3ZmRVlBlKomryoH1TDqtoL+uZF/DZXBpskKPAWkICevXNjJoPvSLx6K/DzgioViLLj6Cegme72DyfEUNpNGIhsHZA2MPsrtXqXf+8BHdf7JaQToXHJwD5j04CkbDWBuLSrkLqeUiJLxp2eZgpwnGcDAjrQAK/6F+pVZs3ltXB2ZqDwngHGiEUoYW0eyAKWXoc5SFVJ8YiRJ3KULCuqQVoB8G9TzaddCuMFDUETqa/aWRA5Uc+Hul0jDpIiMpnTp1IJ1CoB0HIqhC5wnWbVYlHDjc5BqvFk0pAzOSkNDl4JDqgyttpkQOlBIipXNgjIoFZRZMtvWsWJDneKCNFznFcuP1Igfa6osckJulzN2vRbK8zrzGskEOVL8k6fo8L5OPa7WcA1JhlO1LVysYnbSCUIMLhqaXkFA7B9rqauDuOtjnjYS64IH1FjwP7LGizoGRjoZlOXugYsNQ1JwDQA54iOJ4+hD+Hg3nwFhUyp15sBYhYTx2EvWT5TTBfjokkQPJXvrUln3qNd+4J/ltRX3jjjXR33sCjb888VXFSH+v8ZAD2qFGhISihF+R6hMjWeKOjKB6p0PiepxbYPaU2h2ho9VfQA+mo87pwESjpIuMJnKApj7WAu0tdJ7wAIdx3LuDClwf8vEK1Qs5EJcytMss8vu6dGg8m4UcaBAHZSmNLWW1gjEqVlpBnZEDc6d06b8XP7NLXXby3ExvJW2elCfqi7ykCAldaQVVkhHK62SVzqpGeN9Ko4WX4uLRrlqVA5ALceVJ9m0ockAyWPscNSbPd3SU31BDaigxN+XBi/Wgvet1iODnoRnoDvT56y8+ZtgNBznevEJCiCAaRg4NutLQMEfDikTXoexQRQ2n0dZgaQVjUSl3phVYhIRDhdc6hlNyDmAv/c69MW+BlEc37I2ccrUaaD7iSyl8K2kU5wDaQU4ZwOnzUA2u6hPDUeXCJ3Rekq6wL3Eg1QMB4nIOXJw4QsmB65qVlcTIz3OEjkZ/QXeRRmI6raCiLlo4vS7P2UyCOb7/cJ+65pan1A/+8Iw+8799zxp147LN6rQjp7Dvc+fAQCbngKm0Up9ShvI6dK/xrrQCXhHLU62AShlijy2rFZQSIuUsGaPi8njWQ0jpun7pZv36L76zOJeBGwanjyFeQtXbnMiBejoH6klImI5WyvvS2VQP5IBMibA4BxyERPVADqSrFYwOciDUkJqc8EmknCWSsLEOayLUwN2SkNLVKxfaJXn1mUNkJKNhRaLrRgFKnAMSFdJgaQWNksM9WgJnDSmsECjoRda64WyxPz+cpDhlycd+uaxmToc0IaHPOVAZNpRefdIK3A7TkOoTIw1R5lHYeqRocDZ3vjfWKy1gpPtrsuYcEHug4/xvlHSRkRLSQX+RlGxcte2A+tItTzoJYX/3+Fb9WqL6stI1kAYgg22cV6uIyMBMnFaQJiTkbfCR8ZacA6UUldI5MEbF2tTa6wuhDiGTcm2evmgtGOYh2NzqhRzgm6XcgGsVbmTKTRndXl/kwDh3PpyjHm9VEecU/0NjEBKGGlxHTY9TXqTCI/unHgpRqIELxwpF8Hxl22qVFPNxleNEDoC73ne5+sHbLlHXXH1O9D+9rjdMtkh0Xc5RX/SEjykMttFQlMaaUu4nJFSptALax0OdJhhnmVYgU3hcQpVMUNWkWvFBeLO+V2+UXrWCdhDfgOYcaIL51s14deqht7gCEmSUNUIaRTUCXaqnf8A6S9KlDOP/m/U5q9VNoaf4RJ68QFygMkaW3gCnJ9f5aOlXqxN1OKsV2HwI0fcc55puE3N+ldUKSikiZVrBGBWbkHDkINQEs5ObE2BXoaUMoWzZhITVcw5w5Q2e92FJK/AYMfXiHJDtz0wrCFSsUEcXkT3pOMFlkVYwWs6BUNg7lcILysmsQ1pBqIF7w2ObtVFDZIVkAFFb66mYSShhLSX8EA0bCWdPCOT1/tU77PZ5jDauOOHxhxOtkSVQymlP5OiSucMw9o0mEulBAsjray44Wv33nauDUlcwpX2lDPOEIocnz51UdV+HphXYhISN4RzAftfPjIZGaVuW8ChsPdorz0XaIjCuSAu4d+VWddOd96uXXHaxetYJsxvWuCID+Nq7VjvPEh/irxHSRYZbsvlrsgXnA/QFueatSkMOQkKqsFEtybDLoc9RtHAe2KUM3fObHIAI2j2+aa+6cEHrjG8pwyONfxqUMixil09rGzUGbtq4+xLDePv+HmfUNIyQsAbkANuE68k3kEorqHicA1TKsE7IAU6mmJVWUMQhxPtHpniYagX1aX8tEhIFQT9QzmFWZKUeB2cemgECjojhrHUvxxuszY0qWdF1mI0wFFPIAbGdacXOkVYwmtHSkUJhNINzAH9fcOz04Eimr1pBEeRNLSUj26sgJGyctAKOHGgeorJuhhyoxcEZiv6gMSUOgvNnDUX/N6pBlVfGl8ozcnFVThrNdJHhlDzdNER/w//S8WwF2TS6wLxXiz4kUUZRKUNHWkGWjtmefOfWFVvVlr090d8f+9Xy3FTfUkopkQNjVOqdVlANAzdtTjxydsuKrdGmJSNn0utdb+cA31DrWcZQRqhdigcJRW5Wbz8Q/b0jcZBUezjz9nNlrxbjlzzih5Ub2QCv+MFRLmUYEgWh+fa9+56Jvrdu1yErsiIP4nooyllohizJQ9pU2xYuoxUxr0d0fVqnUp989dl6j5AoEJ/Cz9/XaQWjHC0dCRRGo4nmCmAR/z7GmP+i0+YERTK5c5VLEWMfDutqxqCZCQl1LvLAkEZtyBznRhReznBcHRwtaaLexu+DalCb//fQeut9X2WoVpRaqr6Aq8HLOeAg9uYlCKvlG/DxPXH9SxMSZpTLXrFxr1XBRTqNWil1pJT6SukcGKPi8niOJAM3PN3yQHNtWtL7ioONH3BTJ1SfVsAVApQCqpdw5UMqk2j/9v296lePxl7c3yzdrBY/k3aQhApvv40OyY6QZD4D+21etYLRIiTMM7jy5hsZJMOhPPkM3Bnd49TOA31BSJt6GI/14hwYbWfPzIkdatvy+9QVp5vxyuMc6MioVlCP6GMpxaTDQUiIv5G3G+I0afNVKxCK8HAZD2knVFs+50CDzDes/6haQdL3zYAc4ISEne21nzXyTG4G3oVqUJuSh6NBpuGISC1VXzTnQLJeUmS3rlKGrHMn1BAskY5EagPXv4BC4mc735LIafSbpZtGLABRSmvJGNoiSsnLlRopBu48T7eEe/oMUq7MTK+pWoEaNuSARVgjOufep+NcaRnoqgVW7uMcSBESFtAO+HfTuYvx/4CmjhbnQJaEzDdKMRguJdEFH//wy04f0Vr39eQcGGnhkFeC9qZKFeZEcDVygD0y4KHNYBCNCULCKqLXUNT5/kkogt7EOfBXzz1uWI2HvHmn22khBxpjvplc5GLVCkZbJlqEhMOAHGiQ8Ski1ZwR1ebBN6OEpveRyO88tHZXpD9Af0qlFTiQoXwO1YQccJAfupADNudAxXIa7TkUFoAopRQpjX8alNIUyIEiDNxF+QlSaQUO5EAthITccKp/WkEllf9FQgfO129zs2W7HCTVIAey0gqKGL8cJpciJBTXGU3OAZ+EzDdZYaPennSZ0zl3ysjWus+rOtHM4iIVsz7XkNB0bmajwLzHkvB0KggIT4usO07oCuH16v/mBSdkrjPusK5G8pxUsp2N5JTDmojTChJCwiaIHlqlDOuwh6UdPI0xPkWkmjOiHoS7zSLZ/DW2TJ04TnWzOfZn/3V/lOq673Cfp1pBGhXEzyMiJKxWpLMurqQV7hyoJtW3lFIgzbcTltKwpQxDy+IU3bRSyAHAt9gmPKWGdAALOVDntAIeCeMHMhmslE5Qb68uj6w8tCb2ekf3bqtYymwRJTwbOdD4Rmc1h99ww+xGutZ9XunGZhap0Pvqz/P38WejRHLHkmA8mG/A1OAuMB46rYA5UFESloSU/I+9/LRkjQ1lOqyHs5Qhj9J2NFy1gkHD99AEa4Gfb/VwtGQZe80iIWfJrEmdY5ZzIFM3ndKl3v2iEyNE37tfdJLac7DPSRD85Jb9TsQFvcY8xNzh6UW1BEtSqYCEHGDX05wDPHW1Un2qbymlcCk5B8ao2B7I+kKo88r/FN206LfURsAfNXIguSYx9NeidHHjYvJwIgdYE4fDq0tpCJ+/8Qn9+vX/db9VFo8OE0TW6l2tQH/eAJwDdYmsDLNzILT0Yr3a0aycAyGSrlYgXif/EzqE0kdImTbVClqnH5oZOUCs+UX3JQAGSJnHuB7uH9DXoTOB9r2vXH22+tB1S9Ru5outR8nIFDN4ECFhYxhlmPd9HDnQII6LYORAPZwDgWPYyBJylrzjecerT/5mhX5/LG57WWTF5JwkhEBW6iFJpZL+Bq1p8ie0u0oZdtaxWoFADnQ6Shly5wU9GxF17xZ8E65ywKWUIqV0DoxRgbeTNsZ655+h/M+OFe7yP0VqmHOjs28ghn5jz8TBPr2GlAJ+neEoZWgzybYNm1c3hOCROweKwCc5+kEa/3LqjHa1ApeEzDdyMPEyUCNhNI5krfsU50ALOQd8LPZYF1CKt+7r0RUqpk4Y1zQGUcsiB1g6gEYOBK47GtcP/fyx6G/Kq8W4khEkI3ZEXtm3ZkAdcdolasfB/rrVcfdxW2RyDrQ1GHJgYNDwPTTBWrAICeuwh5EjkbYLTMVm6INqzpIT50y2nAPN6ASph/iITkPLHT61eX+qmhTNQ3JQIi2H63z1RA50tduEhB3OUobm+9TG114wX/3HHU+nrj0cAYhSWktK58AYFRyso8HOW03UdPy4NrW/x00mVksZQ7Rn2AgJ2bW53kHK6RGTu9S2fclD1eDVDSllRJ9zXaoIhDQTOSA5BxoQORAy364660j1gz+sY78Z/WhGPUWu80bJfa6HyLmMR81ymEERbJRI7lgSzG2LkLAA50DWuH70l8v0ecGFLkuO6nHjajsrrGvmIFbMvU0anO87o4YcGBxSfahW0CBtG0lCQugT/Yl3oJkNpayzZN3Og2M6raBeCM0H1u5Klds2JQXT6a61IAcoaAdUQxbnAHdGSMf4jx80Og2X4QhAlNJa0joaYilVOQdGy0gI5SdwRayxYe5NmFiHhoYKE/d5nQP1LmXo2bjpnu958YnO3xT16oYSPHI6nkKEhBbngLusZCMjB0Lm27nzp48aMZUkKxwOBVVes9WRAyEVKly/LWUkqxUwQkINbc8ej9BxHYlzTU4dP3LAdmY3gnQ4kAONwoeQJd1dvJRhfdrL94BmcJBUc5bI/b50DlSfeiirSelAm3AS1IOgmc/HzoC0Ajgf4UCVJSwhH77q1NIxUEqmlMiBMSqoETyaCkuRqCkiQXSm3bhsswWfW7phb8qbW0T4/YaTc0BCZl94CtVqj6GxtXh1Q73eXB8oYhRxhT1FSNhELPhZ8+1nD6+3vtvsSqIUuc4beZyKilxXNCdDYaI7DriRO6UMn7TVgBwIHdeRkNB8dUN+2ThrbpyrWkEDOS/CkAPD4Bxogj6oRmRftdjxNuyphz40JukTcA7otAJ2HtVSrSC6JksFHechJJRpBVkOVBL69id+s0JdccaRpXO8FK+UzoExKtLb2Wg5YFIQsaatLC+3vqiDgBuC9eYcsKoViK6WhvUbLzlWLTrzyMKw8lCvt1W+skBknH83Xa1ANTwhYch8cxmYrSTy+VqakLAS7jDr7a8ecVRKcSHF9UBSNnTFpj3qpWfMjdZkaN576LiORGRU7hG+PRVtaaRUHqyZPl6toEH4ELJkPNu3lm7Yo+bPmFhX7ohm6INqRDp+SqMwPPUwr5qU4e9KG+vjO2ubT9xZlUorgFNCoFOLlAoP0b1LGZvSmjthKcGbTl//YMT0XAssfyQEyAFqZhaklDymtTzLmh0H6toXfHNPsVuL139x6YKqYOWhZfE4KqJ6zgFRVrIJShmGiDRKWg05kEoraCBDpVZBaVP9ulIJdpj19A00/N7XKkJQV0J4Ldu4N3r91d+vil5f/+hGXa3gkXW7M8cjdFwnMvj5cIncz312ZVsDIgcQFOjrbx7kAM2fd/1oiX79zh88HM0fwLurlVZKK/BJKq2gRZ9zOFIP85yVGjmQrB8+n2pFDnBnFZ3ZPE1Bch1gTxqOSliljD1pnNOqlBETOky/8runor93J0zP9Thkh1NCcre4RzRU6Jnf+p0H9OuP/GJZXfuCK1zSIOcq8IRxbeqY6RNr8nqTVDL4CzpZVL96zgF/7iIdXs2qdLR6ZCVFSNikTpzQUoZ5DjPI3at2NPze1wqCHFgZ0aLXf/P9h3Vawd/lGHyh40o8NMPt9Ja2fh5yoJEg67paASEHNOdA47TPN392HOjNzP+udf9o5D6oRWSVjJJzwO8guOt9l0c5+SFCzkpppHN9aUINhITxtThyoOLmHGBjS8Na70pYpYxNaR0NsZRChywv21avQ3Y4pUhEOtQjir7Yvr/+CoeL2E4yyV55zR369aG+QfXcf/191fcMIXjkB00R45crT9JJw3WOZkUNuKJ6reYckNH1VickzHKYSWn0va/ZJS8Htsh4hI7rU1sPaKf3jcu2qOGQSjDnQCOmFSTIAeIc0NUKGqd9RUkoa0EM8nO5UfugViGHKT/HJeKvFHsd/8WlC4PQmOSsxLrG3OH9PKFW5AB3DrS3xxVPBBJJphWEIklDKmGVMnalNXfCUkblkB1OKcL6GuIRHam+sA5kwSS7ZW9PXY0UeL1/8LZL1DVXnxP9T69lyZ24XW11Rw40aqWCEJERo1ZzDsjoQivBZ1N8EZViMNFG3/uaXYqSCOaNRxH4L+2p7/zhI+qRHfWf79LA8lcraLy0gnGOagWNmlZQJIe6GhkLyAHpEC59A/VBY5Ic6I0DbVv3Ho72K+40fGbnwZrOFH5u0/jRpXDerd0RX9tOKwhve6vpOKXUVxrntCql6Q/ZkXAO0L5bD4/oSPUFVwhRgnE4nRJZZfEs50C1nAPCOcCv3+hkhFkio3qtZDzLcaJnlVHPZhap5PDXoTDRRt77ml2qyW3NGw+M63nHTM+sJ45d9Lo1bXV3/GTNu6YpZTg4xNIKGlMdHO4cap4K12r7fpYuUkptaEwSQiY9un5P9Pf1j21W53/yZnX552/T3/38zStrSlvje8a9T2+PrtWbcIR8/faYs+XpbftTe03RUuGllCKlrFYwhqSZiUpglE7q6lD7D/enGGWLekRHqi/45t4+ykyyYLeN2lUorYAjB2wlvNIiyIF0qafWUp4k63EriZzLLrj3rMldTbv3NbvUktuaNR40rifPnaQWP7NLHewdyNxTd/dW1INrd6nnnETlY+sjcotoplKGJq1gkKUVNOaeN9w51BZyoEXTClLOgRY730a6/PHNyzc7q2btPtiXukZtlbTMmH3sl8ud1/7p4g1OR1eRUuGllCKldA6MIWlmohIgByhC9K+vOSuKrnMjmzyi5BgI3XxHqi/sUoYVtXn3oVEzUlCHF20J/p1VrUAgB9hlmhk5IKN6jRTlq4fYCI/WUoBTEdxKa+19Y6mGeNHxmDUpzOlDsnWfncY1UmkFjcg5gKas2mqijo3kvCgyfyrJ+V9tDjU3qCQ3SysJ3/dL30D15Y+LcqjQ96i76TdkrFere/muDanUUCq8lFKklM6BMSTDfcgOp8AoJU9qPTyiI9UXFnKgrTKqRkq1nANZaQUW50ATG52tnlZg5S42qBFQN9SHY+yaee8bazXEi4xHEefA7ED0SL3TCvDEuw/1RhUURjt6RxDnb965Ovr7Ppa28cTmuMRkM82feuRQ872eO9BbTWBo0iO2UlpZo3Oo1IIILZLqUw5pKfWU1tISS8mUZiYqGZ9EpWHjZOXWN1JfSOfAaDLJWmkFRTgHmGGZrlbQGs6BjhZPK7A4B5p4nEKrFbTS3tcKUoREsMh4wDlAhk/Wnjqtc0hdcGzMT1AvkQaWy+FKhvi1d62J/n5yy/5RLxsMMtx9oloRyff/sK5hK3YMZw413y94daFWE+z7rXa2jbTUguos+tsiQQr/DlhKKcWldXfCUpzSrEQlQA7UM1duJPqCR2zzSqwNt5HCIWod1aYVpJAD1VWUaDSR8L1Wyz0dS5wDPuW3Wfe+VhFeTeXso6dG773q3KNS+2CR8Zg5qTP6f/rE+H8puParFwzWfU9NOaXa3Ib4/p7GKBscAodu5IodedV46rE3NmrFhnoirFzIqlLCpRZUZ9HfFkn1KYe1lHpKmVYwBqUZiUoAhSbiqXpCM4e7L7idsmzjHnXqkVO0kVIrb0Kt/AfVRNUlr0Cr5LLLQ7jVck/HEnIgS59qxr2vlQSIrxecMls9sn6PWr/rUGSskoPnc685Sx05dUKh8QBy4FDvgPrCn56t3vPjR6zPaU/94JUnq4G1D9X/WTKQA3lVaarNQR5uOPRwkeHWS4Yjh5qPYyvvAzjjSjLCkedQqTZtjTuu8lKyWnnuljLyUjoHxqg0E1EJRVj+7XcrNakUQTOPrKMhPVx9Qe3+2C+X6dfv++lS9eVbntLtHmkjZVxHdazMPA9TEhLa1QqaGTkgiRZb66BtZc4BmSKTl0/bTHtfq8opc6dE/z+wZlf0/+lHTVGvPu/owtc5InEO7OvpV8cfMSn6u7urXf3Lq87Ue+rgQL+6fq2qu2RVKxjNqjStWK1oOMVX7rd10wpGuyVji0OlFkQo9DRynpLD0cW5gdelc6CUekrr7oSltIQAmrn3cF9DQDOLtnvz3h5vu2vlTaiJkLC9WuSA34hubuRAKLlYcwpHQrQ8cqDFHDutKKfMnWy9PmJyV1Vw9ikTOrSz69H1u6P/F8zsHpE9VV6bp7c0oiFeVuzIH8dW2/e5YJ2UaQW1iy9FbdrEcdG/eqWtQS+Z0NnuTYn7m+cfF/1N+yehahs1LaiU5pISOVBKw0ojQjObud12tYIizoH4u2RzyaizzTnQvEbnuBavVsCfp7OJS066RKJgWowuoiVl+UabGf+WFVsjor6iaDBCiRDvAEXhl6zbE703b9oENRIiuS240dWIhngIHHq4yHAbWfgZ3GolbN3VClr3GUdSfOhPkntXblU33Xm/esllF6tnnTC7+koaiV5CgRfX/XYd6FUf+sVj0XcO9w/WHVVbytiVUo0qpWGlCDSzkaRR282j44Vq7baZA0pCtu1qBe0tXQ6vZTgH2sdetYJSGkcINfW331+cer9aNBh4Bx5JkAPzpo+Mc4AvI+lMHM2qND7JIsNVY7hih+UcaOFnB2JsrI3vcIoL/Un/Ll44Q50/ayj6v5b+Rkqn5otg99tzqDfaR3ce6G0qVG0pzSGtpSWW0lLSiNDMZm63jRwIX/qIpriM/7YWSSugQ5fblK2mJPLnaeZxqqVaQSmNj6qqhjEfFQtWbds/asiBNClmY5bOzCop+Z4XnzQmo418HFutSo2zWkG5PzaNQPeSqYDDsY+WUgqX1t0JS2l6aURoZjO3u1rOAUTRh4bSOW0250DzIgdk/7RadIXzRrQa54Ccy602dq0kw4GqAnJgKNmWjh4h5IBtVFaapnQmSgK+4OQjrPcvPWFsknTysWs1p7CTc6B1H7HlBOe2RPs1Kjq1lNaRknOglIaVvBzJasvDjNV2V5NWQNC0L970ZPT33sP9qZw2HmhpZs4BQPh6W9TA5Epvq9XyTnEOtNbjtZQMB6oKzgHIvGkT1UgI3yN8aUiNWjqT7n/hwhnq909sGxNR83DOgdbtgzKtoPlEphU0Ojq1lNaR1t0JS2l6aVRoZrO2uyghISou7DnkrxTRKmkFJONY+1uN8d7iHGjycZIip3JeKcNSWgtVNStJK4CMFOcAdwhk7acjXZUmVI6ZYTtRWpmML0vGCudAmVbQxMgBcWY3Kjq1lNaR1tISS2k5aVRoZjO2uwhsPjSnjUvXuNZIK6CuaWvlagXtzT1OUsgZwJ+v1Rw7rSTDQdRHZRAhEzvb1XRRSmy4hG8R7U0YdT92Rrf1utWISkNlrFQrgIHZhFN1zAqm5r7DfVZKZyMSnpbSWlKmFZTS8NKo0MxmazeUv5h8L7sNoTlt2/f3tA5yIBmXRp9X1QiNNz0XKRethhwgoWfrTxSnUvltXAGqipBHtMqG6oCqmj7BIAfIMUDTYCRsPO6EasaIcxo5MDYXDnfsNOM4hopmvC+dp00hhMz8/h+eif5ete1AKqWz3vtoKaVwGZunQSlNJ40KzWymdiMqEqIAheaqHe4b0H+Pb3bkQIvnZOK5WtE5wOd0CZttbKknqooU6Pf8ZIl+vWH3YfWcz946ImW8OLqoGfeMqRPHqakTxo0JwzhLuCOplR0kncmDlvtj4wtSOg/0GP1KpnQ2Ijq1lNaREjlQSiljRBA5CFECQ3PVujs7WgY5gH5p1chKR0K42OzjlEsO16Lj10pSD1QVFGiZ+gQFergV5KxShs2EHli6YY+T9GwsIgeadRyLpRW07jO2guSldNLo0ee0fzYaOrWU1pGxeRqUUsoYFBi9g46ShFJCc9qOYuRfrVLKsOWRAy1oBPCIX6uOX6tJLaiqRqjz3expBSTzZ5j9e8m6XWOyLjrfDlutkouPU6eUxpWiZQobCZ1aSutI62mJpZRSijPK9sGfL43+PtQ3GOWvZcFvQysu8PJXXc1eyhDIihY0nvnztWJaAVeISuBA60sj1PmusGXUjAo57f23P2lKGb7jfxePWEpG4yIHWm9vlHN0/+H+3OBAKaMnZZnCUhpBWncnLKWUUiz47a6D/pKELgnJaeM68fimRw60bk4mKYJQBtfvOthyiiHIJFs5LaSUxlKg+TxrNudASE7zmEQONNk4hgqN57/97qno7417DucGB0oZPSnLFJbSCFJyDpRSSgtLkfw1l4Kbl9PGf9MyyIEWUxBJAaQx3nModg59887V6tePbtKsx60g7QwOXObUtr40ggLN975mcg7Ueia0mnD0Wys+72hzc5RSTJDSSePjWqOVJEBTliksZTilubX5UkopZdjht1k5bbwkYrMT3bUi5wAUQzkHWi1CyBX8VkR+lGJLI9T55tOsmRyKjZCS0UjC94tWI2VsBG6OUopJaEpnK+kppTSetNZOWEoppYwo/JZDa5ufkDCNhmhmGUuKoV2tYFSbUsoYUaCbNa2gEVIyGklQ4rfZxjFESkdQc0pZprCU0ZYyraCUUlpYhht+a3EONHlaAYgImykKWC/FkBAhzSx8zFpNwS8lW4EmBxef56RAj0TKTLOmFTRCSkajIge4o6AVpHQENa+UZQpLGU0pnQOllNLCMtz5azy/u9mRAyjx1yqH71hSDG3kQGuMXymNrUDzlKpm2jPKnGa/Y5GnJ7WClI6g5hakdJZSykhLa+2EpZRSyojCb7kh1uwl8hA1aiZFP0vGkmLIFfzSOTC2ZDTrfONezWRUNkJKRiMJd3C3GnKgEbg5SimllOaT5jnRSimllIbLXwN/E+XrN7sy2WqEhGNJMbSQA+WpVsoICXgHmm3PKHOafciB5hrHPCkdQaWUUko1Mqpq1B133KH+6I/+SB111FERRO/nP/+59fnQ0JD6yEc+oo488kg1YcIE9aIXvUg99VRcqxWyc+dO9Wd/9mdqypQpatq0aeqtb32r2r9/v/WdRx99VF122WVq/Pjxav78+epzn/tcqi0/+clP1CmnnBJ958wzz1TXX3/9MD11KaWMvJCyd9f7Llc/eNsl6pqrz4n+p9e1KoGI0jZ7SkErljIcS4qhVY6sRA6UMkKCqdaMa2i4zoRmEz52zYQACZXSEVRKKaU0FefAgQMH1Nlnn63e8pa3qFe/+tWpz8mI/7d/+zf1ne98Ry1cuFB9+MMfVldccYVavnx5ZMSTkGNg06ZN6uabb1Z9fX3qzW9+s3r729+uvv/970ef7927V73kJS+JHAvf+MY31NKlS6P7kSOBvkdyzz33qNe97nXq05/+tHrZy14W/faVr3ylWrx4sTrjjDNGuFdKKaV58tfgHGh2MkJerYDDTJtdRpu0baSEw4F5LngppYyEYdmMzgGSMqdZOAdaLK0AUpLblVJKKU3jHLjyyiujfy4h1MCXv/xl9aEPfUi94hWviN777ne/q+bMmRMhDK6++mq1YsUKdcMNN6gHHnhAXXDBBdF3vvKVr6hFixapz3/+8xEi4Xvf+57q7e1V1157rers7FSnn366WrJkifriF7+onQPXXHONeulLX6re+973Rq8/8YlPRM6Gr371q5FDoZRSSnELdIsSOdC4MhYUw2Zlji+luQXO0VbbM8aScKRRK49j6QgqpZRSmr5awerVq9XmzZujiD9k6tSp6uKLL1b33ntv5Byg/wkBAMcACX2/ra1N3X///epVr3pV9J3nPve5kWMAQuiDz372s2rXrl1q+vTp0Xfe8573WPen78g0By49PT3RPwghFEgIvUD/xrqgD8q+aG0ZHByI/u/tH1B3PblFXXDs9GDjrNHmSFvC3U3Nb5Q21VMuOGaKUor+KTU40K+SoWsq8c0ZPuUGBvpbcvxKqU6Gc5/BvCO3YjnnmlUG9V9DgwOpcWy0c6qUxpdyzpQyGnOmnvOtYZ0D5BggIaQAF3qNz+j/2bNnW593dHSoGTNmWN+hlAR5DXxGzgH6P+s+LqEUhI9//OOp92+66SY1ceLEgk/bukIIjFJaUx7ZUVE/+P/buxPoKKrsj+M3kBAWIewJENlRdgEB/+CCiJFlXBF0cATHBVFGBDcQxOACAziKwzIgRxlwAdQzuDCK2wCOKCIiECAxCIgsAgkGwhLWkPqf+8aKnRCQrnS6uru+n3Nykq6uhIr5WdV1+737tujL4ijZe/iE3P7PVVK5jCW96+fJRdWKWiQrtDPy0zb9XUrJtj1ZMnn+R9KoklXgphOho3Bmsvb+72+nvvj8c6kW/gswIMBK4jxzKldHTEXJnj27ZNGinQH/+Sh56bv1JP+/kW/L/vu5VIkN7esUwgeZQTAzc+TIEYn44kCoGzlyZIHRBjpyQJsdan8DbY7odVrB0pAnJSVJTEyM24eDAPskNUNmf51y2jrZB05EyewfSsvUP14k3VsULLiFckb09/l69QZ9uS97jpaSaWkiCZViZXSvpr/7eyB4zpSZDw+slQ37M83X3a7qKrUrl3PxKBFKSvI88/S6pZKTe1LqJtaRXr1aBfRnIziyV+6QBT99b75Ourqb1KwYG7LXKYQHMgM3MmOPYI/o4kBCQoL5nJGRYVYrsOnjNm3a5O+Tmfm/F4S23Nxcs4KB/f36Wb/Hl/349/axny9KbGys+ShM/6icDH7Df4/IcyrPknEfbTytMKB0m74Po8/3bF3nnKYYuJ2RjzfsliFvnl7oyDh43Gyno3PoKZyZGJ+eF2XKcM5BcM4zpX/tbq/5I3PhqUzMby+Dy8WWOePf0e3rFMIPmUEwMxPIrIVsi3GdCqA354sXLy5QFdFeAp06dTKP9XN2drZ89913+fssWbJE8vLyTG8Cex9dMtF3LoZWZy688EIzpcDex/ffsfex/x0Av9HGdr6d7wvTm2x9XvcLh0KHdvI/U6FD6fO6H0KXbyMxljJEsNhZs4sECD80MwWAgly9oh0+fNisHKAfdhNC/Xr79u1mOaphw4bJ2LFjZeHChWYJwgEDBpgVCHSZQdWsWTOzysDAgQNl5cqV8tVXX8kDDzxgmhXqfuq2224zzQjvvvtuSU1NlbfeesusTuA7JWDo0KFm1YMXXnhB0tPT5amnnpJVq1aZnwWgIO14H8j93BRJhQ4v831Rz1KGCBY7dr8udIIw5FtMtJezBQAvc3Vagd6Ad+3aNf+xfcN+xx13yJw5c2T48OGSk5NjlhzUEQKXXXaZuYkvW/a3blO6VKHexHfr1s2sUnDzzTfLlClTCqxwoE0C//KXv8jFF18s1atXl+Tk5PxlDFXnzp1l3rx5ZtnEUaNGSZMmTcxKBS1btgzafwsgXOhSeIHcz02RVOjwsgIjB3j3D0FS6tesRTNyIGxF+xQEOHcAgMvFgSuvvFIs68zDdfUdoGeeecZ8nImuTKA39mfTunVrWbZs2Vn36du3r/kAcHYdG1SVWnFlZc+BY0UOx9eXVwlxZc1+oS6SCh1eFu3z1i2v7xEs9s0kN5Xhq5TvyAGKPAAQuj0HAIQmfSE85rrm5uvCL4ntx/p8OLxgtgsdZzpS3V4rTAodXuY7csB+NxcI1o2lb/4QXuy/nf4pOXcAAMUBAA5o937t4q8jBHzp43Dq7h9JhQ4v8/37+L4TCJQkO3bcVIYv+2/HqAEACPGlDAGENi0AJDVPMM36dE6+Dr3Xd9jD7UbaLnToqgS+zQm10KGFgXApdHgZqxXADYwcCH/23y7crlsAUFIoDgBwTF9QdWpUTcJdpBQ6vMp3KTlqAwgWeg5EDkss+XpLFud9AJ5HcQAAIqjQ4UWsVgA3MHIgvH28YbeMeneD+frYyTzp9/IK02OGEWMAvIxJVgCAsEbPAbjBHrBCz4HwLAzc/8Zq2ZdzosB2XYVHt+vzAOBFFAcAAJGzWgH3aQgSu78FIwfCy6k8y/SYKWopXnubPq/7AYDXUBwAAIS10qV/W44sipEDCBJ7xIBvzwuEPu0t49t8tjAtCejzuh8AeA1XNABAWLOXIWOlAgSLvqucczzXfL1j3xHeZQ4j2nQ2kPsBQCShOAAAiIieA/QbQDDofPTLJi6RHzIOm8dzlv9kHjNPPTzoajSB3A8AIgnFAQBAWIv+dVoBo7sRrEZ2hYel08gufOhyhboqwZlKibpdn9f9AMBreCkFAAhrjBxAMNDILnLOF7pcoSp8xrAf6/MsiwrAiygOAADCmt0tnp4DKEk0soscPVrWkhm3t5OEuIJTB/SxbtfnAcCLot0+AAAAisPuFk9tACWJRnaRRQsASc0TTDFH/2baY0CnEjBiAICXURwAAETEyAF7aTmgJNDILvJoIaBTo2puHwYAhAymFQAAwpr9Th/TClCSaGQHAIh0FAcAABExciCK4gBKEI3sAACRjuIAACCs2asUnDh1Sr7ekkW3eJQYGtkBACIZPQcAAGFL15Uf+c568/XBo7nS7+UVZmi3voPLjRpKAo3sAACRiuIAACBsCwP3v7H6tHXn9xw4ZrbzTi5KCo3sAACRiGkFAICwo1MHnv532mmFAWVv0+eZYgAAAHBuKA4AAMKODunefeDM68lrSUCf1/0AAADw+ygOAADCjs71DuR+AAAAXkdxAAAQdrQJXCD3AwAA8DqKAwCAsKPd4XVVgjP1h9ft+rzuBwAAgN9HcQAAEJbd4nW5QlW4QGA/1udZXg4AAODcUBwAAIQlXaZQlytMiCs4dUAfs4whAACAf6L93B8AgJChBYCk5glmVQJtPqg9BnQqASMGAAAA/ENxAAAQ1rQQ0KlRNbcPAwAAIKwxrQAAAAAAAI+jOAAAAAAAgMdRHAAAAAAAwOMoDgAAAAAA4HEUBwAAAAAA8DiKAwAAAAAAeBzFAQAAAAAAPI7iAAAAAAAAHkdxAAAAAAAAj6M4AAAAAACAx1EcAAAAAADA4ygOAAAAAADgcRQHAAAAAADwuGi3DyBSWJZlPh88eNDtQwkJJ0+elCNHjpj/HjExMW4fDkIQGYG/yAz8RWZQHOQH/iIzcCMz9v2nfT9aHBQHAuTQoUPm8/nnn+/2oQAAAAAAPHY/GhcXV6yfEWUFosQAycvLk127dknFihUlKipKvE4rWFoo2bFjh1SqVMntw0EIIiPwF5mBv8gMioP8wF9kBm5kRm/ntTBQu3ZtKVWqeF0DGDkQIPqHSExMdPswQo6GnJMjzoaMwF9kBv4iMygO8gN/kRkEOzPFHTFgoyEhAAAAAAAeR3EAAAAAAACPoziAEhEbGytjxowxn4GikBH4i8zAX2QGxUF+4C8yg3DPDA0JAQAAAADwOEYOAAAAAADgcRQHAAAAAADwOIoDAAAAAAB4HMUBAAAAAAA8juIAAABAEfLy8tw+BAAAgobiAEIOL8YABFJGRobs2rXL7cNAmElPT5fJkye7fRgAAARNdPD+KeDsDhw4IHFxcVKqVClTINDPgK+tW7fKe++9J3v37pVOnTrJdddd5/YhIcStWbNGbrzxRpk9e7bUrl3b7cNBmFi/fr106NBBTpw4IZ07d5ZLLrnE7UNCmPjpp5/ks88+k6NHj0qTJk2kZ8+ebh8SwoiuMB8VFeX2YcDDmeHuCyEhLS1N6tWrJ3/961/NY7tAANjWrVsnV1xxhXzwwQfy3//+V2644QZZuHCh24eFEJaSkiKXX3653HTTTXLVVVe5fTgIo9x07NhRbr31VunSpYs55yiuSTiXopIWkubPny/vvvuuXHvttTJgwABZuXKl24eGELdv3z7zWW/y9GYPcCszFAfgup07d8rtt98u8fHx8sILL8iECRPMdgoEsP3www/yhz/8Qfr37y8fffSRebGu78ZodoCipKammsLAkCFD5O9//7ucOnVK1q5dK8uXLzfPAWcaaaK5eeSRR+TVV181owdmzpxpRrbpNYkX7TiTrKwsc40aOHCgLFmyRJYuXWquVXPnzpWxY8eax8CZ3iDT18DDhg0zjykQwM3MUByAq/Tmf8GCBdKgQQN56aWXZPjw4TJ+/HgKBMinw3qffvpp6datmzz77LNSpkwZqVKlipQrV05WrFghd999t0ybNk3279/v9qEiRBw/fty8SD/vvPNk6NChZlufPn3krrvuMlNR9J29v/3tb24fJkJMZmamXHrppTJo0CBzM6e0uFS1atX83gMM98WZZGdnS3R0tNx2223mRbpeu9q0aSPNmjWTb7/9lusUiqT9cO68805p3bq1vPLKK/LQQw+Z7RQI4FZm6DkAV+nNf69evaRmzZrStWtXcyHVYGuBQD3++OP0IPA4LQaMGjXKnAxLly5ttun0Ex2y2a9fPylbtqw8+OCDsnHjRpk6darbh4sQEBsbK5MmTZL77rvPXDR15En16tVlypQpJi9ff/21KRpUrFjR7AOomJgY+fjjj830JZu+M9O2bVv59NNPJTk52WxjTjCKcujQIVm9erXs2bNHmjdvbq5dR44ckfPPP99cw3SEZI8ePczIAsA+l+iIEp1Wq+8Ab9u2zdz06flFr2H2zR7nGwQ1MxYQAvLy8vK/3rt3rzVhwgSrUqVK1vjx48223Nxca+HCheY5eNu6deusq6++2lq0aFF+bv71r39Z0dHRVnp6utuHhxA6lyxdutRKSEiwunTpYu3atavAfo888ojVqlUrKysrq8D3ALZTp06Zzxs2bLBiY2OtWbNmuX1ICGEnT560+vfvbzVu3NiaNm2aNX/+fKtKlSrW4MGDzfPDhg2z/vjHP5r9OOfAtn37duv999/Pfzx37lxzvtG82MgLfG3btq1EM8PIAQSdvgP8888/m/l5V199tRkRoB+5ublmSJ6+w6fDf+13iLUCpvvqsM7t27e7ffhwMSOqVatW8tprr0mtWrXy99fn9J0azQ68yTczOgVFXXnllWbOr87Nq1GjRoH9dQRB+fLlzRQV3pXxrjOda+zRanr90Wlv2lhO+53okHEdmUJm4JudpKQk8/plxIgR8o9//EPGjBkjCQkJMnjw4PwpKtq3QqcV6H6ATUeW6IdNG6Hq+cX33WDtmfPWW2/JRRddJC1btnT1eOG+unXrlmhmOEMh6B3n9UWWDufVob56o3fvvfea4XY6P1jDrEPH9YW8ziXXF2Y6HK9y5cpmKLDvDSG8mRGlL7p8aTYSExPNME54T1GZueeee0xmLr74YjMvr/ALcn1B36JFCzl58qQZTs7Nnvf83rnGLhBoEal3796maG0vcQhvK5wdffGthQDNzvTp0+WJJ54w2bFfs+hrGX19Y0+dVJxzvMm+5pyJvgbu27ev+Vpv9pRmZ8aMGbJ58+agHSdCx44dO+T77783y3hrIVLvifT1rv2masAz43jMAeAnnRLQrFkza8SIEdbWrVutzMxMq1+/ftYll1xihsIcPHiwwFBOpUP0dHpBamqqi0eOUMuITYeKjx492qpcubK1fv16144b4ZWZJ5980gz35bziXeeaG53SZmvbtq25Juk1imG+3nWm7HTo0MFkJzs7u8D+W7ZssUaNGmWuU2lpaa4dN9ynU5Suv/76c7r26Lnn9ddft6Kiosz16ttvvw3KMSK0pKSkWPHx8Va7du2sMmXKWC1atLAee+wxa//+/addowKVGYoDCBq9eatfv74Juu348eNWcnKy1VbPVTUAABLfSURBVLFjR+uJJ56wjh49arbrCy8NuP4P8d1337l41AgmfzKyatUq6/bbb7caNGhgrVmzxsWjRrhkZuXKlVbfvn2txMREMuNx/uTGNnnyZGvTpk0uHC3CNTtaSLjvvvusCy+80Fq9erWLRw23aSGpYcOG5satTZs21saNG8+6vxYh7777bvMGGUUlb8rOzjZFAe2RpP2R9LwycuRIq3PnztYNN9xgtvkWCAKVGdq/I2h0CIwOo7P7BuhwGN325JNPSpcuXeTDDz80y/0o3U+XlPrmm2+kXbt2Lh85QjEjOrXglltukcWLF5uhmvAmfzKjQ3w1M59//jmZ8Th/cqPPKV0VpXHjxq4eN8IrO9oH57HHHjPXKV31At5dXvfVV181879Xrlxp8nLjjTeaKSln8sknn8iSJUtMdnQ5THjP/v37zRKpugSzLqmrvZKeeuopM21Sl97Va5KukqLTCvQN/0BlJkorBAH9TYCznBwvu+wyc1P33nvvmTDb82U0hnrS1IunnkBZusWbziUjelOnDQkBRWZQ0tcjwBfZgb+0f4lmRT/36dPH3PB1797d3Njp9gsuuKDIhpfat6JwjyV4xy+//GKWeR80aJA88MAD+fdGmqOXXnpJZs2aZZYz7N+/v9k/IyPD7FPczDByAEGhQdYOz7Nnz5YvvvhC7r//frPdvphq2K+//npTCVMUBrznXDOiDVkARWYQjOsRYCM7cEJv8m+44QZTGFDaUG7RokWmoaWOINi0aZPZrkWm5cuXy7Fjx6R27doUBjwuLi5OLrzwQpk/f75s27Yt/95I86QNUHVkkq5IYIuPjw9IZigOICg0yNo5Uzv6ajVdgz5gwABT5bJt3brVLCum+8F7yAj8RWbgBLmBU2QHTukIE2UP2K5WrZqZgqIFAi0cpKamypAhQ+Shhx6SnJwcl48WbtOc6KoWuvrJli1bzBQCLTr6DvjX6QY6ukCLSYHEtAKUiMLTAuwhd4cPHzZD8tauXWvWi65Xr56ZR6Mnyffff98sSafLSSHykRH4i8zACXIDp8gOSipL9mNdVldv8rTHlo5K0REp7du3d/VYERpOnDhh+lPoeaZHjx5mWeZx48aZXmxabNLeA7t375Z33303oEt5M3IAAaXVLW2g4XsC1Oq5Xkx/+uknM69KG/V069bNVEl79eolderUkZo1a5omLVxMIx8Zgb/IDJwgN3CK7KA4Cr/vqtnRLB08eND0G1B2trSg1LRpUzPaZNWqVRQGPMgq4n16zYze8GvxSKcL6HQTnVpw3333meLATTfdJG+//baMHz8+oIUB+4CAgFi7dq1ZomXWrFmnPbd9+3arevXqZokNXabQXnbDXital99A5CMj8BeZgRPkBk6RHTi1efNma9++fQW22RnRpQxr165tLVq0KP85zc2UKVNM3ljq0pt+/PFH66233jLLFp4pM7q0uzpw4ID12muvmaUNx40bZ6Wnp5fIMVEcQMAuphUqVLBGjBhR5PN68hs2bFj+BdRmPy68HZGHjMBfZAZOkBs4RXZQkkWle+65p0BG9OulS5damzZtCvLRIhSkpKSYXDz++OP5GbALjJqZypUrWwMHDjQ5CWbhkZ4DKLb09HQzhC45Odms86vdfHUd8c2bN5umPU2aNJEaNWqY7drMB95DRuAvMgMnyA2cIjtwKiUlRS699FKz3NyECRNOe37q1Kny448/yqRJk1iNC8aOHTvMkqh9+/aV559//rQ+AwsWLDC9S5577rmgn2+ig/qvIeLoRVLnvOjcGHuJlqSkJDNHRufl6VyqBg0amBOiNtKA95AR+IvMwAlyA6fIDopTVNI+AWcrKukqBLqdwgBs2kOgYcOGpjCg2dD8aK8TLQ5oXm6++Wbz4QZKnygWrWYNGjRIBg4cKG3btjVVd12/VZf40bXFNfTaUXPs2LGmuy+8h4zAX2QGTpAbOEV2EMii0sMPPyzDhw+X/v37S79+/WTdunWMNsFpIwfi4uLM1zqCQJtRlitXzjy+6qqr5J///Kf52pUB/kGbwICIlpmZaQ0ePNhq3769lZaWVuC5F1980UpISLB27tzp2vHBfWQE/iIzcILcwCmyA3/t2bPHuvfee63Y2FirZcuWVu/evU3/gRMnTljvvPOOdc0111h9+/a1Dh065PahIoTMnTvXio+Pt1555RWrV69eVlZWVv5z2mwwOjra2rBhgyvHxrQC+G3Xrl2yevVqM/Slbt26ZjiVzsMbPXq0WWajUaNGZj+tpGqlvXHjxmaJloAvtYGQRUbgLzIDJ8gNnCI7CARdZk5HlOgyl7qMpX7drFkz85wuN6dZmjhxohw4cEDOO+88tw8XIeLSSy+VSy65RGbMmCEVK1aUqlWr5vczueeee2TOnDlmmdQWLVoE/dgoDsAv69evlxtvvFGqV69umqvUr1/fDJ3Shhq1atWShISE/DlVejFV//nPfyQxMVHKly/v8tEjGMgI/EVm4AS5gVNkB05RVEJxMlOvXj25+OKLzecrrrjCNBzU7Vu3bjV9TZQWkXRaU2xsrLjClfEKCNv1WxMTE63hw4eb9ThXrVpl3XHHHdZdd91l1uQsvITPtm3brEcffdSqWrWqtW7dOteOG8FDRuAvMgMnyA2cIjtwSv/+DRs2tDp27GiWoNPpJ2+//Xb+80UtZTl06FArKSnJOnz4cJCPFqGamTfffDP/+YkTJ1q1atWyWrduba1YscJav369lZycbNWvX98sZ+gGigM4J8ePH7cefvhh65ZbbjFf23Q912rVqlm//PJLgf2/+eYbc6Ft2rSptWbNGheOGMFGRuAvMgMnyA2cIjtwiqISApkZ3/OP9h/o2bOnFRUVZbVo0cJq3LixtXr1asstTCvAOdF5MDqcTudR6dAoLSzpkLvOnTub4S8nT54ssH/Hjh3l0KFD8swzz0idOnVcO24EDxmBv8gMnCA3cIrswAkd9j19+nSTk2effdZkR4eG67BwnY6iQ8N1uUub9h6YOXOmWa5u8eLFZvULeMsJPzJz2223mQ+delCpUiXzUbNmTdeOneIAzknZsmXN/Dx7PoxN58TExMQUuKB+99135n+Abt26uXCkcAsZgb/IDJwgN3CK7MAJikooqczY21WbNm1CYslL948AIWv37t2m+vnxxx+bkNsXU22yYgdZu6/u378//3uSk5PNGq9ZWVnurM2JoCIj8BeZgRPkBk6RHQSqqKRd5M+lqKS0qERhwLvKnmNm9By0Zs0a83UoFAYUIwdQpHXr1sn1119vOmVmZGSY7r16sezevbtZbsOudOmHhlmrYLp8y/PPPy/Lli0rMLwKkYmMwF9kBk6QGzhFdlCcotKOHTtk3759cs011xQoKtkrWBRVVJo2bZps2rTJ5MsuPsEbdkdKZlzrdoCQlZmZaZrvjBo1ytqyZYv1888/W7feeqvVrFkza8yYMeZ5W0ZGhtW2bVvzfJkyZUyzDUQ+MgJ/kRk4QW7gFNmBUykpKVa9evWsCy64wIqLizM5mjdvnpWVlWWet5sPbty40apRo4a1b98+69lnn7XKlStHdjwqJYIyQ3EAp0lNTTVLaBQO64gRI6xWrVpZzz33nJWTk2O2paWlme6aGm46+XoHGYG/yAycIDdwiuzACYpK8HpmQmNyA0KKzoPJzc2VI0eOmMdHjx41nydMmCBdu3aVGTNmyObNm822KlWqyODBg02HTW2kAW8gI/AXmYET5AZOkR04sXfvXjl27Jj07t1bGjZsKLVr15Y333zTTE955513ZM6cOfmZ0p4Ua9eulYULF8o333xjGljCe/ZGWGaitELg9kEg9GinVZ17t2TJEvP4+PHjZs6e6tChgzRu3Fjmz59vHuv/ENp4A95CRuAvMgMnyA2cIjvwV0pKilx77bUyb948ufzyy01RqVy5cua5oUOHyr///W957733pHXr1rJnzx7To+KBBx6Qpk2bun3ocElKhGWGkQOQnJwcs+TKwYMH87fp+qypqalm3U2lF1OtwCtdo1O/x8bFNPKREfiLzMAJcgOnyA4C4aKLLjKNK8eMGWMe602eFpXU5MmTTZPK8ePHm8cJCQmmeWWo3uQhOC6KsMxQHPC4tLQ0MwymS5cuZi3OuXPnmu36tQb6s88+k759+5rhefYSG5mZmVKhQgVzgWXgSeQjI/AXmYET5AZOkR04RVEJ/sqJ8MywlKHHL6Ya2AEDBkj79u3N2qx33nmnNG/eXNq2bWvmyuiFU+fh6VAYrXKVKVNGPvzwQ1mxYoVERxOfSEdG4C8yAyfIDZwiOyhOdh566CEzZ1yXunzuuefkT3/6U35RaciQIaaopMPF7aXofItKui0klp5D0KR5IDP0HPAoXYOzX79+5iKpYbZpk55WrVrJlClT8rdpdUznx+j3aLXr/vvvNxddRDYyAn+RGThBbuAU2UEgi0pTp041TeK0qKQN5BYvXmyKStq3onBRqWXLlm7/CgiyNI9khnKpR+nQuuzsbOnTp495nJeXZ4baNWjQwFw41a9LXUrFihVl4sSJBfZD5CMj8BeZgRPkBk6RHTih2dB3f/Ud30mTJpltOhxcV6uYPXu2udErX768XHfddXLllVcWKCqtXLmSopIH7fNQZigOeFR8fLy88cYb0qRJE/P41KlT5kJZp04d2bZtm9mmw170Q+fUVKpUKX8bvIGMwF9kBk6QGzhFduAERSX466SHMhNeR4uAsi+mGtyYmBjztYZa58bYtLvmK6+8kt9Ugwuqt5AR+IvMwAlyA6fIDpwWlXTZObuopLSoZN/IaUb0a9+mc+TGu+I9lBlGDsAEWS+kdoDtkCcnJ5thMWvWrKFhj8eREfiLzMAJcgOnyA5KoqikXecffPBBk51wvNFD4DTxSGY4S8KwL6ga5PPPP9+swakdOFetWmXW7wTICPxFZuAEuYFTZAf+oqgEf5WK8MyE75EjoOxgayXs5ZdfNvPyvvzyS2nXrp3bh4YQQUbgLzIDJ8gNnCI7cIKiEvxlRXBm6DmAArp3724+L1++3CzTARRGRuAvMgMnyA2cIjsoTlFJ3/2lqASvZibK0tIH4CMnJ0cqVKjg9mEghJER+IvMwAlyA6fIDvyl7/p27NhRNmzYEFZLz8E9qyIwMxQHAAAAAHgeRSV4PTMUBwAAAAAA8Dh6DgAAAAAA4HEUBwAAAAAA8DiKAwAAAAAAeBzFAQAAAAAAPI7iAAAAAAAAHkdxAAAAhJQ5c+ZI5cqV3T4MAAA8heIAAABw5M9//rNERUWd9rF582a3Dw0AAPgp2t9vAAAAsPXo0UNmz55dYFuNGjVcOx4AAOAMIwcAAIBjsbGxkpCQUOCjdOnS8v7770u7du2kbNmy0rBhQ3n66aclNzc3//uys7Nl0KBBEh8fb/Zp2bKlfPDBBwV+9ieffCLNmjWT8847zxQhdu/enf/ct99+K0lJSVK9enWJi4uTLl26yOrVq4P6uwMAEEkoDgAAgIBatmyZDBgwQIYOHSppaWkyc+ZM00dg3Lhx5vm8vDzp2bOnfPXVV/LGG2+YfSZMmGCKCrYjR47I888/L6+//rp88cUXsn37dnn00Ufznz906JDccccd8uWXX8qKFSukSZMm0qtXL7MdAAD4L8qyLMvB9wEAAI/TngN6c6/v/Nv0pn///v3SrVs3GTlyZP523W/48OGya9cu+fTTT81+33//vVxwwQWn/VwtJNx5552md0GjRo3MtunTp8szzzwje/bsKfJYtOCgTQznzZsn1157bYn8vgAARDJ6DgAAAMe6du0qM2bMyH9coUIFad26tRkVYI8UUKdOnZJjx46ZEQFr166VxMTEIgsDtvLly+cXBlStWrUkMzMz/3FGRoaMHj1aPv/8c7Ndf77+bB1hAAAA/EdxAAAAOKbFgMaNGxfYdvjwYdNjoHfv3qftr6MMypUr97s/NyYmpsBjXQXBd7CjTinIysqSyZMnS7169Uzvg06dOsmJEyeK9fsAAOBVFAcAAEBAaSPCjRs3nlY0sOnIgp07d8oPP/xw1tEDZ6MjE3SqgfYZUDt27JBffvmlWMcNAICXURwAAAABlZycbOb9161bV/r06SOlSpWSlJQU2bBhg4wdO9asLHDFFVfIzTffLJMmTTJFhPT0dDM6QFclOBfagFCbFbZv314OHjwojz322DmNSAAAAEVjtQIAABBQ3bt3N8sSauPBDh06yP/93//Jiy++aIb/2xYsWGCe69evnzRv3tw0K9S+Aedq1qxZpvGhjlLo37+/PPjgg1KzZs0S+o0AAIh8rFYAAAAAAIDHMXIAAAAAAACPozgAAAAAAIDHURwAAAAAAMDjKA4AAAAAAOBxFAcAAAAAAPA4igMAAAAAAHgcxQEAAAAAADyO4gAAAAAAAB5HcQAAAAAAAI+jOAAAAAAAgMdRHAAAAAAAwOMoDgAAAAAAIN72/8kCF3G+GemWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/23 19:40:49 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 852153 ms exceeds timeout 120000 ms\n",
      "25/12/23 19:40:49 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/12/23 19:40:53 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:40:53 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:41:03 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:41:03 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:41:13 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:41:13 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:41:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:41:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:41:33 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:41:33 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:41:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:41:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:58:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:58:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:58:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:58:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:59:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:59:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:59:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:59:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:59:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:59:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:59:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 19:59:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:10:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:10:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:10:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:10:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:10:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:10:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:10:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:10:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:11:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:11:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:11:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:11:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:11:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:11:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:11:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:11:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:11:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:11:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:11:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:11:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:12:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:12:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:12:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/12/23 20:12:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/12/23 20:12:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:12:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:29:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:29:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:29:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:29:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:29:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:29:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:29:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:29:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:29:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:29:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:29:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:29:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:46:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:46:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:46:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:46:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:47:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:47:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:47:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:47:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:47:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:47:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:47:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 20:47:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:03:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:03:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:03:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:03:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:03:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:03:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:03:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:03:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:03:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:03:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:04:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:04:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:11:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:11:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:11:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:11:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:11:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:11:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:11:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:11:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:12:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:12:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:12:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:12:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:12:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:12:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:28:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:28:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:28:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:28:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:28:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:28:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:28:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:28:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:28:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:28:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:29:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:29:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:44:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:44:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:44:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:44:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:44:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:44:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:44:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:44:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.1:55353\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/23 21:44:46 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "# Leer Gold para verificar\n",
    "df_gold_daily = spark.read.parquet(gold_daily_path)\n",
    "df_gold_daily.show(10, truncate=False)\n",
    "\n",
    "# Convertir a Pandas para gráfica rápida\n",
    "df_gold_pd = df_gold_daily.toPandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_gold_pd[\"sale_date\"], df_gold_pd[\"daily_revenue\"], marker='o')\n",
    "plt.title(\"Revenue Diario (Capa Gold)\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Revenue ($)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
